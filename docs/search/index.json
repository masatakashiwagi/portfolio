[{"content":"ã¯ã˜ã‚ã« 2ãƒ¶æœˆä»¥ä¸Šã”ç„¡æ²™æ±°ã«ãªã£ã¦ã—ã¾ã„ã¾ã—ãŸãŒï¼Œä¹…ã—ã¶ã‚Šã®ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°ã«ãªã‚Šã¾ã™ï¼ä»Šå›ã¯ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«ï¼ŒGithub Actionsã¨CodePipelineã‚’ä½¿ã£ã¦ãƒãƒ¼ã‚¸ãƒˆãƒªã‚¬ãƒ¼ã§Step Functionsã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å‹•ã‹ã™CI/CDã‚’æ§‹ç¯‰ã—ãŸãŠè©±ã«ãªã‚Šã¾ã™ï¼\nä»Šå›ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¯ï¼Œ3ã¤ã»ã©ã‚ã‚Šã¾ã™ï¼\n MLç³»ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã¨DryRunçš„ãªã‚‚ã®ã‚’æ¯å›æ‰‹å‹•ã§å®Ÿè¡Œã™ã‚‹ã®ãŒã„ã„ã‹ã’ã‚“ã‚ã‚“ã©ãã•ããªã£ã¦ããŸ äººæ•°ãŒå°‘ãªã„MLãƒãƒ¼ãƒ ã ã¨æ‹…å½“è€…ãŒå¯¾å¿œã§ããªã„å ´åˆã«ï¼Œå±äººåŒ–ã—ãŸã‚‚ã®ã‚’ä»£ã‚ã‚Šã«ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã®ãŒå¤§å¤‰ã§ã‚ªãƒšãƒŸã‚¹ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹  ã“ã®è¾ºã‚Šã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™ã‚„ãƒãƒ¼ãƒ å†…ã§ã®å…±æœ‰ã¨ã„ã£ãŸéƒ¨åˆ†ã‚’æ•´ç†ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã®ã¯ç†è§£ã—ã¤ã¤\u0026hellip;   CI/CDå‘¨ã‚Šã®è¨­å®šå«ã‚ã¦ã‚‚ã†å°‘ã—çŸ¥è­˜ã‚’ä»˜ã‘ã¦MLOpsã®ãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ãŸã‹ã£ãŸ  MLç³»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã„ã¦ï¼ŒCI/CDæ•´å‚™ã®å„ªå…ˆåº¦ãŒä½ã‹ã£ãŸã‚Šï¼Œãã‚‚ãã‚‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«æ¯”ã¹ã¦ã“ã®è¾ºã‚Šã®çµŒé¨“ã‚„çŸ¥è­˜ãŒè±Šå¯Œã§ãªã„ã¨ã„ã†ã“ã¨ã§å¾Œå›ã—ã«ã•ã‚ŒãŒã¡ã§ã™ãŒï¼ŒMLOpsã‚’è€ƒãˆã‚‹ä¸Šã§CI/CDã¯å¤§äº‹ãªãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®1ã¤ãªã®ã§ã—ã£ã‹ã‚Šå–ã‚Šçµ„ã‚€ã¹ãã ã¨æ€ã„ã¾ã™ï¼ˆCI/CDã®è‡ªå‹•åŒ–ã¯GoogleãŒå®šç¾©ã—ã¦ã„ã‚‹MLOps level 2: CI/CD pipeline automationã«ç›¸å½“ã™ã‚‹éƒ¨åˆ†ï¼‰ï¼ã¾ãŸï¼Œå°‘äººæ•°ãƒãƒ¼ãƒ ã®å ´åˆã¯å°šã®ã“ã¨ï¼Œäººæ‰‹ã‚’ã‹ã‘ã‚‰ã‚Œãªã„+å±äººåŒ–ã‚’æ’é™¤ã™ã‚‹æ„å‘³ã§ã‚‚å–ã‚Šå…¥ã‚Œã¦ã„ãã®ãŒè‰¯ã„ã‹ãªã¨æ€ã„ã¾ã™ï¼\nä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãªã©ã‚’ç½®ã„ã¦ã‚ã‚Šã¾ã™ï¼\n CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹æˆ â€» ã¯ã˜ã‚ã«ï¼ŒCodePipelineã®è¨­å®šã‚„IAMãƒ­ãƒ¼ãƒ«ã®å¿…è¦ãªæ¨©é™ã¯è©³ç´°ã«èª¬æ˜ã—ãªã„ã®ã§ã”äº†æ‰¿ãã ã•ã„ã¾ã›ï¼å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚„å··ã«ã‚ã‚‹è©³ç´°ãªèª¬æ˜ãŒã•ã‚Œã¦ã„ã‚‹ãƒ–ãƒ­ã‚°ã‚’ã”è¦§ä¸‹ã•ã„ï¼\nä»Šå›ã®ã‚´ãƒ¼ãƒ«ã¯Githubã®ãƒ–ãƒ©ãƒ³ãƒãƒãƒ¼ã‚¸ã‹ã‚‰æœ€çµ‚çš„ã«Step Functionsã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å‹•ã‹ã™ã¨ã“ã‚ã¾ã§ã«ãªã‚Šã¾ã™ï¼æœ¬æ¥ã¯Step Functionså†…ã§MLã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’è¡Œã†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ãŒï¼Œä»Šå›ã¯ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦SageMaker ProcessingJobã‚’å˜ç™ºã§å‹•ã‹ã™ã ã‘ã«ãªã‚Šã¾ã™ï¼\nä»Šå›æ§‹ç¯‰ã—ãŸCI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã«ãªã‚Šã¾ã™ï¼\nãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n. â”œâ”€â”€ .github â”‚ â””â”€â”€ workflows â”‚ â””â”€â”€ sam-codepipeline.yaml â”œâ”€â”€ README.md â”œâ”€â”€ config â”‚ â”œâ”€â”€ buildspec.yml â”‚ â””â”€â”€ codepipeline-ver1.json â”œâ”€â”€ container â”‚ â”œâ”€â”€ Dockerfile â”‚ â”œâ”€â”€ app â”‚ â”‚ â””â”€â”€ src â”‚ â”‚ â”œâ”€â”€ hello.py â”‚ â”‚ â””â”€â”€ logger.py â”‚ â”œâ”€â”€ docker-compose.yml â”‚ â”œâ”€â”€ requirements.lock â”‚ â””â”€â”€ requirements.txt â””â”€â”€ sam â”œâ”€â”€ env â”‚ â”œâ”€â”€ dev â”‚ â”‚ â”œâ”€â”€ samconfig.toml â”‚ â”‚ â””â”€â”€ template.yaml â”‚ â””â”€â”€ prod â”‚ â”œâ”€â”€ samconfig.toml â”‚ â””â”€â”€ template.yaml â””â”€â”€ statemachine â””â”€â”€ sample-ml-pipelines-ver1.asl.json  æµã‚Œã‚’èª¬æ˜ã—ã¦ã„ãã¨ï¼Œ\n  Github Actionsãƒ‘ãƒ¼ãƒˆ\n sam-codepipeline.yaml name: sam-stepfunctions-codepipeline on: pull_request: branches: - dev - main types: [opened] # paths: # - 'config/codepipeline-ver1.json' # - './github/workflows/sam-codepipeline.yaml' workflow_dispatch: jobs: Build-Deploy-SAM: name: Build \u0026amp; Deploy SAM for Pipeline runs-on: ubuntu-latest timeout-minutes: 5 steps: - name: Checkout uses: actions/checkout@v2 - name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: ap-northeast-1 # samã«ã‚ˆã‚‹dev/prodç’°å¢ƒã®AWSãƒªã‚½ãƒ¼ã‚¹æ›´æ–° - name: Build SAM \u0026amp; Deploy SAM run: | if ${{ github.base_ref == 'dev' }}; then cd sam/env/dev sam build sam deploy --fail-on-empty-changeset --no-confirm-changeset elif ${{ github.base_ref == 'main' }}; then cd sam/env/prod sam build sam deploy --fail-on-empty-changeset --no-confirm-changeset else echo \u0026quot;Invalid branch name.\u0026quot; exit 1 fi Update-CodePipeline: name: Update Codepipeline for Step Functions runs-on: ubuntu-latest timeout-minutes: 5 needs: Build-Deploy-SAM steps: - name: Checkout uses: actions/checkout@v2 - name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: ap-northeast-1 - name: Update Codepipeline run: aws codepipeline update-pipeline --pipeline file://config/codepipeline-ver1.json    Pull ReqestãŒOpenã—ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§Github ActionsãŒèµ°ã‚‹ AWS Serverless Application Model (SAM)ã®Buildã¨Deployã‚’è¡Œã†  ãƒãƒ¼ã‚¸å…ˆã®ãƒ–ãƒ©ãƒ³ãƒã«å¿œã˜ã¦ï¼Œåˆ‡ã‚Šæ›¿ã‚ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼devãƒãƒ¼ã‚¸ã§ã¯devç”¨ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ï¼Œmainãƒãƒ¼ã‚¸ã§ã¯prodç”¨ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ï¼   AWS CLIã‚’ä½¿ã£ã¦CodePipelineã®action configurationã‚’æ›´æ–°ã™ã‚‹  Step Functionsã®StateMachineArnãŒMLã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦å¤‰æ›´ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ï¼Œå¾Œç¶šã®CodePipelineã§å‹•ã‹ã™å¯¾è±¡ã®Step Functionsã‚’æ›´æ–°ã—ã¾ã™ï¼      CodePipelineãƒ‘ãƒ¼ãƒˆ\n buildspec.yml version: 0.2 env: variables: ENV: \u0026quot;dev\u0026quot; REPOSITORY_NAME: \u0026lt;ECRã®ãƒªãƒã‚¸ãƒˆãƒªå\u0026gt; IMAGE_TAG: \u0026quot;latest\u0026quot; REGION: \u0026quot;ap-northeast-1\u0026quot; parameter-store: AWS_ACCOUNT_ID: \u0026quot;/CodeBuild/common/AWS_ACCOUNT_ID\u0026quot; AWS_ACCESS_KEY_ID: \u0026quot;/CodeBuild/common/AWS_ACCESS_KEY_ID\u0026quot; AWS_SECRET_ACCESS_KEY: \u0026quot;/CodeBuild/common/AWS_SECRET_ACCESS_KEY\u0026quot; phases: pre_build: commands: # - echo Login to Docker # - docker login --username $AWS_ACCESS_KEY_ID --password $AWS_SECRET_ACCESS_KEY - echo Set ECR repository URI - REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com - aws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $REPOSITORY_URI build: commands: - echo Build started - echo Building the Docker Image - docker build -t $REPOSITORY_URI/$REPOSITORY_NAME:$IMAGE_TAG container post_build: commands: - echo Login to Amazon ECR - aws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $REPOSITORY_URI - echo Pushing the Docker Image to ECR started - docker push $REPOSITORY_URI/$REPOSITORY_NAME:$IMAGE_TAG    PRãŒdev/mainã«ãƒãƒ¼ã‚¸ã•ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§AWSã§äº‹å‰ã«è¨­å®šã—ã¦ã„ã‚‹CodePipelineãŒèµ°ã‚‹  äº‹å‰ã«CodePipelineä¸Šã§çµ„ã‚“ã§ã„ã‚‹ãƒ•ãƒ­ãƒ¼ãŒå‹•ã   CodeBuildãŒèµ·å‹•ã—ï¼ŒDocker Imageã®BuildãŒè¡Œã‚ã‚Œï¼ŒImageã‚’ECRã«pushã—ã¾ã™ Step FunctionsãŒèµ·å‹•ã—ï¼Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒèµ°ã‚‹  ECRã«ç™»éŒ²ã—ã¦ã„ã‚‹Imageã‚’ä½¿ã£ã¦ï¼ŒSageMaker ProcessingJobãŒå‹•ã     ç´°ã‹ã„éƒ¨åˆ†ã§è¨€ã†ã¨ï¼ŒAWS_ACCOUNT_ID, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEYãªã©ã®æ©Ÿå¯†æƒ…å ±ã¯ï¼Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢(AWS Systems Manager Parameter Store)ã¸ç™»éŒ²ã—ã¦ãŠãï¼Œãã‚Œã‚’å‚ç…§ã™ã‚‹å½¢ã§ä½¿ã†ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼    AWS Serverless Application Model AWS Serverless Application Model (SAM)ã¨ã¯AWSã§ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç°¡å˜ã«æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãªã‚Šã¾ã™ï¼CloudFormationã®æ‹¡å¼µã§CloudFormationã§åˆ©ç”¨ã§ãã‚‹ãƒªã‚½ãƒ¼ã‚¹ã¯SAMã§ã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼YAMLã‚‚ã—ãã¯JSONå½¢å¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ã£ã¦ç°¡å˜ã«ç’°å¢ƒæ§‹ç¯‰ãŒã§ãã¾ã™ã—ï¼ŒCLIã‚‚æä¾›ã•ã‚Œã¦ã¾ã™ï¼è©³ã—ãã¯å…¬å¼ã®ã€ŒAWS Serverless Application Model (AWS SAM) ã¨ã¯ã€ã‚’è¦‹ã¦é ‚ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\nè¨­å®šã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯2ã¤ã‚ã‚Šã¾ã™ï¼\n samconfig.toml template.yaml  devç’°å¢ƒã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¦ã„ãã¨ï¼Œ\n  samconfig.toml\n samconfig.toml version = 0.1 [default] [default.deploy.parameters] stack_name = \u0026quot;dev-sample-codepipeline\u0026quot; s3_bucket = \u0026quot;aws-sam-cli-managed-samclisourcebucket-dev-sample-codepipeline\u0026quot; s3_prefix = \u0026quot;dev-sample-codepipeline\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; confirm_changeset = true capabilities = \u0026quot;CAPABILITY_IAM\u0026quot; disable_rollback = true    ã“ã¡ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«devã¨prodã®ä¸¡æ–¹ã®è¨­å®šã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒï¼Œä»Šå›ã¯ç’°å¢ƒæ¯ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†ã‘ã¦ã„ã¾ã™ï¼ï¼ˆå¾Œè¿°ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ä¸€ç·’ã«ç®¡ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒï¼Œå¾®å¦™ã«ç’°å¢ƒæ¯ã§å¤‰æ•°ãŒé•ã†éƒ¨åˆ†ã‚‚ã‚ã‚‹ã®ã§ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚åˆ†ã‘ã¦ç®¡ç†ã—ãŸæ–¹ãŒè‰¯ã„ã‹ãªã¨æ€ã„åˆ†ã‘ã¦ã„ã¾ã™ï¼‰ [default.deploy.parameters]ã¯sam deployã‚³ãƒãƒ³ãƒ‰ãŒå®Ÿè¡Œã•ã‚ŒãŸæ™‚ã«æ¸¡ã•ã‚Œã‚‹å¼•æ•°ã«ãªã‚Šã¾ã™ æ³¨æ„ã¨ã—ã¦ã¯ï¼Œs3_bucketã¯äº‹å‰ã«ä½œæˆã—ã¦ãŠã‹ãªã„ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸéš›ã«S3 Bucket does not exist.ã¨ã„ã£ãŸã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ï¼  S3ã«ã¯ï¼Œãƒ“ãƒ«ãƒ‰ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒªã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã™      template.yaml\n template.yaml AWSTemplateFormatVersion: \u0026quot;2010-09-09\u0026quot; Transform: AWS::Serverless-2016-10-31 Description: \u0026gt; Create Resource - StepFunctions - EventBridge Parameters: EnvironmentVariable: Description: ç’°å¢ƒå¤‰æ•° Type: String Default: dev VersionVariable: Description: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå· Type: String Default: ver1 StepFunctionsExecutionRole: Description: Step Functionsã®å®Ÿè¡Œãƒ­ãƒ¼ãƒ« Type: String Default: arn:aws:iam::\u0026lt;AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆID\u0026gt;:role/StepFunctionsExecutionRole SageMakerProcessingImage: Description: SageMakerã®ProcessingJobã‚’å‹•ã‹ã™Image Type: String Default: \u0026lt;AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆID\u0026gt;.dkr.ecr.ap-northeast-1.amazonaws.com/\u0026lt;ECRã®ãƒªãƒã‚¸ãƒˆãƒªå\u0026gt;:latest Resources: # =======Step Functions for ProcessingJob======== # DevMLPipelinesStateMachine: Type: AWS::Serverless::StateMachine Properties: Name: !Sub ${EnvironmentVariable}-sample-ml-pipelines-${VersionVariable} DefinitionUri: ../../statemachine/sample-ml-pipelines-ver1.asl.json DefinitionSubstitutions: ProcessingJobRole: !Ref StepFunctionsExecutionRole ProcessingImage: !Ref SageMakerProcessingImage ProcessingEnvironment: !Ref EnvironmentVariable Role: !Ref StepFunctionsExecutionRole Events: Schedule: Type: Schedule Properties: Description: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ Enabled: False Name: !Sub ${EnvironmentVariable}-sample-ml-pipelines-${VersionVariable} Schedule: \u0026quot;cron(0 16 * * ? *)\u0026quot;    JSONã§ã¯ãªãï¼ŒYAMLå½¢å¼ã§æ›¸ã‘ã‚‹ã®ã§è‰¯ãã§ã™ã­ï¼ Parametersãƒ–ãƒ­ãƒƒã‚¯ã§ã¯ï¼Œå€¤ã‚’å¤‰æ•°åŒ–ã§ãã‚‹ã®ã§ï¼Œå…±é€šè¨­å®šã‚„dev/prodã§å‹•çš„ã«å¤‰ã‚ã‚‹éƒ¨åˆ†ã ã£ãŸã‚Šã‚’æ›¸ã„ã¦ãŠãã¨ä½¿ã„å›ã—ã‚„ã™ã„ã‹ãªã¨æ€ã„ã¾ã™ï¼ Resourcesãƒ–ãƒ­ãƒƒã‚¯ã§ã¯ï¼ŒParametersãƒ–ãƒ­ãƒƒã‚¯ã§å®šç¾©ã—ãŸå¤‰æ•°ã‚’!Refã‚„!Subã§ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ï¼  !Subã¯å€¤ã®ä¸€éƒ¨ã«å¤‰æ•°ã‚’ä½¿ç”¨ã—ãŸã„æ™‚ã«ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ï¼   Roleã®è¨­å®šã‚‚ã§ãã¾ã™ãŒï¼Œä»Šå›ã¯äº‹å‰ã«è¨­å®šã—ã¦ãŠã„ãŸIAMãƒ­ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼ ä»Šå›ã¯Step Functionsã ã‘ã‚’å®šç¾©ã—ãŸã®ã§ï¼Œå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«sample-ml-pipelines-ver1.asl.jsonã‚’æ¬¡ã«è¦‹ã¦ã„ãã¾ã™ï¼    sample-ml-pipelines-ver1.asl.json\n sample-ml-pipelines-ver1.asl.json { \u0026quot;Comment\u0026quot;: \u0026quot;Sample ML pipelines\u0026quot;, \u0026quot;StartAt\u0026quot;: \u0026quot;SageMaker-Hello-World\u0026quot;, \u0026quot;States\u0026quot;: { \u0026quot;SageMaker-Hello-World\u0026quot;: { \u0026quot;Comment\u0026quot;: \u0026quot;Hello Worldã‚’å‡ºåŠ›ã™ã‚‹\u0026quot;, \u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::sagemaker:createProcessingJob.sync\u0026quot;, \u0026quot;Parameters\u0026quot;: { \u0026quot;RoleArn\u0026quot;: \u0026quot;${ProcessingJobRole}\u0026quot;, \u0026quot;ProcessingJobName.$\u0026quot;: \u0026quot;States.Format('{}', $$.Execution.Name)\u0026quot;, \u0026quot;AppSpecification\u0026quot;: { \u0026quot;ImageUri\u0026quot;: \u0026quot;${ProcessingImage}\u0026quot;, \u0026quot;ContainerEntrypoint\u0026quot;: [ \u0026quot;python3\u0026quot;, \u0026quot;/opt/program/src/hello.py\u0026quot; ] }, \u0026quot;ProcessingResources\u0026quot;: { \u0026quot;ClusterConfig\u0026quot;: { \u0026quot;InstanceCount\u0026quot;: 1, \u0026quot;InstanceType\u0026quot;: \u0026quot;ml.t3.medium\u0026quot;, \u0026quot;VolumeSizeInGB\u0026quot;: 10 } }, \u0026quot;Environment\u0026quot;: { \u0026quot;PYTHON_ENV\u0026quot;: \u0026quot;${ProcessingEnvironment}\u0026quot; }, \u0026quot;StoppingCondition\u0026quot;: { \u0026quot;MaxRuntimeInSeconds\u0026quot;: 86400 } }, \u0026quot;Catch\u0026quot;: [ { \u0026quot;ErrorEquals\u0026quot;: [ \u0026quot;States.ALL\u0026quot; ], \u0026quot;Next\u0026quot;: \u0026quot;FailState\u0026quot; } ], \u0026quot;End\u0026quot;: true }, \u0026quot;FailState\u0026quot;: { \u0026quot;Type\u0026quot;: \u0026quot;Fail\u0026quot;, \u0026quot;Cause\u0026quot;: \u0026quot;Error\u0026quot;, \u0026quot;Error\u0026quot;: \u0026quot;Error\u0026quot; } } }    JSONå½¢å¼ã§æ›¸ã‹ã‚ŒãŸStep Functionsã®å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã«ãªã‚Šã¾ã™ï¼ Hello Worldã‚’å‡ºåŠ›ã™ã‚‹ã ã‘ã®å†…å®¹ã«ãªã£ã¦ã„ã¾ã™ãŒï¼Œãã‚Œã‚’SageMaker ProcessingJobã§å‹•ã‹ã—ã¦ã„ã¾ã™ï¼ä»Šå›ã¯å˜ç´”ãªå‡¦ç†ã§ã™ãŒï¼ŒMLãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã“ã“ã«å®Ÿè£…ã™ã‚Œã°ï¼Œãã®å†…å®¹ãŒSAMã§æ§‹ç¯‰ã•ã‚Œã¾ã™ï¼ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã¯ï¼ŒStep Functionsã®Workflow studioã§ç›´æ„Ÿçš„ãªGUIã§ç°¡å˜ã«ä½œæˆã§ãã‚‹ã®ã§ï¼Œãã‚Œã§ä½œæˆã—ãŸå¾Œã«JSONã®å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’DLã™ã‚Œã°åŒã˜ã‚‚ã®ã‚’æœ¬ç•ªç’°å¢ƒç”¨ã«ã‚µã‚¯ãƒƒã¨æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ ProcessingJobã‚’å‹•ã‹ã™Imageã¯CodeBuildæ™‚ã«ECRã«pushã—ãŸã‚‚ã®ã‚’ä½¿ã£ã¦ã„ã¾ã™ï¼ ã¾ãŸï¼ŒProcessingJobNameã¯ä¸€æ„ã§ãªã„ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ï¼ŒContextã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®$$.Execution.Nameã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼    AWS CodePipeline CodePipelineã¯è¤‡æ•°ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¨ã„ã†ã‚‚ã®ãŒç”¨æ„ã•ã‚Œã¦ã„ã¦ï¼Œãã‚Œã‚’ç¹‹ãåˆã‚ã›ã¦ä¸€é€£ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—CI/CDã‚’è‡ªå‹•åŒ–ã™ã‚‹ã‚‚ã®ã«ãªã‚Šã¾ã™ï¼è©³ã—ãã¯å…¬å¼ã®ã€ŒAWS CodePipeline ã¨ã¯ã€ã‚’è¦‹ã¦é ‚ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\nä»Šå›ã®å ´åˆï¼ŒSourceâ†’Buildâ†’Execute(Invoke)ã®ã‚ˆã†ãªæµã‚Œã«ãªã£ã¦ã„ã¾ã™ï¼\n Source: Githubã®ãƒ–ãƒ©ãƒ³ãƒãƒãƒ¼ã‚¸ãƒˆãƒªã‚¬ãƒ¼ã§èµ·å‹•ã™ã‚‹ Build: Docker Imageã®Buildã¨ECRã¸ã®Pushã‚’è¡Œã† Execute(Invoke): Step Functionsã‚’èµ·å‹•ã™ã‚‹   å‡¦ç†ãŒæ­£å¸¸ã«çµ‚äº†ã™ã‚‹ã¨ï¼ŒStep Functionsã®å®Ÿè¡Œçµæœã¨CloudWatch Logsã®ãƒ­ã‚°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼   CodePipelineã‚’å‹•ã‹ã™æ™‚ã®æ³¨æ„ã¨ã—ã¦ã¯ï¼Œæ¨©é™å‘¨ã‚Šã®ã‚¨ãƒ©ãƒ¼ãŒã‚ˆãç™ºç”Ÿã™ã‚‹ã®ã§CodePipelineã‹ã‚‰ä½•ã‚’å‹•ã‹ã™å¿…è¦ãŒã‚ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å‹•ã‹ã™ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ¨©é™ã‚’ä¸ãˆã¦ã‚„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼  ä»Šå›ã®å ´åˆ:  CodePipelineã§ã¯ï¼ŒCodeBuildã¨Step Functionsã‚’å‹•ã‹ã™ãŸã‚ã®ãƒãƒªã‚·ãƒ¼ãŒå¿…è¦ CodeBuildã§ã¯ï¼ŒECRã¨SystemsManagerã‚’æ“ä½œã™ã‚‹ãŸã‚ã®ãƒãƒªã‚·ãƒ¼ãŒå¿…è¦ Step Functionsã§ã¯ï¼ŒSageMakerã®æ“ä½œã¨ECRã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¡Œã†ãƒãƒªã‚·ãƒ¼ãŒå¿…è¦   ã‚¨ãƒ©ãƒ¼å‘¨ã‚Šã¯å‚è€ƒã«æŒ™ã’ãŸãƒ–ãƒ­ã‚°ãŒå½¹ã«ç«‹ã¡ã¾ã—ãŸï¼    ãŠã‚ã‚Šã« ä»Šå›ã¯Github Actionsã¨CodePipelineã‚’ä½¿ã£ã¦Step Functionsã‚’å‹•ã‹ã™CICDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ãŸãŠè©±ã§ã—ãŸï¼\nStep Functionsã®ä¸­èº«ã‚’MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã™ã‚Œã°ï¼ŒGithub Actionsã®PR Openã¨ãƒ–ãƒ©ãƒ³ãƒãƒãƒ¼ã‚¸ã‚’ãƒˆãƒªã‚¬ãƒ¼ã¨ã—ã¦ï¼ŒCodePipelineãŒèµ°ã‚‹ã“ã¨ã§ï¼Œä¸€é€£ã®æµã‚Œã‚’CICDã§å®Ÿç¾ã§ãã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼\nã“ã“ã«ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã—ãŸã‚Šï¼Œä¾‹ãˆã°ï¼ŒECSã§ML-APIãŒå‹•ã„ã¦ã„ã‚‹å ´åˆã«ã¯ï¼ŒStep Functionsã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒæ­£å¸¸çµ‚äº†ã—ãŸå¾Œã«ï¼Œæ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ã‚’å…¥ã‚Œã¦ECSã®ã‚¿ã‚¹ã‚¯å®šç¾©ã¨ã‚µãƒ¼ãƒ“ã‚¹ã®æ›´æ–°ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§ï¼Œãƒ‡ãƒ—ãƒ­ã‚¤ã¾ã§æŒã£ã¦ã„ãã“ã¨ãŒã§ãã‚‹ã‹ãªã¨æ€ã„ã¾ã™ï¼\nã‚‚ã†å°‘ã—ç™ºå±•ã•ã›ã‚‹ã“ã¨ã§ã‚ˆã‚Šè‰¯ã„é–‹ç™ºä½“é¨“ãŒç”Ÿã¿å‡ºã™ã“ã¨ãŒã§ãã‚‹ã®ã¨ï¼ŒMLOpsã®æˆç†Ÿåº¦ã‚‚ä¸ŠãŒã£ã¦é‹ç”¨ã®è‡ªå‹•åŒ–ã‚‚ä¸€æ­©å‰é€²ã™ã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ï¼\nå‚è€ƒ  CodeBuildãƒ»CodePipelineã‚’ä½¿ã£ã¦ãƒ‡ãƒªãƒãƒªãƒ¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å°å…¥ï¼ˆAWSã§Webã‚¢ãƒ—ãƒªæ§‹ç¯‰ part3ï¼‰ Solve - Policy has Prohibited field Principal AWS Error  ","date":"2022-07-18","permalink":"https://masatakashiwagi.github.io/portfolio/post/implement-cicd-github-actions-codepipeline-for-stepfunctions/","tags":["Dev","AWS","MLOps"],"title":"Github Actionsã¨CodePipelineã‚’ä½¿ã£ã¦Step Functionsã‚’å‹•ã‹ã™CI/CDã‚’æ§‹ç¯‰"},{"content":"ã¯ã˜ã‚ã« 2é€±é–“ãã‚‰ã„é–“ãŒç©ºãã¾ã—ãŸãŒï¼Œå…ˆæœˆã®4æœˆ19æ—¥ã«ã“ã¡ã‚‰ã®MLOpså‹‰å¼·ä¼šã§ç™»å£‡ã•ã›ã¦é ‚ã„ãŸæ™‚ã®æ„Ÿæƒ³ãƒã‚¨ãƒ ã‚’æ›¸ã“ã†ã¨æ€ã„ã¾ã™ï¼\nã¨ã“ã‚ã§MLOpså‹‰å¼·ä¼šã¨ã¯ï¼Ÿ\nã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ã®èª¬æ˜ã‚’å¼•ç”¨ã•ã›ã¦è²°ã†ã¨\u0026hellip;\n AI/æ©Ÿæ¢°å­¦ç¿’æŠ€è¡“ã‚’ãƒ“ã‚¸ãƒã‚¹é©ç”¨ã—ãŸå¾Œã«å¿…è¦ã¨ãªã‚‹å¤šãã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã«ã¤ã„ã¦ç†è§£ã‚’æ·±ã‚ã¦ã„ãäº‹ã€ã¾ãŸæ¥­ç•Œæ¨ªæ–­ã®æŠ€è¡“ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ä½œã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\nã¾ãŸã€å…ˆé§†ã‘ã¦MLOpsã«å–ã‚Šçµ„ã¾ã‚Œã¦ã„ã‚‹äº‹ä¾‹ã®è¬›æ¼”ãªã©ã€MLOpsã«é–¢ã™ã‚‹æœ€å…ˆç«¯ã®æƒ…å ±ã‚’å…±æœ‰ã™ã‚‹ä¼šã‚’é–‹å‚¬ã—ã¦ã„ãã¾ã™ã€‚\n æ—¥æœ¬ã§ã®MLOpsã«é–¢ã™ã‚‹äº‹ä¾‹ãªã©ã‚’ãã‚Œã‚‰ã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹æ–¹ã€…ã¨å…±æœ‰ã™ã‚‹ä¼šã§ï¼Œä»Šå›åƒ•ã¯ä»¥å‰ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã§ç´¹ä»‹ã—ãŸã€ŒMLOps Practicesã€ã¨ã„ã†æ—¥æœ¬ã§ã®MLOpsã®äº‹ä¾‹ã‚’åé›†ã—ã¦æ•´ç†ã—ãŸWebã‚µã‚¤ãƒˆã‚’å…¬é–‹ã—ãŸã¨ã„ã†å†…å®¹ã§ç™»å£‡ã•ã›ã¦é ‚ãã¾ã—ãŸï¼\nã“ã®ãƒ–ãƒ­ã‚°ã‚’æ›¸ã„ã¦Twitterã§ç™ºä¿¡ã—ãŸã¨ã“ã‚æƒ³å®šä»¥ä¸Šã®åå¿œã‚’é ‚ã„ã¦ï¼Œãã®ä¸­ã§é‹å–¶ã®æ–¹ã‹ã‚‰ãŠå£°ãŒã‘é ‚ã„ã¦ç™»å£‡ã™ã‚‹æµã‚Œã«ãªã‚Šã¾ã—ãŸï¼\n ç™»å£‡å‰ã¾ã§ ã¾ãšç™»å£‡ã¾ã§ã®è©±ã‚’ã—ã¦ãŠãã¨ï¼ŒãŠè©±ã‚’é ‚ã„ã¦ã‹ã‚‰ç™»å£‡æ—¥ã¾ã§ã¯ååˆ†æ™‚é–“ãŒã‚ã£ãŸã‚‚ã®ã®ï¼Œä¸åº¦è‚²ä¼‘ä¸­ã ã£ãŸã“ã¨ã‚‚ã‚ã‚Šï¼Œè‚²å…ã‚„ã‚‰å®¶äº‹ã‚„ã‚‰ã§æ€ã£ãŸã‚ˆã‚Šã‚‚ã‚ã£ã¨ã„ã†é–“ã«1æ—¥ãŒéãã¦è¡Œã£ã¦ï¼Œè³‡æ–™ã®æ§‹æˆã ã£ãŸã‚Šã‚¹ãƒ©ã‚¤ãƒ‰ã®ä½œæˆã ã£ãŸã‚Šã®æ™‚é–“ã‚’ç¢ºä¿ã™ã‚‹ã®ãŒé›£ã—ãï¼Œæ°—ã¥ã‘ã°ç™»å£‡æ—¥ã¾ã§ã‚ã¨1é€±é–“ã«ãªã£ã¦ãŸæ™‚ã¯å°‘ã—ç„¦ã‚Šã¾ã—ãŸğŸ˜…\nã“ã®è¾ºã¯æ¯æ—¥å°‘ã—ã¥ã¤æ™‚é–“ã‚’ç¢ºä¿ã™ã‚Œã°è‰¯ã‹ã£ãŸãªãƒ¼ã¨è¨ˆç”»æ€§ã®ç„¡ã•ã‚’å®Ÿæ„Ÿã—ã¾ã—ãŸ\u0026hellip;ï¼ˆä½™è«‡ã§ã™ãŒï¼Œå®Ÿã¯å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã“ã¨ã«å¤¢ä¸­ã«ãªã£ã¦ã¦ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆã«å–ã‚Šæ›ã‹ã‚Œã¦ã¾ã›ã‚“ã§ã—ãŸwï¼‰\nã§ã‚‚ï¼Œæˆ‘ãªãŒã‚‰ç”Ÿå¾Œ1~2ãƒ¶æœˆã®å­ä¾›ãŒå±…ã‚‹ä¸­ã§å¦»ã¨äº¤ä»£ã—ãªãŒã‚‰ã®è‚²å…ã¨ã¯ã„ãˆï¼Œç™»å£‡æ‰¿è«¾ã—ã¦è³‡æ–™ä½œæˆã¨ã‹ã—ã¦é ‘å¼µã£ãŸãªãƒ¼ã¨æ€ã„ã¾ã—ãŸç¬‘\nç™»å£‡ã—ã¦ã¿ã¦ å½“æ—¥ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§18æ™‚é–‹å‚¬ã ã£ãŸã®ã§ï¼Œãã‚Œã¾ã§ã«å­ä¾›ã‚’ãŠé¢¨å‘‚ã«å…¥ã‚Œã¦äº‹å‰æº–å‚™ã‚’çµ‚ãˆãŸã‚Šï¼Œç™»å£‡ä¸­ã®è‚²å…ã¯å¦»ã«ãŠé¡˜ã„ã—ãŸã‚Šã—ã¦å¯¾å¿œã—ã¦ã„ã¾ã—ãŸï¼\nå°ã•ã„ãŠå­ã•ã‚“ãŒå±…ã‚‹å®¶åº­ã¯ä¼¼ãŸã‚ˆã†ãªæ„Ÿã˜ãªã®ã‹æ°—ã«ãªã£ãŸã®ã§ï¼Œèª°ã‹ã¾ãŸãŠè©±ã—èã‹ã›ã¦ä¸‹ã•ã„ãƒ¼ï¼\nã•ã¦ã•ã¦å®Ÿéš›ã«ç™»å£‡ã—ãŸæ„Ÿæƒ³ã¨ã—ã¦ã¯ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç™ºè¡¨ã¯ã“ã¡ã‚‰ãŒä¸€æ–¹çš„ã«å–‹ã‚‹æ„Ÿã˜ã«ãªã‚‹ã®ã§ï¼Œè´ã„ã¦ãã‚Œã¦ã„ã‚‹äººã®é¡”ã‚„åå¿œã‚’è¦‹ã‚‹ã“ã¨ãŒã§ããªã„ã®ãŒæ®‹å¿µã ã—é›£ã—ã„ãªã¨æ„Ÿã˜ã¾ã—ãŸï¼è‡ªå·±ç´¹ä»‹ã®ä¸€ç™ºç›®ã«ãƒœã‚±ã‚’ã‹ã¾ã—ãŸã®ã§ï¼Œçš†ã•ã‚“ã®å¤±ç¬‘å…·åˆã‚’è¦‹ã‚Œãªã‹ã£ãŸã®ã¯æ®‹å¿µã§ã™ğŸ¤£\nã‚ã¨ã©ã†ã—ã¦ã‚‚æ·¡ã€…ã¨è©±ã™æ„Ÿã˜ã«ãªã‚‹ã®ã§ï¼Œè©±ã™ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒé€Ÿã‹ã£ãŸã‚Šã¨ã‹ã«æ°—ã¥ãã«ãã„ã¨ã‚‚æ€ã„ã¾ã—ãŸï¼ç™ºè¡¨ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã—ãŸã„ã‘ã©ï¼Œå°ã•ã„å­ä¾›ãŒå±…ã‚‹ã¨ä»Šå›ã®ã‚ˆã†ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§åŠ©ã‹ã‚‹ãªã¨ã‚‚æ€ã„ï¼Œé›£ã—ã„ã§ã™ã­ï¼\nå†…å®¹ã«é–¢ã—ã¦ã¯ï¼Œå®Ÿå‹™ã§ã®å–ã‚Šçµ„ã¿ã¨ã¯å°‘ã—é•ã†éƒ¨åˆ†ãŒãƒ¡ã‚¤ãƒ³ã«ãªã‚‹ã®ã§ï¼Œè´ã„ã¦ã„ã‚‹äººã®èˆˆå‘³ã¨ã—ã¦ã©ã†ãªã®ã‹ãªï¼Ÿã¨æ€ã„ï¼ŒãŠã¾ã‘ã¨ã—ã¦å®Ÿå‹™ã§å–ã‚Šçµ„ã‚“ã§ã„ã‚‹äº‹ä¾‹ã‚‚è»½ãç´¹ä»‹ã™ã‚‹å½¢ã«ã—ã¾ã—ãŸï¼ãƒ¡ã‚¤ãƒ³ãƒ‘ãƒ¼ãƒˆã¯ç¶™ç¶šçš„ãªå–ã‚Šçµ„ã¿ãŒå¿…è¦ã¨ã•ã‚Œã‚‹MLOpsã«ãŠã„ã¦ï¼Œãã‚Œã‚‰ã«èˆˆå‘³ãŒã‚ã‚‹äººã«ã¨ã£ã¦ã©ã†ã‚†ã†ã®ã‚’å‚è€ƒã«ã™ã‚Œã°ã„ã„ã‹ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å½¢ã§æµ·å¤–ã®äº‹ä¾‹é›†ã‚’ç´¹ä»‹ã—ã¤ã¤ï¼Œæ—¥æœ¬ç‰ˆã§ãã†ã„ã£ãŸäº‹ä¾‹é›†ãŒãªã„ã®ã§ï¼Œãã‚Œã‚’ä½œã‚ŠãŸã„æ°—æŒã¡ã§Websiteã‚’ä½œæˆã—ã¦å…¬é–‹ã—ãŸè©±ã‚’ã™ã‚‹æµã‚Œã«ã—ã¾ã—ãŸï¼å‚™å¿˜éŒ²ãŒã¦ã‚‰ã«ç”¨æ„ã—ãŸã‚‚ã®ã§è‰²ã€…ã¨åéŸ¿é ‚ã‘ãŸã®ã¯å¬‰ã—ã‹ã£ãŸã§ã™ï¼\nã¾ãŸï¼Œç™ºè¡¨å¾Œã®è³ªå•ã‚„ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœã‚’è¦‹ã‚‹é™ã‚Šï¼Œå®Ÿéš›ã«çš†ã•ã‚“ã‹ã‚‰ã‚‚å¥½æ„çš„ãªå†…å®¹ãŒå¤šãå¬‰ã—ã„æ°—æŒã¡ã§ã—ãŸï¼ğŸ˜†ï¼ˆå—ã‘ãŸè³ªå•ã‚’ãƒ¡ãƒ¢ã—ã¦ãŠã‘ã°è‰¯ã‹ã£ãŸã®ã§ã™ãŒï¼Œã—ã¦ã„ãªã‹ã£ãŸã®ã§ã‚‚ã—éŒ²ç”»ãŒå…¬é–‹ã•ã‚ŒãŸã‚‰ã“ã®ãƒ–ãƒ­ã‚°ã«å›ç­”ã™ã‚‹å½¢ã§è¿½è¨˜ã—ãŸã„ã¨æ€ã„ã¾ã™ï¼ï¼‰\nãŠã‚ã‚Šã« è‡ªåˆ†è‡ªèº«ã¾ã ã¾ã æº€è¶³ã—ãŸMLOpsã®å–ã‚Šçµ„ã¿ãŒå‡ºæ¥ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ \u0026amp; çŸ¥ã‚‰ãªã„éƒ¨åˆ†ã‚‚å¤šã„ã®ã§ï¼Œä»–ç¤¾ã•ã‚“ã®äº‹ä¾‹ã‚’å‚è€ƒã«ã—ãªãŒã‚‰ï¼Œå€‹äººçš„ã«é–¢å¿ƒãŒå¼·ã„ã€Œæ©Ÿæ¢°å­¦ç¿’ã®ç¤¾ä¼šå®Ÿè£…ã¨ç¶™ç¶šçš„ãªä»•çµ„ã¿ä½œã‚Šã€ã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦è¡Œã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\nãã—ã¦ï¼Œæ—¥æœ¬ã®MLOpsã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ç•Œéšˆã‚’å°‘ã—ã§ã‚‚ç››ã‚Šä¸Šã’ãŸã„æ°—æŒã¡ã‹ã‚‰ï¼Œã“ã®åº¦MLOpså‹‰å¼·ä¼šã®é‹å–¶ã«å‚åŠ ã•ã›ã¦é ‚ãã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼æƒ…å ±ç™ºä¿¡ã‚„ä¼ç”»ãªã©é€²ã‚ã¦è¡Œã‘ã‚Œã°ã¨æ€ã†ã®ã§ï¼Œä»Šå¾Œã¨ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ğŸ™\nå‚è€ƒ  MLOpså‹‰å¼·ä¼š  ","date":"2022-05-04","permalink":"https://masatakashiwagi.github.io/portfolio/post/my-thoughts-on-speaking-at-the-mlops-study/","tags":["Poem"],"title":"MLOpså‹‰å¼·ä¼šã§ç™»å£‡ã—ãŸæ„Ÿæƒ³"},{"content":"ã¯ã˜ã‚ã« Continuous Machine Learning (CML) ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®CIãƒ„ãƒ¼ãƒ«ã‚’å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å°å…¥ã—ãŸã®ã§ï¼Œãã®ç´¹ä»‹ã‚’ã—ã‚ˆã†ã¨æ€ã„ã¾ã™ï¼\næ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ãƒ†ã‚¹ãƒˆã‚’è€ƒãˆã‚‹æ™‚ã«ï¼Œå¤§ãã3ã¤ã‚ã‚‹ã¨æ€ã£ã¦ã„ã¾ã™ï¼\n ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒ†ã‚¹ãƒˆ: å˜ä½“ãƒ†ã‚¹ãƒˆã‚„çµåˆãƒ†ã‚¹ãƒˆãªã©ã‚³ãƒ¼ãƒ‰ãŒæ„å›³é€šã‚Šã®æŒ™å‹•ã‚’ç¤ºã™ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ãƒ†ã‚¹ãƒˆ  ãƒ„ãƒ¼ãƒ«: pytest, unittest \u0026hellip;ãªã©   æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ï¼Œè©•ä¾¡æŒ‡æ¨™ã§ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ãªã©ã‚’ç¢ºèªã™ã‚‹ãƒ†ã‚¹ãƒˆ  ãƒ„ãƒ¼ãƒ«: CML (with DVC) \u0026hellip;ãªã©   ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ: ãƒ‡ãƒ¼ã‚¿ãŒæƒ³å®šã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ã„ã‚‹ã‹ï¼Œãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚„ç¯„å›²ãŒæ„å›³ã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ãªã©ã‚’ç¢ºèªã™ã‚‹ãƒ†ã‚¹ãƒˆ  ãƒ„ãƒ¼ãƒ«: dbt, Dataform \u0026hellip;ãªã©    ã“ã®ã†ã¡ä»Šå›ã¯ï¼Œã€Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆã€ã«ç€ç›®ã—ã¦ã“ã‚Œã‚’ã©ã®ã‚ˆã†ã«å®Ÿæ–½ã™ã‚‹ã‹ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ï¼\nâ€» ä»Šå›ï¼ŒDVCã¯ä½¿ã£ã¦ã„ã¾ã›ã‚“ï¼æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã™ã‚‹éƒ¨åˆ†ãŒã‹ãªã‚Šå¤§ãã„ã®ã§ï¼ŒDVCã¨çµ„ã¿åˆã‚ã›ã¦å®Ÿæ–½ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„ã§ã™ãŒï¼Œä»Šå›ã¯ç°¡æ˜“çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã¦ï¼ŒCMLã‚’å®Ÿæ–½ã—ã¦ã„ã¾ã™ï¼\nContinuous Machine Learning (CML) ã¨ã¯ï¼Ÿ Continuous Machine Learning (CML) ã¯ï¼ŒIterative.aiãŒé–‹ç™ºã—ã¦ã„ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®CI/CDã‚’å®Ÿç¾ã™ã‚‹OSSã§ã‚ã‚Šï¼Œç‰¹å¾´ã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç‚¹ãŒã‚ã‚Šã¾ã™ï¼\n ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡ã®çµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆï¼ˆmarkdownå½¢å¼ï¼‰ã«ã—ã¦è‡ªå‹•ç”Ÿæˆã§ãã‚‹ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚„å›³ãªã©ï¼‰ Github Actionsã¨é€£æºã—ã¦ï¼ŒPull Requestsæ™‚ã«è‡ªå‹•çš„ã«å®Ÿè¡Œã™ã‚‹ä»•çµ„ã¿ ä»»æ„ã®ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§å®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½  ã“ã‚Œã¯ä¾‹ãˆã°ï¼Œæ¬¡ã®ã‚ˆã†ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ã‚µãƒãƒ¼ãƒˆã«ãªã‚‹ã¨æ€ã„ã¾ã™ï¼\n PoCã§ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãŒä½œæˆã—ãŸã‚³ãƒ¼ãƒ‰ã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã«è¼‰ã›ãŸéš›ã«ï¼Œãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ã‚’ã©ã®ã‚ˆã†ã«ç¢ºèªã™ã‚‹ã‹ï¼Ÿ ãƒ¢ãƒ‡ãƒ«ãŒå‰å›ã‹ã‚‰å‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ã‚’ã©ã®ã‚ˆã†ã«ç¢ºèªã™ã‚‹ã‹ï¼Ÿï¼ˆã“ã‚Œã«ã¤ã„ã¦ã¯DVCã¨ã®é€£æºã‚‚å¿…è¦ï¼‰ ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã®éš›ã«ã‚‚åŒã˜ã‚ˆã†ãªãƒã‚§ãƒƒã‚¯ãŒè¡Œã‚ã‚Œã‚‹ã®ã‹ï¼Ÿ etc\u0026hellip;  CMLã¯PRãƒ™ãƒ¼ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡ã‚’è¡Œã„ï¼Œé©åˆ‡ãªæ„æ€æ±ºå®šã«ç¹‹ã’ã‚‹ã®ã«å½¹ç«‹ã¤ãƒ„ãƒ¼ãƒ«ã ã¨æ€ã„ã¾ã™ï¼\nå€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å°å…¥ å‰å›ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã®ã“ã¡ã‚‰ã®ç« ã§å°‘ã—è§¦ã‚ŒãŸéƒ¨åˆ†ã«ãªã‚Šã¾ã™ï¼\næ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚’è¡Œã£ã¦ã„ã‚‹tasks.pyã®if __name__ == \u0026quot;__main__\u0026quot;:ä»¥ä¸‹ãŒCMLç”¨ã«ç”¨æ„ã—ãŸã‚³ãƒ¼ãƒ‰ã«ãªã‚Šã¾ã™ï¼\n if __name__ == \"__main__\":ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’æŠœç²‹ if __name__ == \u0026quot;__main__\u0026quot;: def plot_yy(y_valid, y_pred, metrics, savepath): \u0026quot;\u0026quot;\u0026quot;Vizualize the results using yy-plot \u0026quot;\u0026quot;\u0026quot; y_max = np.max(y_valid) y_min = np.min(y_valid) # calculate max and min of y_pred predict_y_max = np.max(y_pred) predict_y_min = np.min(y_pred) # use the smallest and largest value of either of both y_valid and y_pred # as the range of the vertical axis horizontal axis axis_max = max(y_max, predict_y_max) axis_min = min(y_min, predict_y_min) # margin of 5% of the length axis_max = axis_max + (axis_max - axis_min) * 0.05 axis_min = axis_min - (axis_max - axis_min) * 0.05 plt.figure(figsize=(10, 6)) plt.subplots_adjust(wspace=0.2, hspace=0.3) plt.scatter(y_pred, y_valid, c='r', s=50, zorder=2, edgecolors=(0, 0, 0), alpha=0.6) plt.plot([axis_min, axis_max], [axis_min, axis_max], c=\u0026quot;#1560bd\u0026quot;) plt.xlabel('Predict Values', fontsize=20) plt.ylabel('True Values', fontsize=20) plt.title(r'RMSE=%.2f' % (metrics), fontsize=15) plt.tick_params(labelsize=20) plt.tight_layout() plt.grid(True) plt.savefig(savepath, dpi=100, bbox_inches='tight', pad_inches=0.1) plt.close() def plot_residual(y_valid, y_pred, savepath): residual = y_pred - y_valid xmax = np.max(y_pred) + (np.max(y_pred) - np.min(y_pred)) * 0.05 xmin = np.min(y_pred) - (np.max(y_pred) - np.min(y_pred)) * 0.05 plt.figure(figsize=(10, 6)) plt.subplots_adjust(wspace=0.2, hspace=0.3) plt.scatter(y_pred, residual, c='r', s=50, zorder=2, edgecolors=(0, 0, 0), alpha=0.6) plt.hlines(y=0, xmin=xmin, xmax=xmax, color='#1560bd') plt.title('Residual Plot', fontsize=20) plt.xlabel('Predict Values', fontsize=20) plt.ylabel('Residuals', fontsize=20) plt.tick_params(labelsize=20) plt.tight_layout() plt.grid(True) plt.savefig(savepath, dpi=100, bbox_inches='tight', pad_inches=0.1) plt.close() params = { \u0026quot;model_id\u0026quot;: \u0026quot;sample_test\u0026quot;, \u0026quot;dataset_id\u0026quot;: \u0026quot;test_diabetes\u0026quot;, \u0026quot;features\u0026quot;: [\u0026quot;age\u0026quot;, \u0026quot;bmi\u0026quot;, \u0026quot;bp\u0026quot;, \u0026quot;s1\u0026quot;, \u0026quot;s2\u0026quot;, \u0026quot;s3\u0026quot;, \u0026quot;s4\u0026quot;, \u0026quot;s5\u0026quot;, \u0026quot;s6\u0026quot;], \u0026quot;target\u0026quot;: \u0026quot;target\u0026quot; } dataset_path = 'test/data/' + params['dataset_id'] + '.csv' df = pd.read_csv(dataset_path) result = train(df, params) rmse = result['metrics']['rmse'] # Record the metrics outfile = \u0026quot;data/metrics.txt\u0026quot; if not os.path.isdir(\u0026quot;data\u0026quot;): os.mkdir(\u0026quot;data\u0026quot;) with open(outfile, \u0026quot;w\u0026quot;) as f: f.write(\u0026quot;RMSE: \u0026quot; + f\u0026quot;{rmse:.2f}\u0026quot; + \u0026quot;\\n\u0026quot;) # Plot results y_valid = result['y_true'] y_pred = result['y_pred'] savepath_yy = \u0026quot;data/yy_plot.png\u0026quot; plot_yy(y_valid, y_pred, metrics=rmse, savepath=savepath_yy) savepath_residual = \u0026quot;data/residual_plot.png\u0026quot; plot_residual(y_valid, y_pred, savepath=savepath_residual)   ã“ã¡ã‚‰ã®ã‚³ãƒ¼ãƒ‰ãŒãƒ¬ãƒãƒ¼ãƒˆã«ã™ã‚‹å‡¦ç†ã«ãªã‚Šã¾ã™ï¼metrics.txtã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚çš„ã«ä½œæˆã—ï¼Œãã“ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çµæœã‚’æ›¸ãè¾¼ã¿ã¾ã™ï¼ã¾ãŸï¼Œä½œæˆã—ãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å®Ÿæ¸¬-äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆã®å›³ï¼ˆY-Yãƒ—ãƒ­ãƒƒãƒˆï¼‰ã‚„æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆã®å›³ã‚’pngãƒ•ã‚¡ã‚¤ãƒ«ã§ã“ã¡ã‚‰ã‚‚ä¸€æ™‚çš„ã«ä¿å­˜ã—ï¼Œãƒ¬ãƒãƒ¼ãƒˆã«å‡ºåŠ›ã—ã¾ã™ï¼\n# Record the metrics outfile = \u0026quot;data/metrics.txt\u0026quot; if not os.path.isdir(\u0026quot;data\u0026quot;): os.mkdir(\u0026quot;data\u0026quot;) with open(outfile, \u0026quot;w\u0026quot;) as f: f.write(\u0026quot;RMSE: \u0026quot; + f\u0026quot;{rmse:.2f}\u0026quot; + \u0026quot;\\n\u0026quot;) # Plot results y_valid = result['y_true'] y_pred = result['y_pred'] savepath_yy = \u0026quot;data/yy_plot.png\u0026quot; plot_yy(y_valid, y_pred, metrics=rmse, savepath=savepath_yy) savepath_residual = \u0026quot;data/residual_plot.png\u0026quot; plot_residual(y_valid, y_pred, savepath=savepath_residual)  ãƒ¬ãƒãƒ¼ãƒˆã«å‡ºåŠ›ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã§ããŸã‚‰ï¼ŒCMLã‚’ä½¿ã†ãŸã‚ã«cml.yamlãƒ•ã‚¡ã‚¤ãƒ«ã‚’.github/workflowsä»¥ä¸‹ã«ä½œæˆã—ã¾ã™ï¼å…¬å¼ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’å‚è€ƒã«ã—ã¦ã‚‚è‰¯ã„ã¨æ€ã„ã¾ã™ï¼\nä»¥ä¸‹ã¯ï¼Œä»Šå›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å®Ÿè¡Œã—ãŸCMLã«ãªã‚Šã¾ã™ï¼\nname: train-my-model on: push: paths: - 'async-processing/app/consumer/tasks.py' pull_request: branches: - dev jobs: train-model: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: iterative/setup-cml@v1 - name: Set up Python uses: actions/setup-python@v2 with: python-version: '3.8' - name: Train model env: repo_token: ${{ secrets.GITHUB_TOKEN }} S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }} S3_PATH_NAME: ${{ secrets.S3_PATH_NAME }} S3_MODEL_PATH_NAME: ${{ secrets.S3_MODEL_PATH_NAME }} run: | cd async-processing docker compose up -d docker compose exec -T consumer python3 consumer/tasks.py # Create CML report echo \u0026quot;## Metrics\u0026quot; \u0026gt;\u0026gt; report.md cat app/data/metrics.txt \u0026gt;\u0026gt; report.md echo \u0026quot;## Plots\u0026quot; \u0026gt;\u0026gt; report.md echo \u0026quot;### YY-plot\u0026quot; \u0026gt;\u0026gt; report.md cml-publish app/data/yy_plot.png --md --title 'YY Plot' \u0026gt;\u0026gt; report.md echo \u0026quot;### Residual-plot\u0026quot; \u0026gt;\u0026gt; report.md cml-publish app/data/residual_plot.png --md --title 'Residual Plot' \u0026gt;\u0026gt; report.md cml-send-comment report.md  CMLãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¨ã—ã¦ï¼Œtasks.pyãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã¨devãƒ–ãƒ©ãƒ³ãƒã«PRãŒä½œæˆã•ã‚ŒãŸæ™‚ã®2ã¤ã‚’è¨­å®šã—ã¦ã„ã¾ã™ãŒï¼Œã“ã¡ã‚‰ã¯é©å®œçŠ¶æ³ã«åˆã‚ã›ã‚‹ã®ãŒè‰¯ã„ã¨æ€ã„ã¾ã™ï¼ä»Šå›ã¯å˜ç´”ãªRandomForestã®ãƒ¢ãƒ‡ãƒ«ãªã®ã§ç°¡å˜ã«çŸ­æ™‚é–“ã§å›ã™ã“ã¨ãŒã§ãã¾ã™ãŒï¼Œç”»åƒç³»ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãªã©å­¦ç¿’ã«æ™‚é–“ã‚‚ãƒªã‚½ãƒ¼ã‚¹ã‚‚ã‹ã‹ã‚‹å ´åˆï¼ˆç‰¹ã«ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§CMLã‚’å‹•ã‹ã™å ´åˆï¼‰ï¼Œã‚³ãƒ¼ãƒ‰ä¿®æ­£ã®åº¦ã«å®Ÿè¡Œã•ã‚Œã‚‹ã®ã¯é©åˆ‡ã§ãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼\nrunãƒ‘ãƒ¼ãƒˆã¯ï¼Œdocker compose upã§ç«‹ã¡ä¸Šã’ãŸã‚³ãƒ³ãƒ†ãƒŠç’°å¢ƒå†…ã§tasks.pyã‚’å®Ÿè¡Œã—ã¦ï¼Œå‡ºåŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨å›³ã‚’markdownå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¦ã„ã¾ã™ï¼ã“ã“ã§ï¼Œechoã‚’æŒŸã‚€ã“ã¨ã§headerã‚’ä»˜ã‘ãŸã‚Šã‚‚ã§ãã¾ã™ï¼\n cml-publish: ãƒ¬ãƒãƒ¼ãƒˆã«ç”»åƒã‚’è¡¨ç¤ºã•ã›ã‚‹ã‚³ãƒãƒ³ãƒ‰ cml-send-comment: githubã®PRã«ã‚³ãƒ¡ãƒ³ãƒˆã¨ã¨ã—ã¦markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã‚³ãƒãƒ³ãƒ‰  å‚è€ƒ: CML - Command Reference\nçµæœã¯ã“ã®ã‚ˆã†ãªå½¢ã®ãƒ¬ãƒãƒ¼ãƒˆã«ãªã‚Šã¾ã™ï¼\nå®Ÿéš›ä½¿ã£ã¦ã¿ãŸæ„Ÿæƒ³ å€‹äººçš„ã«è‰¯ã„ã¨æ€ã†éƒ¨åˆ†ã¨å¾®å¦™ã ãªã¨æ€ã†éƒ¨åˆ†ã‚’æŒ™ã’ã¦ãŠãã¾ã™ï¼\n è‰¯ã„ç‚¹  ä½œæˆã—ãŸå­¦ç¿’ã®çµæœã‚„è©•ä¾¡ã‚’PRä¸Šã§è­°è«–ã§ãã‚‹ç‚¹  èªè­˜ã®ã‚ºãƒ¬ãªã©ã‚’è­°è«–ã§ãã‚‹ã‹ãªã¨æ€ã„ã¾ã™   ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’è¦‹ã¦ï¼Œãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã‹ã©ã†ã‹ãªã©æ„æ€æ±ºå®šã«ç¹‹ã’ã‚‹ã“ã¨ãŒã§ãã‚‹ç‚¹ å†ç¾æ€§ã‚’ä¸€å®šæ‹…ä¿ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ç‚¹   å¾®å¦™ãªç‚¹  å¿…è¦ãªã‚‚ã®ã‚’å‡ºåŠ›ã—ã¦ã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ç‚¹  çµæœã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚„å›³ã‚’å‡ºåŠ›ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã®ã§ï¼Œãã“ãŒé¢å€’ã ã£ãŸã‚Šï¼Œä½•ã‚’å‡ºã™ã‹ã®æ¤œè¨ã‚‚å¿…è¦   ã©ã†ã„ã£ãŸåŸºæº–ã§CMLã‚’å®Ÿè¡Œã™ã‚‹ã‹  ã©ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§CMLã‚’å®Ÿè¡Œã™ã‚‹ã‹ï¼Ÿï¼ˆpushæ™‚ï¼Ÿmergeæ™‚ï¼Ÿï¼‰ é‡ãŸã„ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆï¼Œå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã¦ãƒ†ã‚¹ãƒˆã™ã¹ãã‹ï¼Ÿ etc\u0026hellip;      å¾®å¦™ãªç‚¹ã¨ã—ã¦æŒ™ã’ãŸå†…å®¹ã‚‚ä¸€éƒ¨ã¯ï¼Œåˆ©ç”¨ã™ã‚‹å´ã§æ±ºã‚ã‚‹ã¹ããƒ«ãƒ¼ãƒ«ã‚„ãƒãƒªã‚·ãƒ¼ã ã£ãŸã‚Šã™ã‚‹ã®ã§ï¼Œã“ã“ã¯ã©ã†ã„ã£ãŸæƒ…å ±ãŒã‚ã‚Œã°ã€Œæ„æ€æ±ºå®šã€ã‚’ã™ã‚‹ä¸Šã§åˆ¤æ–­ææ–™ã¨ãªã‚‹ã®ã‹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã‚¯ãƒªã‚¢ã«ãªã‚‹éƒ¨åˆ†ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ï¼\nãŠã‚ã‚Šã« ä»Šå›ã¯ï¼Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆã¨ã—ã¦ï¼ŒCMLã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§CI/CDã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã¿ãŸã®ã§ãã®ç´¹ä»‹ã«ãªã‚Šã¾ã™ï¼\nã¾ãŸï¼Œä»Šå›ã¯ä½¿ã£ã¦ã„ãªã„ã§ã™ãŒï¼ŒDVCã¨ã„ã†åŒã˜Iterative.aiãŒé–‹ç™ºã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã‚’CMLã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ã†æ–¹æ³•ã‚‚ã‚ã‚‹ã®ã§ï¼Œã“ã“ã‚‚æ¬¡å›å®Ÿé¨“ã—ã¦ä½¿ã£ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ï¼ã“ã‚Œã‚’ä½¿ã†ã“ã¨ã§å‰å›ã®çµæœã¨ã®å·®åˆ†ãªã©ã‚‚è¦‹ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ï¼Œã‚ˆã‚Šè‰¯ã„ã€ŒCI/CD for MLã€ãŒå®Ÿç¾ã§ãã‚‹ã‹ãªã¨æ€ã„ã¾ã™ï¼\nP.S. Twitterã§ã‚³ãƒ¡ãƒ³ãƒˆé ‚ã„ãŸã®ã§ï¼Œè¿½è¨˜ã—ã¦ãŠãã¾ã™ï¼\nç¢ºã‹ã«ï¼Œãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’Pushæ™‚ã‚„PRæ™‚ã«æ¯å›å›ã™ã®ã¯å¤§å¤‰ãªã®ã§ï¼Œå­¦ç¿’æ™‚ã«é©ç”¨ã™ã‚‹ã®ã§ã¯ãªãï¼Œå­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦é©å½“ãªã‚µãƒ–ã‚»ãƒƒãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã¦ãã‚Œã«å¯¾ã™ã‚‹æ¨è«–çµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã™ã‚‹ã®ãŒè»½é‡ã§è©¦ã—ã‚„ã™ãã†ã ãªã¨æ€ã„ã¾ã—ãŸï¼\nãƒ—ãƒ«ãƒªã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡çµæœã‚’å‡ºåŠ›ã—ã¦ãã‚Œã‚‹GitHub Actionã€‚å­¦ç¿’ã¾ã§å›ã™ã®ã¯å¤§å¤‰ãã†ãªã®ã§ã€ã‚µãƒ–ã‚»ãƒƒãƒˆã®æ¨è«–çµæœãã‚‰ã„ã«ç•™ã‚ãŸæ–¹ãŒè‰¯ã•ãã†ï¼Ÿ https://t.co/5QkaHvQYxt\n\u0026mdash; ken_jimmy (@ken_jimmy) May 2, 2022 å‚è€ƒ  Continuous Machine Learning (CML) Data Version Control (DVC) masatakashiwagi/teamaya/async-processing  ","date":"2022-05-01","permalink":"https://masatakashiwagi.github.io/portfolio/post/build-continuous-machine-learning/","tags":["MLOps","Machine Learning"],"title":"CMLã‚’ä½¿ã£ãŸMLãƒ¢ãƒ‡ãƒ«ã®CI/CD"},{"content":"ã¯ã˜ã‚ã« æœ€è¿‘ï¼Œæ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã£ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã©ã†ã„ã£ãŸå‡¦ç†ã‚’è¡Œã£ã¦ãƒ¢ãƒ‡ãƒ«ä½œæˆãªã©ã‚’è¡Œã£ã¦ã„ã‚‹ã‹æ°—ã«ãªã£ãŸã®ã§ï¼Œãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«ã‚ˆãè¡Œã‚ã‚Œã‚‹éåŒæœŸå‡¦ç†ã‚’FastAPIã¨RabbitMQã‚’ç”¨ã„ã¦æ¤œè¨¼ã—ãŸãŠè©±ã«ãªã‚Šã¾ã™ï¼\næ©Ÿæ¢°å­¦ç¿’ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ä½œæˆã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆï¼Œãƒ¢ãƒ‡ãƒ«ä½œæˆã‚’è¡Œã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ï¼Œãã®æƒ…å ±ã‚’å—ã‘å–ã£ãŸã¨ã„ã†ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã ã‘ã‚’å…ˆã«è¿”ã—ï¼Œå®Ÿéš›ã®å‡¦ç†ã¯éåŒæœŸã§è¡Œã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã¨æ€ã„ã¾ã™ï¼ã“ã®å‡¦ç†ã‚’RabbitMQã¨ã„ã†OSSã®message queuing serviceã‚’ç”¨ã„ã¦å®Ÿæ–½ã—ãŸç´¹ä»‹ã«ãªã‚Šã¾ã™ï¼\nã‚ã¨å€‹äººçš„ã«RPC (Remote Procedure Call) ã‚„Publish/Subscribeã®ä»•çµ„ã¿ã‚’ç†è§£ã—ãŸã„ã¨ã„ã†æ°—æŒã¡ã‚‚ã‚ã‚Šã¾ã—ãŸï¼\nä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãªã©ã‚’ç½®ã„ã¦ã‚ã‚Šã¾ã™ï¼\n æ¦‚è¦ã¨ã—ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªæµã‚Œã§å‡¦ç†ã‚’è¦‹ã¦ã„ãã¾ã—ãŸï¼\n FastAPIã«jsonå½¢å¼ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’POSTã™ã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æƒ…å ±ï¼‰ /trainã¨ã„ã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã¾ãšã¯ãƒ‡ãƒ¼ã‚¿ã‚’POSTã™ã‚‹ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒè¡Œã‚ã‚Œãƒ¢ãƒ‡ãƒ«ã‚’S3ã«ä¿å­˜ã™ã‚‹ ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ãŸã‚‰ï¼Œæ¬¡ã«/predictã¨ã„ã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’POSTã™ã‚‹ å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’S3ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ï¼ŒPOSTã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ç¢ºç‡ã‚’è¿”ã™  Message Queuing Serviceã¨ã¯ï¼Ÿ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯Producerã¨å‘¼ã°ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒä½œæˆã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šï¼Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæºœã¾ã£ã¦ã„ãä»•çµ„ã¿ã§ã™ï¼Producerå´ã‹ã‚‰è¦‹ã‚‹ã¨ï¼Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é…ä¿¡ã—ã¾ã™ï¼ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã™ã‚‹å½¹å‰²ã¨ã—ã¦ï¼ŒConsumer (Worker) ã¨å‘¼ã°ã‚Œã‚‹åˆ¥ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šï¼ŒConsumerã¯Queueã«æ¥ç¶šã—ï¼Œå‡¦ç†ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã¾ã™ï¼å‡¦ç†ã—çµ‚ã‚ã£ãŸã‚‰ï¼Œè¿”ä¿¡ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã«é€ä¿¡ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼ï¼ˆQueueã«å…¥ã‚Œã‚‰ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ï¼ŒConsumerãŒå–ã‚Šå‡ºã™ã¾ã§ä¿å­˜ã•ã‚Œã¾ã™ï¼ï¼‰\nã¾ãŸï¼Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã«ã¯Exchangeã¨å‘¼ã°ã‚Œã‚‹æ©Ÿèƒ½ãŒã‚ã‚Šï¼Œã©ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã©ã®ã‚ˆã†ã«é€ã‚‹ã‹ã‚’è¨­å®šã™ã‚‹æ©Ÿèƒ½ã‚‚ã‚ã‚Šã¾ã™ï¼ï¼ˆå³å¯†ã«ã¯ï¼ŒProducerã¯ç›´æ¥Queueã«é€ä¿¡ã™ã‚‹ã®ã§ã¯ãªãï¼ŒExchangeã«é€ä¿¡ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼‰\nå®Ÿéš›ã«ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã®å½¹å‰²ã‚’æ‹…ã†ã‚‚ã®ã‚’Brokerã¨å‘¼ã‚“ã ã‚Šã—ã¾ã™ï¼ã‚µãƒ¼ãƒ“ã‚¹ã¨ã—ã¦RabbitMQã‚„Redisãªã©ãŒã‚ã‚Šï¼Œãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯Amazon Simple Queue Service (SQS) ãŒã‚ã‚Šã¾ã™ï¼\nå‚è€ƒ: What is message queuing?\nRabbitMQã‚’ä½¿ã£ãŸå®Ÿè£… ä»Šå›ã¯RabbitMQã‚’ä½¿ã£ã¦å®Ÿè£…ã—ã¾ã—ãŸï¼RabbitMQã¯OSSã®Message Brokerã§å‹•ä½œãŒé€Ÿãè»½é‡ã§ï¼Œè¤‡æ•°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼ã„ãã¤ã‹ã®è¨€èªã§å®Ÿè£…å¯èƒ½ã§ã™ãŒï¼Œpythonã§æ‰±ã†å ´åˆã«ã¯ï¼Œpikaã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã“ã¨ã«ãªã‚Šã¾ã™ï¼\nä¾‹ãˆã°ï¼ŒCeleryã®ã‚ˆã†ãªåˆ†æ•£ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã“ã¨ã§éåŒæœŸå‡¦ç†ã‚’ã‚ˆã‚Šç°¡å˜ã«å®Ÿè£…ã§ãã¾ã™ãŒï¼ŒCeleryè‡ªä½“ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ãŸã‚ï¼ŒRabbitMQã‚„Redisã®ã‚ˆã†ãªBrokerãŒå¿…è¦ã«ãªã‚Šã¾ã™ï¼ä»Šå›ã¯ã“ã®ã‚ãŸã‚Šã®pub/subã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«Celeryã¯ä½¿ã‚ãšã«RabbitMQã®pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚‹pikaã‚’ä½¿ã£ã¦å®Ÿè£…ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸï¼\nRabbitMQã¯dockerã‚³ãƒ³ãƒ†ãƒŠã§ç«‹ã¡ä¸Šã’ã¦ã„ã¦ï¼Œdefinitions.jsonã¨ã„ã†å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ã«ç”¨æ„ã™ã‚‹ã“ã¨ã§ãã®ã‚¹ã‚­ãƒ¼ãƒã«åŸºã¥ã„ã¦RabbitMQã‚’ç«‹ã¡ä¸Šã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•æ™‚ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼\n definitions.json { \u0026quot;rabbit_version\u0026quot;: \u0026quot;3.9.14\u0026quot;, \u0026quot;rabbitmq_version\u0026quot;: \u0026quot;3.9.14\u0026quot;, \u0026quot;product_name\u0026quot;: \u0026quot;RabbitMQ\u0026quot;, \u0026quot;product_version\u0026quot;: \u0026quot;3.9.14\u0026quot;, \u0026quot;users\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;guest\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;guest\u0026quot;, \u0026quot;hashing_algorithm\u0026quot;: \u0026quot;rabbit_password_hashing_sha256\u0026quot;, \u0026quot;tags\u0026quot;: \u0026quot;administrator\u0026quot;, \u0026quot;limits\u0026quot;: {} } ], \u0026quot;vhosts\u0026quot;: [{ \u0026quot;name\u0026quot;: \u0026quot;/\u0026quot; }], \u0026quot;permissions\u0026quot;: [ { \u0026quot;user\u0026quot;: \u0026quot;guest\u0026quot;, \u0026quot;vhost\u0026quot;: \u0026quot;/\u0026quot;, \u0026quot;configure\u0026quot;: \u0026quot;.*\u0026quot;, \u0026quot;write\u0026quot;: \u0026quot;.*\u0026quot;, \u0026quot;read\u0026quot;: \u0026quot;.*\u0026quot; } ], \u0026quot;topic_permissions\u0026quot;: [], \u0026quot;parameters\u0026quot;: [], \u0026quot;global_parameters\u0026quot;: [], \u0026quot;policies\u0026quot;: [], \u0026quot;queues\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;queue.model.train\u0026quot;, \u0026quot;vhost\u0026quot;: \u0026quot;/\u0026quot;, \u0026quot;durable\u0026quot;: true, \u0026quot;auto_delete\u0026quot;: false, \u0026quot;arguments\u0026quot;: { \u0026quot;x-queue-type\u0026quot;: \u0026quot;classic\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;queue.model.predict\u0026quot;, \u0026quot;vhost\u0026quot;: \u0026quot;/\u0026quot;, \u0026quot;durable\u0026quot;: true, \u0026quot;auto_delete\u0026quot;: false, \u0026quot;arguments\u0026quot;: { \u0026quot;x-queue-type\u0026quot;: \u0026quot;classic\u0026quot; } } ], \u0026quot;exchanges\u0026quot;: [], \u0026quot;bindings\u0026quot;: [] }   RabbitMQã«ã¯ä¸å¯§ãªTutorialsãŒã‚ã‚‹ã®ã§ï¼Œãã‚Œã‚’èª­ã‚€ã¨ç†è§£ãŒé€²ã‚€ã¨æ€ã„ã¾ã™ï¼\nã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ éåŒæœŸå‡¦ç†ã‚’è¡Œã†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹æˆã¯å›³ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼Producer/Broker/Consumerã¨ã‚³ãƒ³ãƒ†ãƒŠã‚’3ã¤ç”¨æ„ã—ã¦ã„ã¾ã™ï¼\nå›³ã®å³ä¸‹ã«ã‚ã‚‹Result Storesã¯ã‚¿ã‚¹ã‚¯ã®å‡¦ç†çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã«ãªã‚Šã¾ã™ï¼Result Storesã«ã¯PostgreSQLã‚„MySQLãªã©ã®DBã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã—ï¼ŒRedisã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼Redisã¯Brokerã¨ã—ã¦ã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ï¼Œä¸¡æ–¹ã‚’1ã¤ã§æ‹…ã†ã“ã¨ãŒå¯èƒ½ã§ã™ï¼ä»Šå›ã¯ãƒ¢ãƒ‡ãƒ«ã‚’S3ã«ä¿å­˜ã™ã‚‹ã ã‘ã¨ã—ã¦ï¼Œå‡¦ç†çµæœã‚’DBã«ä¿å­˜ã—ãŸã‚Šã¯ã—ã¦ã„ãªã„ã§ã™ï¼\n Producer: æ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’è¡Œã†ãŸã‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚¹ãƒˆã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠï¼ˆ=FastAPIï¼‰ Broker: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã®å½¹å‰²ã‚’æ‹…ã†ã‚³ãƒ³ãƒ†ãƒŠï¼ˆ=RabbitMQï¼‰ Consumer: ã‚¿ã‚¹ã‚¯ã‚’å®Ÿéš›ã«å®Ÿè¡Œã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠ Storage: ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆ=S3ï¼‰  docker-compose.ymlã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹æˆã«ãªã‚Šã¾ã™ï¼\n docker-compose.yml version: '3.8' # Common definition x-template: \u0026amp;template volumes: - ~/.gcp:/root/.gcp:cached - ~/.aws:/root/.aws:cached - ./app:/opt/program:cached env_file: - .env environment: TZ: Asia/Tokyo LANG: 'ja_JP.UTF-8' restart: always tty: true services: producer: # FastAPI for producer container_name: producer build: context: . ports: - 5000:5000 command: [\u0026quot;uvicorn\u0026quot;, \u0026quot;main:app\u0026quot;, \u0026quot;--reload\u0026quot;, \u0026quot;--host\u0026quot;, \u0026quot;0.0.0.0\u0026quot;, \u0026quot;--port\u0026quot;, \u0026quot;5000\u0026quot;, \u0026quot;--access-log\u0026quot;] depends_on: - rabbitmq \u0026lt;\u0026lt;: *template consumer: container_name: consumer hostname: consumer build: context: . command: [\u0026quot;python3\u0026quot;, \u0026quot;consumer/consumer.py\u0026quot;, \u0026quot;--num_threads\u0026quot;, \u0026quot;2\u0026quot;] depends_on: - rabbitmq \u0026lt;\u0026lt;: *template rabbitmq: image: rabbitmq:3.9-management container_name: rabbitmq hostname: rabbitmq restart: always volumes: # - ./app/rabbitmq/etc:/etc/rabbitmq/rabbitmq - ./app/rabbitmq/etc/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf - ./app/rabbitmq/etc/definitions.json:/etc/rabbitmq/definitions.json - ./app/rabbitmq/data:/var/lib/rabbitmq - ./app/rabbitmq/logs:/var/log/rabbitmq - ~/.aws:/root/.aws:cached ports: # AMQP protocol port - 5672:5672 # HTTP management UI - 15672:15672 environment: TZ: Asia/Tokyo LANG: 'ja_JP.UTF-8' env_file: - .env # networks: # default: # external: # name: teamaya-network-async   ä»Šå›ã®ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼å°‘ã—å†—é•·ãªæ§‹æˆã«ãªã£ã¦ã„ã¾ã™ãŒï¼Œ./app/producerã¨./app/consumeré…ä¸‹ã«Producerã¨Consumerã®å‡¦ç†ã‚’è¡Œã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒã‚ã‚Šã¾ã™ï¼\n. â”œâ”€â”€ Dockerfile â”œâ”€â”€ README.md â”œâ”€â”€ app â”‚ â”œâ”€â”€ consumer â”‚ â”‚ â”œâ”€â”€ base.py â”‚ â”‚ â”œâ”€â”€ consumer.py â”‚ â”‚ â””â”€â”€ tasks.py â”‚ â”œâ”€â”€ logger.py â”‚ â”œâ”€â”€ main.py â”‚ â”œâ”€â”€ producer â”‚ â”‚ â”œâ”€â”€ base.py â”‚ â”‚ â”œâ”€â”€ producer.py â”‚ â”‚ â””â”€â”€ schema.py â”‚ â”œâ”€â”€ rabbitmq â”‚ â”‚ â””â”€â”€ etc â”‚ â”‚ â”œâ”€â”€ definitions.json â”‚ â”‚ â””â”€â”€ rabbitmq.conf â”‚ â””â”€â”€ test â”‚ â”œâ”€â”€ __init__.py â”‚ â”œâ”€â”€ conftest.py â”‚ â”œâ”€â”€ data â”‚ â”‚ â””â”€â”€ test_diabetes.csv â”‚ â””â”€â”€ unit â”‚ â”œâ”€â”€ __init__.py â”‚ â””â”€â”€ test_tasks.py â”œâ”€â”€ docker-compose.yml â”œâ”€â”€ requirements.lock â””â”€â”€ requirements.txt  Producerã®å®Ÿè£… ãã‚Œãã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ã‚’ã—ã¦ãŠãã¨ï¼Œ\n base.py: RabbitMQã«æ¥ç¶šã™ã‚‹ãŸã‚ã®åˆæœŸåŒ–ã‚„Consumerã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ãŸã‚ã®å‡¦ç†ã‚’å®Ÿè£…ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« producer.py: base.pyã®ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã¦ï¼Œå€‹åˆ¥ã®ã‚¿ã‚¹ã‚¯ã«åˆã‚ã›ã¦é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®Ÿè¡Œã™ã‚‹APIã‚’å®Ÿè£…ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« schema.py: ãƒ‡ãƒ¼ã‚¿ã®å…¥å‡ºåŠ›ã®ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«  FastAPIã§ã¯å…¥å‡ºåŠ›ã‚’Pydanticã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ã¦Data validationã‚’è¡Œã„ã¾ã™ï¼å‹ãƒ’ãƒ³ãƒˆã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã«ãªã‚Šã¾ã™     producer.py import ast import uuid from fastapi import APIRouter from logger import get_logger from producer.base import BaseProducer, QueueNames, RepQueueNames from producer.schema import ApiSchemaPredict, ApiSchemaTrain, ProducerResult LOGGER = get_logger() router = APIRouter(prefix='', tags=[\u0026quot;producers\u0026quot;]) class ProducerTrain(BaseProducer): def __init__(self, queue_name: QueueNames, rep_queue_name: RepQueueNames): BaseProducer.__init__(self, queue_name, rep_queue_name) def run(self, params: ApiSchemaTrain): \u0026quot;\u0026quot;\u0026quot;Run to send message to train consumer Args: params (ApiSchemaTrain): schema for train \u0026quot;\u0026quot;\u0026quot; model_id = str(uuid.uuid4()) message = { \u0026quot;model_id\u0026quot;: model_id, \u0026quot;dataset_id\u0026quot;: params.dataset_id, \u0026quot;features\u0026quot;: params.features, \u0026quot;target\u0026quot;: params.target } # self.send_message_to_consumer(message) LOGGER.info(\u0026quot;Produce message for train.\u0026quot;) response = self.send_message_to_consumer(message) response = ast.literal_eval(response.decode()) LOGGER.info(f\u0026quot;Reply Response from consumer: {response}\u0026quot;) return ProducerResult(message=response) class ProducerPredict(BaseProducer): def __init__(self, queue_name: QueueNames, rep_queue_name: RepQueueNames): BaseProducer.__init__(self, queue_name, rep_queue_name) def run(self, params: ApiSchemaPredict): \u0026quot;\u0026quot;\u0026quot;Run to send message to predict consumer Args: params (ApiSchemaPredict): schema for predict \u0026quot;\u0026quot;\u0026quot; message = { \u0026quot;model_id\u0026quot;: params.model_id, \u0026quot;dataset_id\u0026quot;: params.dataset_id, \u0026quot;input_data\u0026quot;: params.input_data } LOGGER.info(\u0026quot;Produce message for predict.\u0026quot;) response = self.send_message_to_consumer(message) response = ast.literal_eval(response.decode()) LOGGER.info(f\u0026quot;Reply Response from consumer: {response}\u0026quot;) return ProducerResult(message=response) @router.post(\u0026quot;/train\u0026quot;, response_model=ProducerResult, name=\u0026quot;train\u0026quot;) async def train(params: ApiSchemaTrain) -\u0026gt; ProducerResult: \u0026quot;\u0026quot;\u0026quot;Train model\u0026quot;\u0026quot;\u0026quot; return ProducerTrain(queue_name='queue.model.train', rep_queue_name='queue.reply.train').run(params) @router.post(\u0026quot;/predict\u0026quot;, response_model=ProducerResult, name=\u0026quot;predict\u0026quot;) async def predict(params: ApiSchemaPredict) -\u0026gt; ProducerResult: \u0026quot;\u0026quot;\u0026quot;Predict model\u0026quot;\u0026quot;\u0026quot; return ProducerPredict(queue_name='queue.model.predict', rep_queue_name='queue.reply.predict').run(params)   ProducerTrainã¨ProducerPredictã¯ã‚¿ã‚¹ã‚¯å®Ÿè¡Œç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹ã‚­ãƒ¥ãƒ¼ã®queue_nameã¨Consumerå´ã‹ã‚‰ã®è¿”ä¿¡ç”¨ã®ã‚­ãƒ¥ãƒ¼ã§ã‚ã‚‹rep_queue_nameã®2ã¤ã‚’å¼•æ•°ã«å–ã‚Šã¾ã™ï¼å®Ÿéš›ã®å­¦ç¿’ã‚„äºˆæ¸¬å‡¦ç†ã‚’è¡Œã†éƒ¨åˆ†ã¯Consumerå´ã§å®Ÿè£…ã—ã¦ã„ã¾ã™ï¼\n base.py import json import os import uuid from typing import Literal import pika from logger import get_logger LOGGER = get_logger() # Possible values as queue name QueueNames = Literal['queue.model.train', 'queue.model.predict'] RepQueueNames = Literal['queue.reply.train', 'queue.reply.predict'] class BaseProducer: def __init__(self, queue_name: QueueNames, rep_queue_name: RepQueueNames): self.queue_name = queue_name self.rep_queue_name = rep_queue_name self.pika_params = pika.ConnectionParameters( host=\u0026quot;rabbitmq\u0026quot;, port=os.getenv('RABBITMQ_PORT', 5672), connection_attempts=10, heartbeat=0 ) self.connection = pika.BlockingConnection(self.pika_params) self.channel = self.connection.channel() LOGGER.info('Pika connection initialized.') result = self.channel.queue_declare(queue=self.rep_queue_name, exclusive=True) self.callback_queue = result.method.queue self.channel.basic_consume(queue=self.callback_queue, on_message_callback=self.on_response, auto_ack=True) def on_response(self, ch, method, props, body): if self.corr_id == props.correlation_id: self.response = body def run(self): raise NotImplementedError() def send_message_to_consumer(self, message: dict): \u0026quot;\u0026quot;\u0026quot;Send message Args: message (dict): message info \u0026quot;\u0026quot;\u0026quot; self.response = None self.corr_id = str(uuid.uuid4()) message_json = json.dumps(message) self.channel.basic_publish( exchange=\u0026quot;\u0026quot;, routing_key=self.queue_name, body=message_json, properties=pika.BasicProperties( content_type='application/json', delivery_mode=2, # make message persistent reply_to=self.callback_queue, correlation_id=self.corr_id ) ) LOGGER.info(f\u0026quot;Sent message. [q] '{self.queue_name}' [x] Body: {message_json=}\u0026quot;) while self.response is None: self.connection.process_data_events() self.close() return self.response def close(self): self.channel.close() self.connection.close()     __init__é–¢æ•°:\n RabbitMQã®ã‚µãƒ¼ãƒãƒ¼ã¨æ¥ç¶šã™ã‚‹ãŸã‚ã«pika.BlockingConnection()ã§host, portãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã‚’è¡Œã† Consumerã‹ã‚‰ã®Replyç”¨ã«rep_queue_nameã«æŒ‡å®šã—ãŸã‚­ãƒ¥ãƒ¼åã§callback_queueã‚’ä½œæˆ basic_consumeã§ã¯subscribeã™ã‚‹ã‚­ãƒ¥ãƒ¼ãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’å®Ÿè¡Œ    send_message_to_consumeré–¢æ•°:\n ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’json.dumpã—ï¼Œbasic_publishã®bodyã«ã¤ã‚ã¦Exchangeã«é€ã‚‹    Consumerã®å®Ÿè£… ãã‚Œãã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ã‚’ã—ã¦ãŠãã¨ï¼Œ\n base.py: RabbitMQã«æ¥ç¶šã—ã¦ã‚­ãƒ¥ãƒ¼ã«ã‚ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ï¼Œå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«  callbackéƒ¨åˆ†ã¯tasks.pyã§å®Ÿè£…ã—ã¦ã„ã¾ã™   consumer.py: ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’æ±ºã‚ã‚‹num_threadsã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã«å–ã‚Šï¼Œã‚³ãƒ³ãƒ†ãƒŠä¸Šã§ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ tasks.py: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚„å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦äºˆæ¸¬ã‚’è¡Œã†å‡¦ç†ã‚’å®Ÿè£…ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«  callbackãƒ¡ã‚½ãƒƒãƒ‰ã«å®Ÿè¡Œã—ãŸã„å‡¦ç†ã‚’å®Ÿè£…ã—ã¾ã™ if __name__ == \u0026quot;__main__\u0026quot;:ä»¥ä¸‹ã«ã¯Continuous Machine Learning (CML) ã§åˆ©ç”¨ã™ã‚‹CTç”¨ã®å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ï¼ï¼ˆCMLã«é–¢ã—ã¦ã¯åˆ¥ã§ãƒ–ãƒ­ã‚°ã‚’æ›¸ã“ã†ã¨æ€ã„ã¾ã™ï¼‰     tasks.py import json import os import sys import traceback from typing import Any, Dict import matplotlib.pyplot as plt import numpy as np import pandas as pd import pika from logger import get_logger from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split from base import BaseConsumer, EvalMetrics, QueueNames LOGGER = get_logger() S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME') S3_PATH_NAME = os.getenv('S3_PATH_NAME') S3_MODEL_PATH_NAME = os.getenv('S3_MODEL_PATH_NAME') class TrainConsumer(BaseConsumer): def __init__(self, queue_name: QueueNames): BaseConsumer.__init__(self, queue_name) def callback(self, ch, method, props, body): params = self.body2dict(body) payload = { 'status': 'TASK_RECEIVED', 'model_id': params['model_id'] } response = json.dumps(payload) ch.basic_publish( exchange='', routing_key=props.reply_to, properties=pika.BasicProperties(correlation_id=props.correlation_id), body=response ) # ch.basic_ack(delivery_tag=method.delivery_tag) self.download_from_s3(S3_BUCKET_NAME, S3_PATH_NAME, 'data/', params['dataset_id'] + '.csv') LOGGER.info(\u0026quot;Download dataset from S3.\u0026quot;) dataset_path = 'data/' + params['dataset_id'] + '.csv' df = pd.read_csv(dataset_path) LOGGER.info(\u0026quot;Read csv file and transform to dataframe.\u0026quot;) try: result = train(df, params) # save model model_path = 'data/model.pkl' self.save_model(result['model'], model_path) LOGGER.info(\u0026quot;Save trained model to local.\u0026quot;) # upload model to cloud storage model_id = params['model_id'] self.upload_to_s3(S3_BUCKET_NAME, S3_MODEL_PATH_NAME + f'{model_id}/', 'data/', 'model.pkl') LOGGER.info(\u0026quot;Upload trained model to S3.\u0026quot;) LOGGER.info(\u0026quot;TASK_COMPLETED\u0026quot;) except Exception as e: _, _, tb = sys.exc_info() LOGGER.error( f\u0026quot;Exception Error: {e} || Type: {str(type(e))} || Traceback Message: {traceback.format_tb(tb)}\u0026quot;) LOGGER.error(\u0026quot;TASK_ERROR\u0026quot;) class PredictConsumer(BaseConsumer): def __init__(self, queue_name: QueueNames): BaseConsumer.__init__(self, queue_name) def callback(self, ch, method, props, body): params = self.body2dict(body) model_id = params['model_id'] self.download_from_s3(S3_BUCKET_NAME, S3_MODEL_PATH_NAME + f'{model_id}/', 'data/', 'model.pkl') LOGGER.info(\u0026quot;Download model file from S3.\u0026quot;) model_path = 'data/model.pkl' model = self.load_model(model_path) LOGGER.info(\u0026quot;Load model for prediction.\u0026quot;) try: result = predict(model, params) payload = { 'status': 'TASK_COMPLETED', 'pred_proba': result['pred_proba'] } response = json.dumps(payload) except Exception as e: _, _, tb = sys.exc_info() LOGGER.error( f\u0026quot;Exception Error: {e} || Type: {str(type(e))} || Traceback Message: {traceback.format_tb(tb)}\u0026quot;) payload = { 'status': 'TASK_ERROR', 'pred_proba': None } response = json.dumps(payload) ch.basic_publish( exchange='', routing_key=props.reply_to, properties=pika.BasicProperties(correlation_id=props.correlation_id), body=response ) # ch.basic_ack(delivery_tag=method.delivery_tag) def train(df: pd.DataFrame, params: dict) -\u0026gt; Dict[str, Any]: \u0026quot;\u0026quot;\u0026quot;Train machine learning model (RandomForestRegressor) Args: df (pd.DataFrame): dataset for training model params (dict): parameters for training \u0026quot;\u0026quot;\u0026quot; features = params['features'] target = params['target'] X, y = df[features], df[target].values # train/test split X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42) LOGGER.info(\u0026quot;Start model training.\u0026quot;) # machine learning model: RandomForestRegressor reg_model = RandomForestRegressor(max_depth=3, random_state=42, n_estimators=100) reg_model.fit(X_train, y_train) LOGGER.info(\u0026quot;Model fit for training.\u0026quot;) # evaluate model pred = reg_model.predict(X_valid) # evaluate metrics eval_metrics = EvalMetrics() rmse = eval_metrics.rmse_score(y_valid, pred) LOGGER.info(\u0026quot;Evaluate metrics=RMSE for valid dataset : %.3f\u0026quot; % rmse) LOGGER.info(\u0026quot;Finish model training.\u0026quot;) result = { 'y_pred': pred, 'y_true': y_valid, 'metrics': {'rmse': rmse}, 'model': reg_model } return result def predict(model: object, params: dict) -\u0026gt; Dict[str, Any]: \u0026quot;\u0026quot;\u0026quot;Prediction for dataset using trained model Args: model (object): trained model params (dict): parameters for prediction Returns: float: predict probability \u0026quot;\u0026quot;\u0026quot; input_data = params['input_data'] pred_proba = model.predict(pd.DataFrame([input_data])) result = { 'pred_proba': pred_proba[0] } return result    å­¦ç¿’ãƒ‘ãƒ¼ãƒˆ  ä»Šå›ï¼Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯ä½•ã§ã‚‚ã‚ˆã‹ã£ãŸã®ã§ï¼ŒRandomForestã§å›å¸°ã‚’è¡Œã†å‡¦ç†ã«ã—ã¦ã„ã¾ã™ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯S3ã«ä¿å­˜ã—ã¦ã„ã‚‹ã®ã§ï¼Œã“ã®å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã«è‡ªèº«ã§åˆ©ç”¨ã—ã¦ã„ã‚‹AWSã®ãƒã‚±ãƒƒãƒˆæƒ…å ±ãªã©ã‚’è¼‰ã›ã¦ä¸‹ã•ã„    S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME') S3_PATH_NAME = os.getenv('S3_PATH_NAME') S3_MODEL_PATH_NAME = os.getenv('S3_MODEL_PATH_NAME')  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’æ™‚ã®ãƒ¡ã‚¿æƒ…å ±ã‚‚DBã«æ®‹ã—ã¦ãŠãã®ãŒè‰¯ã„ã¨æ€ã„ã¾ã™ãŒï¼Œä»Šå›ã¯ãã®éƒ¨åˆ†ã¯å®Ÿè£…ã—ã¦ã„ãªã„ã§ã™ğŸ™\n äºˆæ¸¬ãƒ‘ãƒ¼ãƒˆ  S3ã«ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ï¼Œä¸ãˆã‚‰ãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ ãƒ¢ãƒ‡ãƒ«IDã¯å­¦ç¿’æ™‚ã«ç™ºè¡Œã•ã‚ŒãŸUUIDã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã™ãŒï¼Œå‡ºåŠ›ã•ã‚ŒãŸãƒ­ã‚°ã‹ã‚‰æ‹¾ã†ã®ã§ã¡ã‚‡ã£ã¨ã„ã‘ã¦ãªã„ã§ã™ãŒãƒ¢ãƒƒã‚¯ãªã®ã§ã”å‹˜å¼ã‚’\u0026hellip;     consumer.py from concurrent.futures import ThreadPoolExecutor import click import tasks @click.command() @click.option(\u0026quot;--num_threads\u0026quot;, type=int, help='the number of threads', default=1) @click.option(\u0026quot;--max_workers\u0026quot;, type=int, help='the number of max workers', default=None) def main(num_threads: int, max_workers: int): # Consumer execution with ThreadPoolExecutor(max_workers=max_workers) as executor: for _ in range(num_threads): for task in [ tasks.TrainConsumer(queue_name='queue.model.train'), tasks.PredictConsumer(queue_name='queue.model.predict') ]: executor.submit(task.run) if __name__ == \u0026quot;__main__\u0026quot;: main()   å¼•æ•°ã«æŒ‡å®šã—ãŸã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã«å¿œã˜ã¦ConsumerãŒè¤‡æ•°ç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ï¼\nå®Ÿè¡Œçµæœ docker compose upã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ã¦ï¼Œhttp://localhost:5000/docsã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨Swaggerã«ã‚ˆã‚‹è¡¨ç¤ºãŒã•ã‚Œã¾ã™ï¼FastAPIã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§OpenAPIã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ãã‚Œï¼ŒSwaggerã‚„ReDocã§è¡¨ç¤ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nã“ã®è¾ºã¯å€‹äººçš„ã«ã¨ã¦ã‚‚ä¾¿åˆ©ã ãªã¨æ€ã£ã¦ã„ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚’ç°¡å˜ã«GET/POSTã™ã‚‹ã“ã¨ã§å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ãã¾ã™ï¼\n Swaggerã®ç”»é¢   ReDocã®ç”»é¢  å­¦ç¿’ç·¨ /trainã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’POSTã—ã¾ã™ï¼äº‹å‰ã«S3ã«ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’dataset_idã«ï¼Œä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰ã‚’featuresã«ï¼Œç›®çš„å¤‰æ•°ã‚’targetã«æŒ‡å®šã—ã¾ã™ï¼\ncurl -X 'POST' \\ 'http://localhost:5000/train' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \u0026quot;dataset_id\u0026quot;: \u0026quot;diabetes\u0026quot;, \u0026quot;features\u0026quot;: [\u0026quot;age\u0026quot;, \u0026quot;bmi\u0026quot;, \u0026quot;bp\u0026quot;, \u0026quot;s1\u0026quot;, \u0026quot;s2\u0026quot;, \u0026quot;s3\u0026quot;, \u0026quot;s4\u0026quot;, \u0026quot;s5\u0026quot;, \u0026quot;s6\u0026quot;], \u0026quot;target\u0026quot;: \u0026quot;target\u0026quot; }'  å‡ºåŠ›ã•ã‚Œã‚‹ãƒ­ã‚°ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã«ãªã‚Šã¾ã™ï¼\n 4è¡Œç›®ã¯ProducerãŒã‚­ãƒ¥ãƒ¼ã«å¯¾ã—ã¦é€ä¿¡ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆConsumerã«æ¸¡ã—ãŸã„æƒ…å ±ï¼‰ 7è¡Œç›®ï¼ˆä¸­ç•¥å¾Œ1è¡Œç›®ï¼‰ã¯Consumerã‹ã‚‰ã®Replyãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ æœ€å¾Œã®Consumerã‹ã‚‰ã®ãƒ­ã‚°ã¯å­¦ç¿’å‡¦ç†ã‚’å®Ÿè¡Œä¸­ã«å‡ºåŠ›ã•ã‚Œã‚‹ãƒ­ã‚°  producer | [2022-04-24 15:49:09] [ INFO] Created channel=1 producer | [2022-04-24 15:49:09] [ INFO] Pika connection initialized. producer | [2022-04-24 15:49:09] [ INFO] Produce message for train. producer | [2022-04-24 15:49:09] [ INFO] Sent message. [q] 'queue.model.train' [x] Body: message_json='{\u0026quot;model_id\u0026quot;: \u0026quot;c7632288-442d-44c5-9102-31ccda2af6b7\u0026quot;, \u0026quot;dataset_id\u0026quot;: \u0026quot;diabetes\u0026quot;, \u0026quot;features\u0026quot;: [\u0026quot;age\u0026quot;, \u0026quot;bmi\u0026quot;, \u0026quot;bp\u0026quot;, \u0026quot;s1\u0026quot;, \u0026quot;s2\u0026quot;, \u0026quot;s3\u0026quot;, \u0026quot;s4\u0026quot;, \u0026quot;s5\u0026quot;, \u0026quot;s6\u0026quot;], \u0026quot;target\u0026quot;: \u0026quot;target\u0026quot;}' consumer | [2022-04-24 15:49:09] [ INFO] Convert message to dict type. ~ä¸­ç•¥~ producer | [2022-04-24 15:49:09] [ INFO] Reply Response from consumer: {'status': 'TASK_RECEIVED', 'model_id': 'c7632288-442d-44c5-9102-31ccda2af6b7'} producer | INFO: 172.24.0.1:57222 - \u0026quot;POST /train HTTP/1.1\u0026quot; 200 OK rabbitmq | 2022-04-24 06:49:09.367236+00:00 [info] \u0026lt;0.5900.0\u0026gt; closing AMQP connection \u0026lt;0.5900.0\u0026gt; (172.24.0.4:46266 -\u0026gt; 172.24.0.2:5672, vhost: '/', user: 'guest') consumer | [2022-04-24 15:49:09] [ INFO] Found credentials in shared credentials file: ~/.aws/credentials consumer | [2022-04-24 15:49:09] [ INFO] Download dataset from S3. consumer | [2022-04-24 15:49:09] [ INFO] Read csv file and transform to dataframe. consumer | [2022-04-24 15:49:09] [ INFO] Start model training. consumer | [2022-04-24 15:49:09] [ INFO] Model fit for training. consumer | [2022-04-24 15:49:09] [ INFO] Evaluate metrics=RMSE for valid dataset : 53.039 consumer | [2022-04-24 15:49:09] [ INFO] Finish model training. consumer | [2022-04-24 15:49:09] [ INFO] Save trained model to local. consumer | [2022-04-24 15:49:10] [ INFO] Upload trained model to S3. consumer | [2022-04-24 15:49:10] [ INFO] TASK_COMPLETED  äºˆæ¸¬ç·¨ /predictã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’POSTã—ã¾ã™ï¼model_idã‚’å…ƒã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’S3ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼input_dataã«ã¯ï¼Œãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’dictå½¢å¼ã§ç‰¹å¾´é‡ã¨ãã®å€¤ã¨ã„ã†çµ„ã§æ¸¡ã—ã¾ã™ï¼\nâ€» model_idã¯å­¦ç¿’ç·¨ã®ãƒ­ã‚°å‡ºåŠ›ã«ã‚ã‚‹model_idã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\ncurl -X 'POST' \\ 'http://localhost:5000/predict' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \u0026quot;model_id\u0026quot;: \u0026quot;c7632288-442d-44c5-9102-31ccda2af6b7\u0026quot;, \u0026quot;dataset_id\u0026quot;: \u0026quot;diabetes\u0026quot;, \u0026quot;input_data\u0026quot;: { \u0026quot;age\u0026quot;: 0.038076, \u0026quot;bmi\u0026quot;: 0.061696, \u0026quot;bp\u0026quot;: 0.021872, \u0026quot;s1\u0026quot;: -0.044223, \u0026quot;s2\u0026quot;: -0.034821, \u0026quot;s3\u0026quot;: -0.043401, \u0026quot;s4\u0026quot;: -0.002592, \u0026quot;s5\u0026quot;: 0.019908, \u0026quot;s6\u0026quot;: -0.017646 } }'  å‡ºåŠ›ã•ã‚Œã‚‹ãƒ­ã‚°ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã«ãªã‚Šã¾ã™ï¼\n 4è¡Œç›®ã¯ProducerãŒã‚­ãƒ¥ãƒ¼ã«å¯¾ã—ã¦é€ä¿¡ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆConsumerã«æ¸¡ã—ãŸã„æƒ…å ±ï¼‰ 5è¡Œç›®ã®Consumerã‹ã‚‰ã®ãƒ­ã‚°ã¯äºˆæ¸¬å‡¦ç†ã‚’å®Ÿè¡Œä¸­ã«å‡ºåŠ›ã•ã‚Œã‚‹ãƒ­ã‚° ï¼ˆä¸­ç•¥å¾Œ1è¡Œç›®ï¼‰ã¯Consumerã‹ã‚‰ã®Replyãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ï¼Œäºˆæ¸¬çµæœãŒå…¥ã£ã¦ã„ã¾ã™  producer | [2022-04-24 18:00:16] [ INFO] Created channel=1 producer | [2022-04-24 18:00:16] [ INFO] Pika connection initialized. producer | [2022-04-24 18:00:16] [ INFO] Produce message for predict. producer | [2022-04-24 18:00:16] [ INFO] Sent message. [q] 'queue.model.predict' [x] Body: message_json='{\u0026quot;model_id\u0026quot;: \u0026quot;c7632288-442d-44c5-9102-31ccda2af6b7\u0026quot;, \u0026quot;dataset_id\u0026quot;: \u0026quot;diabetes\u0026quot;, \u0026quot;input_data\u0026quot;: {\u0026quot;age\u0026quot;: 0.038076, \u0026quot;bmi\u0026quot;: 0.061696, \u0026quot;bp\u0026quot;: 0.021872, \u0026quot;s1\u0026quot;: -0.044223, \u0026quot;s2\u0026quot;: -0.034821, \u0026quot;s3\u0026quot;: -0.043401, \u0026quot;s4\u0026quot;: -0.002592, \u0026quot;s5\u0026quot;: 0.019908, \u0026quot;s6\u0026quot;: -0.017646}}' consumer | [2022-04-24 18:00:16] [ INFO] Convert message to dict type. consumer | [2022-04-24 18:00:16] [ INFO] Download model file from S3. consumer | [2022-04-24 18:00:16] [ INFO] Load model for prediction. ~ä¸­ç•¥~ producer | [2022-04-24 18:00:16] [ INFO] Reply Response from consumer: {'status': 'TASK_COMPLETED', 'pred_proba': 208.6445780005619} rabbitmq | 2022-04-24 09:00:16.565636+00:00 [info] \u0026lt;0.8348.0\u0026gt; closing AMQP connection \u0026lt;0.8348.0\u0026gt; (172.24.0.4:46664 -\u0026gt; 172.24.0.2:5672, vhost: '/', user: 'guest') producer | INFO: 172.24.0.1:57624 - \u0026quot;POST /predict HTTP/1.1\u0026quot; 200 OK  ãŠã‚ã‚Šã« FastAPIã¨RabbitMQã‚’ç”¨ã„ã¦WebAPIå½¢å¼ã§ï¼Œæ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®éåŒæœŸå‡¦ç†ã‚’è¡Œã†æ¤œè¨¼ã‚’ã—ã¾ã—ãŸï¼éåŒæœŸå‡¦ç†ã ã£ãŸã‚Šï¼ŒRPCã‚„Pub/Subã®ä»•çµ„ã¿ã‚’å°‘ã—ã¯ç†è§£ã§ããŸã‹ãªã¨æ€ã„ã¾ã™ï¼\nä»Šå›ã¯DBã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ãŸã‚ŠDBå‘¨ã‚Šã®å‡¦ç†ã¯å®Ÿè£…ã—ã¦ã„ãªã„ã®ã§ï¼Œã“ã®è¾ºã‚‚æ™‚é–“ãŒã‚ã‚Œã°å®Ÿè£…ã§ãã‚Œã°ã¨æ€ã„ã¾ã™\u0026hellip;\néåŒæœŸå‡¦ç†ã‚’è¡Œã†ä¸Šã§ãƒ¡ã‚¤ãƒ³ã®å½¹å‰²ã‚’æœãŸã—ãŸRabbitMQã«ã¤ã„ã¦ã‚‚ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹ã¨ï¼ŒOSSã§ç°¡å˜ã«éåŒæœŸå‡¦ç†ã‚’è¡Œãˆã‚‹ä¾¿åˆ©ãªæŠ€è¡“ã ã¨æ€ã„ã¾ã™ï¼Producer/Exchange/Queue/Consumerã®é–¢ä¿‚æ€§ã‚‚Tutorialsã®å›³ãªã©ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ã—ã‚„ã™ããªã‚‹ã®ã§ï¼Œã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãªãŒã‚‰æ¯”è¼ƒçš„å®¹æ˜“ã«å®Ÿè£…ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸï¼\nä¸€æ–¹ã§ï¼ŒConsumerã‹ã‚‰Producerã«Replyãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹å ´åˆã«ï¼Œã©ã®ã‚ˆã†ã«å®Ÿè£…ã™ã‚Œã°ã„ã„ã‹ãŒåˆ†ã‹ã‚Šã¥ã‚‰ãï¼Œå€‹äººçš„ã«ã¯ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆã§ã—ãŸï¼\nã‚ã¨ï¼Œãªã«ã’ã«FastAPIã‚‚ã»ã¨ã‚“ã©ä½¿ã£ãŸã“ã¨ãªã‹ã£ãŸã®ã§è‰¯ã„å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸï¼\næœ€å¾Œã«ä»Šå¾Œã‚„ã‚ŠãŸã„ã“ã¨ã«ã¤ã„ã¦åˆ—æŒ™ã—ã¦ãŠãã¨\u0026hellip;\n AWS SQSã‚’ä½¿ã£ãŸéåŒæœŸå‡¦ç†ã®å®Ÿè£… Celeryã‚’ä½¿ã£ãŸéåŒæœŸå‡¦ç†ã®å®Ÿè£… Brokerã¨ã—ã¦Redisã‚’ç”¨ã„ãŸå®Ÿè£… DBã‚’ä½¿ã£ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ etc\u0026hellip;  å‚è€ƒ  FastAPI RabbitMQ  RabbitMQ Tutorials   Asynchronous message-based communication Deep Learning: Scaling your neural networks with containerization and a message broker katanaml/katana-skipper  ","date":"2022-04-24","permalink":"https://masatakashiwagi.github.io/portfolio/post/async-ml-processing/","tags":["Dev","Machine Learning"],"title":"FastAPIã¨RabbitMQã‚’ç”¨ã„ãŸæ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®éåŒæœŸå‡¦ç†"},{"content":"ã¯ã˜ã‚ã« æœ€è¿‘å€‹äººçš„ã«MLOpsã¨ã„ã†é ˜åŸŸã«é«˜ã„é–¢å¿ƒãŒã‚ã£ã¦ï¼Œæ—¥ã€…æƒ…å ±åé›†ã‚’ã—ãŸã‚Šã—ã¦ã„ã‚‹ã®ã§ã™ãŒï¼Œå„ç¤¾ãŒå®Ÿå‹™ã§å–ã‚Šçµ„ã‚“ã§ã„ã‚‹äº‹ä¾‹ã‚„MLOpsã®å„é ˜åŸŸã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã‚„ãƒ„ãƒ¼ãƒ«ãªã©å€‹åˆ¥ã®TipsãŒç‚¹åœ¨ã—ã¦ã„ã¦è¦‹ã¤ã‘ã‚‹ã®ãŒå¤§å¤‰ã ãªã¨ã„ã†å°è±¡ãŒã‚ã‚Šã¾ã™ï¼\nç‰¹ã«å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒæ•´ç†ã•ã‚Œã¦ã„ã‚‹ã¨å¬‰ã—ã„ãªãƒ¼ã¨ã„ã†æ°—æŒã¡ã‹ã‚‰ï¼Œã˜ã‚ƒã‚è‡ªåˆ†ã§æ•´ç†ã™ã‚Œã°ã„ã„ã®ã§ã¯ï¼Ÿã¨æ€ã„ã€ŒMLOps Practicesã€ã¨ã„ã†Websiteã‚’ä½œã£ã¦å…¬é–‹ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸï¼\nMLOps Practicesã¨ã¯ï¼Ÿ æµ·å¤–ã«ã¯ï¼ŒApplyingML ã‚„ Awesome MLOps ã¨ã„ã†Website/RepositoryãŒã‚ã‚Šãƒˆãƒ”ãƒƒã‚¯æ¯ã«å„ç¤¾ã®äº‹ä¾‹ãŒè¼‰ã£ã¦ã„ãŸã‚Šï¼Œè‰²ã€…ã¨ç¶²ç¾…çš„ã«æ•´ç†ã•ã‚Œã¦ãŠã‚Šã‚µãƒ¼ãƒ™ã‚¤ã®å‚è€ƒã«ãªã‚‹ã‚‚ã®ãŒã‚ã‚Šã¾ã™ï¼\nã“ã‚Œã¨ä¼¼ãŸã‚‚ã®ãŒã‚ã£ãŸã‚‰ã„ã„ãªãƒ¼ã¨æ€ã£ã¦è»½ãæ¢ã—ãŸã¨ã“ã‚ï¼Œè¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã®ã§ï¼Œãã‚Œã ã£ãŸã‚‰è‡ªåˆ†ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ç”¨ã‚‚å…¼ã­ã¦ä½œã£ã¦ã¿ã‚ˆã†ã‹ãªã¨ã„ã†æ°—æŒã¡ã‹ã‚‰ MLOps Practices ã¨ã„ã†Websiteã‚’ä½œæˆã—ï¼Œå…¬é–‹ã—ã¾ã—ãŸï¼\nKnowledgeã«ã¯ï¼Œå„ç¤¾ã§å®Ÿéš›ã«å°å…¥ã•ã‚Œã¦ã„ãŸ or ã•ã‚Œã¦ã„ã‚‹äº‹ä¾‹ã‚’æ•´ç†ã—ã¦ã„ã¾ã™ï¼ç‰¹ã«ä¼šç¤¾ã®ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã§ã®ç™»å£‡è³‡æ–™ã‚’ç´¹ä»‹ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼ã“ã‚Œã¯å®Ÿé‹ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã‚’å¤§äº‹ã«ã—ãŸã„ã¨æ€ã£ãŸã®ã§ï¼Œãã®éƒ¨åˆ†ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ï¼\nTipsï¼ˆã“ã¡ã‚‰ã¯æœªæ•´å‚™ï¼‰ã«ã¯ï¼Œå„ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹ãªã©å€‹äººãƒ–ãƒ­ã‚°ãªã©ã‹ã‚‰ã‚‚åé›†ã—ã‚ˆã†ã¨è€ƒãˆã¦ã¾ã™ãŒï¼Œæ•°ãŒè†¨å¤§ã«ãªã‚‹ã®ã§è¦æ¤œè¨ã¨ã„ã†æ„Ÿã˜ã§ã™ï¼\nã¾ã ã¾ã å§‹ã‚ãŸã°ã‹ã‚Šã§ååˆ†ã«æ•´ç†ç¶²ç¾…å‡ºæ¥ã¦ã„ãªã„ã§ã™ãŒï¼Œç´°ã€…ã¨ç¶šã‘ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼ã‚‚ã—ï¼Œã€Œæ‰‹ä¼ã£ã¦ã‚‚ã„ã„ã‚ˆãƒ¼ï¼ã€ã¨ã„ã†æ–¹ãŒå±…ã¾ã—ãŸã‚‰æ˜¯éãŠå£°ãŒã‘ä¸‹ã•ã„ï¼ä¸€ç·’ã«é€²ã‚ã¦è¡Œã‘ãŸã‚‰ã¨æ€ã„ã¾ã™ï¼\nãã‚Œä»¥å¤–ã«ã‚‚è¿½åŠ ã®äº‹ä¾‹ãªã©ã‚ã‚Šã¾ã—ãŸã‚‰ï¼ŒIssueã‚’ä½œæˆå¾Œã«PRã‚’å‡ºã—ã¦è²°ãˆãŸã‚‰å¤§å¤‰å¬‰ã—ã„ã§ã™ï¼\nãŠã‚ã‚Šã« å¾ã€…ã«å†…å®¹ã‚’å……å®Ÿã•ã›ã¦è¡Œã‘ã‚Œã°ã¨æ€ã†ã®ã§ï¼Œä»Šå¾Œã‚‚å®šæœŸçš„ã«æ›´æ–°ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼ã¾ãŸï¼Œä¸€ç·’ã«æ›´æ–° \u0026amp; é‹ç”¨ã—ã¦ã„ã£ã¦ãã‚Œã‚‹äººã‚‚å‹Ÿé›†ä¸­ã§ã™ã®ã§ï¼Œèˆˆå‘³ãŒã‚ã‚Œã°ã”é€£çµ¡ä¸‹ã•ã„ï¼\nRepositoryã«ã‚¹ã‚¿ãƒ¼è¿½åŠ ã—ã¦è²°ãˆã‚‹ã¨åŠ±ã¿ã«ãªã‚Šã¾ã™ã®ã§ï¼Œã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ğŸ™‡\n\nå„ç¤¾ã®MLOpsã«å¯¾ã™ã‚‹å®Ÿè·µäº‹ä¾‹ã‚’åé›†ã—ã¦æ•´ç†ã™ã‚‹Repositoryã‚’ä½œã£ã¦Websiteã«å…¬é–‹ã—ãŸã®ã§ï¼Œè‰¯ã‘ã‚Œã°ã”åˆ©ç”¨ãã ã•ã„ãƒ¼ï¼https://t.co/JMOQGuDtf0\n\u0026mdash; asteriam (@asteriam_fp) January 22, 2022  å‚è€ƒ  ApplyingML Awesome MLOps MLOps Practices  Website: https://masatakashiwagi.github.io/mlops-practices/ Repository: https://github.com/masatakashiwagi/mlops-practices    ","date":"2022-02-05","permalink":"https://masatakashiwagi.github.io/portfolio/post/start-mlops-practices-project/","tags":["Poem","MLOps"],"title":"å„ç¤¾ã®MLOpsäº‹ä¾‹ã‚’é›†ã‚ãŸMLOps Practicesã¨ã„ã†Websiteã‚’å…¬é–‹ã—ã¾ã—ãŸ"},{"content":"ã¯ã˜ã‚ã« Step Functionsã§SageMakerã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ç‰¹ã«ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã§ä½¿ã†å ´åˆï¼Œå˜ç´”ã«InstanceTypeã¨ã—ã¦\u0026quot;ml.g4dn.xlarge\u0026quot;ãªã©ã®GPUãƒã‚·ãƒ³ã‚’è¨­å®šã™ã‚‹ã ã‘ã§ã¯GPUã‚’ä½¿ã£ãŸå­¦ç¿’ã¯ã§ããªãã¦ï¼Œä½¿ã„ãŸã„Dockerfileã«å°‘ã—æ‰‹ã‚’åŠ ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\nä»Šå›ã¯å‚™å¿˜éŒ²ã‚‚å…¼ã­ã¦Dockerfileã®ä¸­èº«ã‚’ç´¹ä»‹ã—ãªãŒã‚‰ï¼ŒGPUç’°å¢ƒã§ã®å‹•ä½œç¢ºèªã‚’ã—ãŸã„ã¨æ€ã„ã¾ã™ï¼\nä»¥ä¸‹ã®æ‰‹é †ã§å‹•ä½œç¢ºèªã‚’è¡Œã£ã¦ã„ã¾ã™ï¼\n ãƒ­ãƒ¼ã‚«ãƒ«ã§Dockerfileã¨å‹•ä½œç¢ºèªç”¨ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹ ãƒ­ãƒ¼ã‚«ãƒ«ã§buildã—ï¼ŒAWS ECRã«buildã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’pushã™ã‚‹ pushã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã®URIã‚’SageMaker Training Jobã®TrainingImageã«æŒ‡å®šã™ã‚‹ Step Functionsã‚’å®Ÿè¡Œã™ã‚‹ CloudWatch Logsã‚’ç¢ºèªã™ã‚‹  ä»Šå›ã®å‹•ä½œç¢ºèªãƒ•ãƒ­ãƒ¼ã¯ä»¥ä¸‹ã®å›³ã®ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ï¼\nè‡ªä½œã®ã€ŒDockerfile.gpuã€ãƒ•ã‚¡ã‚¤ãƒ« ä»Šå›ã¯Tensorflow-gpuã®ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦ã„ã¾ã™ï¼ãã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã«ã€Œnvidia-dockerã€ã‚’è¿½åŠ ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§Step Functionsã§GPUç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦SageMakerã‚’å‹•ä½œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nTensorFlow Docker Imagesã‹ã‚‰å¥½ããªgpuç”¨ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’é¸æŠã—ã¦ä¸‹ã•ã„ï¼ä»Šå›ã¯ã€Œtensorflow/tensorflow:2.6.1-gpuã€ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«ã—ã¾ã™ï¼Optional Featuresã«ã‚‚è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ãŒï¼Œnvidia-dockerãŒå¿…è¦ã ã‚ˆã¨ã®ã“ã¨ãªã®ã§ï¼Œã“ã®é€šã‚Šã«ã—ã¾ã™ï¼\n -gpu tags are based on Nvidia CUDA. You need nvidia-docker to run them. NOTE: GPU versions of TensorFlow 1.13 and above (this includes the latest- tags) require an NVidia driver that supports CUDA 10. See NVidia\u0026rsquo;s support matrix.\n å¤§äº‹ãªéƒ¨åˆ†ã¯ä»¥ä¸‹ã®4è¡Œã«ãªã‚Šã¾ã™ï¼ä»¥å‰ã¯ã“ã¡ã‚‰ã®è¨˜äº‹ã«ã‚‚æ›¸ã‹ã‚Œã¦ã„ã¾ã™ãŒï¼Œnvidia-container-toolkitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã£ãŸã¿ãŸã„ã§ã™ãŒï¼Œä»Šã¯nvidia-docker2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§ï¼Œnvidia-container-toolkitã‚‚ä¸€ç·’ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ã¿ãŸã„ã§ï¼Œã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«ãªã£ã¦ã„ã¾ã™ï¼\nRUN distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list RUN sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y nvidia-docker2  ä»Šå›ä½¿ç”¨ã—ãŸDockerfileå…¨ä½“ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n# Dockerfile.gpu FROM tensorflow/tensorflow:2.6.1-gpu # Set some environment variables. # PYTHONUNBUFFERED keeps Python from buffering our standard # output stream, which means that logs can be delivered to the user quickly. ENV PYTHONUNBUFFERED=TRUE # PYTHONDONTWRITEBYTECODE keeps Python from writing the .pyc files which # are unnecessary in this case. ENV PYTHONDONTWRITEBYTECODE=TRUE # DEBIAN_FRONTEND prevent from stoping docker build with tzdata ENV DEBIAN_FRONTEND=noninteractive RUN apt-get -y update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ curl \\ sudo \\ libmecab-dev \\ python3.8 \\ python3-distutils \\ python3-six \\ git \\ file \\ wget \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # ã“ã“ãŒä»Šå›ã®ãƒã‚¤ãƒ³ãƒˆã§ï¼Œnvidia-dockerã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ RUN distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list RUN sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y nvidia-docker2 # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ã‚’requirements.lockã‚’ä½¿ã£ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ COPY requirements.lock /tmp/requirements.lock RUN python3 -m pip install -U pip \\ \u0026amp;\u0026amp; python3 -m pip install -r /tmp/requirements.lock \\ \u0026amp;\u0026amp; python3 -m pip install sagemaker \\ \u0026amp;\u0026amp; python3 -m pip install sagemaker-training \\ \u0026amp;\u0026amp; rm /tmp/requirements.lock \\ \u0026amp;\u0026amp; rm -rf /root/.cache # Timezone jst RUN ln -sf /usr/share/zoneinfo/Asia/Tokyo /etc/localtime # Locale Japanese ENV LC_ALL=ja_JP.UTF-8 # Set up the program in the image ENV PROGRAM_DIR=/opt/program COPY app $PROGRAM_DIR WORKDIR $PROGRAM_DIR ENV PATH=\u0026quot;/opt/program:${PATH}\u0026quot; RUN chmod +x $PROGRAM_DIR/hello_gpu.py CMD [\u0026quot;python3\u0026quot;]  ã¾ãŸï¼ŒSageMakerã§GPUã‚’èªè­˜ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n# hello_gpu.py import tensorflow as tf from tensorflow.python.client import device_lib def main(): # Tensorflowã®GPUç¢ºèª print(f'GPUs Available: {tf.test.is_gpu_available()}') print(f\u0026quot;Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\u0026quot;) print(f'{device_lib.list_local_devices()}') if __name__ == \u0026quot;__main__\u0026quot;: main()  ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã¦ï¼Œãƒ­ãƒ¼ã‚«ãƒ«ã§buildã‚’è¡Œã„ã¾ã™ï¼Œbuildã—ãŸå¾Œã¯ãã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ECRã«pushã™ã‚‹ã“ã¨ã§ï¼ŒStep Functionsã§ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nâ€» ECRã¸ã®pushæ–¹æ³•ã‚„è¨­å®šã¯ä»Šå›å‰²æ„›ã—ã¾ã™ï¼\nStep Functionsã®è¨­å®š Step Functionsã¨ã¯ï¼ŒAWSãŒæä¾›ã™ã‚‹å„ç¨®ã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã«ãªã‚Šã¾ã™ï¼æ©Ÿæ¢°å­¦ç¿’å‘ã‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã¦ï¼Œä»Šå›ä½¿ç”¨ã™ã‚‹SageMaker Training Jobã‚‚ãã®ä¸€ã¤ã«ãªã‚Šã¾ã™ï¼\nè¨­å®šã¯yamlãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ˆã†ãªå½¢å¼ã§AWSã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ç”»é¢ä¸Šã§æ‰“ã¡è¾¼ã‚“ã§ã„ãã¾ã™ï¼ä»Šå›å®Ÿæ–½ã™ã‚‹å†…å®¹ã®è¨˜è¿°ã¯ä»¥ä¸‹ã®é€šã‚Šã«ãªã‚Šã¾ã™ï¼\n{ \u0026quot;Comment\u0026quot;: \u0026quot;Check GPU env\u0026quot;, \u0026quot;StartAt\u0026quot;: \u0026quot;Hello-GPU\u0026quot;, \u0026quot;States\u0026quot;: { \u0026quot;Hello-GPU\u0026quot;: { \u0026quot;Comment\u0026quot;: \u0026quot;GPUã®å‹•ä½œç¢ºèª\u0026quot;, \u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::sagemaker:createTrainingJob.sync\u0026quot;, \u0026quot;Parameters\u0026quot;: { \u0026quot;RoleArn\u0026quot;: \u0026quot;\u0026lt;SageMaker Training Jobã®å®Ÿè¡Œæ¨©é™ãŒã‚¢ã‚¿ãƒƒãƒã•ã‚Œã¦ã„ã‚‹ãƒ­ãƒ¼ãƒ«\u0026gt;\u0026quot;, \u0026quot;TrainingJobName\u0026quot;: \u0026quot;sample-training-job\u0026quot;, \u0026quot;AlgorithmSpecification\u0026quot;: { \u0026quot;EnableSageMakerMetricsTimeSeries\u0026quot;: true, \u0026quot;TrainingImage\u0026quot;: \u0026quot;\u0026lt;ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID\u0026gt;.dkr.ecr.ap-northeast-1.amazonaws.com/sample:latest-gpu\u0026quot;, \u0026quot;TrainingInputMode\u0026quot;: \u0026quot;File\u0026quot; }, \u0026quot;EnableInterContainerTrafficEncryption\u0026quot;: true, \u0026quot;EnableManagedSpotTraining\u0026quot;: true, \u0026quot;Environment\u0026quot;: { \u0026quot;SAGEMAKER_PROGRAM\u0026quot;: \u0026quot;/opt/program/hello_gpu.py\u0026quot; }, \u0026quot;ResourceConfig\u0026quot;: { \u0026quot;InstanceCount\u0026quot;: 1, \u0026quot;InstanceType\u0026quot;: \u0026quot;ml.g4dn.xlarge\u0026quot;, \u0026quot;VolumeSizeInGB\u0026quot;: 20 }, \u0026quot;StoppingCondition\u0026quot;: { \u0026quot;MaxRuntimeInSeconds\u0026quot;: 12345, \u0026quot;MaxWaitTimeInSeconds\u0026quot;: 12345 } }, \u0026quot;End\u0026quot;: true } } }  ç´°ã‹ã„è¨­å®šå†…å®¹ã«é–¢ã—ã¦ã¯ï¼ŒCreateTrainingJob ã¨ã„ã†ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚è€ƒä¸‹ã•ã„ï¼\nã“ã“ã§ï¼ŒEnvironmentï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰ã®ã€ŒSAGEMAKER_PROGRAMã€ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãŠãã¾ã™ï¼ã“ã®å¤‰æ•°ã«æŒ‡å®šã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯Training Jobã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nå…ƒã€…ã¯ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã®ã§ã™ãŒï¼ˆtrain.pyãŒã‚ã‚Œã°ãã‚ŒãŒå¯¾è±¡ã¨ãªã‚‹ï¼‰ï¼Œå®Ÿè¡Œã—ãŸã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ä»»æ„ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n docker run \u0026lt;ã‚¤ãƒ¡ãƒ¼ã‚¸\u0026gt; train\n ãŸã ã—ï¼Œå®Ÿè¡Œæ¨©é™ã‚’ä¸ãˆã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã®ã§ï¼ŒDockerfileå†…ã§RUN chmod +x $PROGRAM_DIR/hello_gpu.pyã¨ã—ã¦ã„ã¾ã™ï¼\nã‚ã¨ã¯ï¼Œå®Ÿè¡Œçµæœã‚’CloudWatch Logsã§ç¢ºèªã—ã¦ï¼Œä»¥ä¸‹ã®å†…å®¹ãŒãƒ­ã‚°ã«å‡ºåŠ›ã•ã‚Œã¦ã„ã‚Œã°OKã§ã™ï¼\n GPUs Available: True Num GPUs Available: 1\n ãŠã‚ã‚Šã« ä»Šå›ã¯ï¼ŒStep Functionsã§SageMakerã®Training Jobã‚’ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦GPUç’°å¢ƒã§å‹•ã‹ã™æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã—ãŸï¼ã“ã®æ–¹æ³•ã‚’ä½¿ãˆã°ï¼Œæ·±å±¤å­¦ç¿’ãªã©ã®GPUç’°å¢ƒã‚’å¿…è¦ã¨ã—ãŸå­¦ç¿’ã‚‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ï¼ã¾ãŸï¼ŒTraining Jobã‚’ä½¿ã£ãŸå­¦ç¿’ãŒã§ãã‚Œã°ï¼Œå®Ÿé¨“çµæœã¯SageMaker Experimentsã«ä¿å­˜ã•ã‚Œã‚‹ã®ã§ï¼Œå†ç¾æ€§ã‚’æ‹…ä¿ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼\nStep Functionsã§ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦GPUç’°å¢ƒã§å­¦ç¿’ã•ã›ãŸã„å ´åˆã«ã¯ï¼Œå‚è€ƒã«ã—ã¦é ‚ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\nå‚è€ƒ  Available SageMaker Studio Instance Types Amazon SageMakerã®æ–™é‡‘ NVIDIA Docker ã£ã¦ä»Šã©ã†ãªã£ã¦ã‚‹ã®ï¼Ÿ (20.09 ç‰ˆ) What is AWS Step Functions?  ","date":"2022-01-30","permalink":"https://masatakashiwagi.github.io/portfolio/post/aws-stepfunctions-gpu-setting-for-sagemaker-jobs/","tags":["AWS","Dev"],"title":"Step Functionsã§è‡ªä½œDockerfileã‚’ä½¿ã£ã¦SageMakerã®GPUãƒã‚·ãƒ³ã‚’å‹•ã‹ã™æ–¹æ³•"},{"content":"ã¯ã˜ã‚ã« Step Functionsã§SageMakerã®ProceesingJobã‚’ä½¿ã£ã¦ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚’å®Ÿè¡Œã—ãŸéš›ã«ï¼Œãã®å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§ExperimentAnalyticsã®APIã‚’ä½¿ç”¨ã—ã¦ã„ãŸã¨ã“ã‚ï¼Œã€ŒValueError: Must setup local AWS configuration with a region supported by SageMaker.ã€ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã®ã§ï¼Œãã®å¯¾å‡¦æ–¹æ³•ã‚’ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ï¼\nçµè«–ã‹ã‚‰è¨€ã†ã¨ï¼Œã‚¨ãƒ©ãƒ¼å†…å®¹ã«ã‚ã‚‹é€šã‚Šã€Œregionã€ã®æŒ‡å®šã‚’è¡Œã†ã“ã¨ã§è§£æ±ºã§ãã¾ã™ï¼\næ–¹æ³•ã¨ã—ã¦ã¯2ã¤ã‚ã‚Šã¾ã™ï¼\n ã€Œboto_sessionï¼Œsagemaker_clientã€ã®ã€Œregion_nameã€ã‚’æŒ‡å®šã™ã‚‹ ç’°å¢ƒå¤‰æ•°ã«ã€ŒAWS_DEFAULT_REGIONã€ã‚’è¨­å®šã™ã‚‹  2ã¤ç›®ã®æ–¹æ³•ã®Step Functionsã®å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã«ç’°å¢ƒå¤‰æ•°: AWS_DEFAULT_REGIONã‚’1è¡Œè¿½è¨˜ã™ã‚‹ã®ãŒç°¡å˜ã‹ã¨æ€ã„ã¾ã™ï¼\nConfiguration Error SageMaker Experimentsã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å®Ÿé¨“çµæœã¯sagemaker.analytics.ExperimentAnalyticsã®APIä½¿ã†ã“ã¨ã§å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ä»Šå›ï¼ŒStep Functionsã§SageMakerã®ProceesingJobã‚’ä½¿ã£ã¦ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚’å®Ÿè¡Œã—ãŸéš›ã«ï¼Œä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼\n ValueError: Must setup local AWS configuration with a region supported by SageMaker.\n Configurationã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã‚‹ã¨ä»¥ä¸‹ã®ã“ã¨ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ï¼\n Configuration - Overview Boto3 looks at various configuration locations until it finds configuration values. Boto3 adheres to the following lookup order when searching through sources for configuration values:\n A Config object that\u0026rsquo;s created and passed as the config parameter when creating a client Environment variables The ~/.aws/config file   ä¸Šã‹ã‚‰é †ç•ªã«å„ªå…ˆåº¦ãŒé«˜ã„ã‚‚ã®ã«ãªã£ã¦ã„ã¦ï¼Œä¸‹ä½ã§è¨­å®šã—ã¦ã„ã‚‹å†…å®¹ã‚ˆã‚Šã‚‚ä¸Šä½ã§è¨­å®šã—ãŸå†…å®¹ãŒåæ˜ ã•ã‚Œã¾ã™ï¼\nä»Šå›ã®å ´åˆã¯ï¼Œ1ç•ªç›®ã¨2ç•ªç›®ã¯ç‰¹æ®µè¨­å®šã—ã¦ã„ãªã„ã®ã§ï¼Œ3ç•ªç›®ãŒæ¡ç”¨ã•ã‚Œã¦å•é¡Œãªã„ã‹ãªã¨æ€ã£ã¦ã„ã¾ã—ãŸãŒï¼Œä¸Šè¿°ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼AWSã®ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«æƒ…å ±ï¼ˆconfig, credentialsï¼‰ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®~/.aws/é…ä¸‹ã«ç½®ã‹ã‚Œã¦ãŠã‚Šï¼Œbuildæ™‚ã«ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’volumesãƒã‚¦ãƒ³ãƒˆã—ã¦ã‚³ãƒ³ãƒ†ãƒŠå†…ã¨åŒæœŸã—ã¦ã„ã¾ã™ï¼\nã“ã®è¨­å®šã§ã¯ä¸Šæ‰‹ãã„ã‹ãªã‹ã£ãŸã®ã§ï¼Œ1ç•ªç›®or2ç•ªç›®ã®è¨­å®šã‚’è¡Œã£ãŸã¨ã“ã‚æ­£å¸¸ã«å‹•ä½œã—ãŸã®ã§ï¼Œã“ã¡ã‚‰ã®æ–¹æ³•ã‚’è¨˜è¼‰ã—ã¦ãŠãã¾ã™ï¼ã‚‚ã—ï¼Œvolumesãƒã‚¦ãƒ³ãƒˆã®æ–¹æ³•ã§ä¸Šæ‰‹ãã„ãæ–¹æ³•ãŒã‚ã‚Œã°æ•™ãˆã¦ä¸‹ã•ã„ï¼\nConfig objectã‚’boto3 clientã«æ¸¡ã™æ–¹æ³• å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å„ªå…ˆåº¦ãŒ1ç•ªé«˜ã„æ–¹æ³•ã«ãªã‚Šã¾ã™ï¼botocore.config.Configã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¦ä½¿ã†ã“ã¨ã§è§£æ±ºã™ã‚‹æ–¹æ³•ã«ãªã‚Šã¾ã™ãŒï¼Œä»Šå›ã¯ã‚ã–ã‚ã–Config objectã‚’ä½¿ã‚ãšã«region_nameã‚’æŒ‡å®šã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ï¼\nimport boto3 import sagemaker # sessionã¨clientã®è¨­å®šã‚’è¡Œã† boto_session = boto3.session.Session(region_name=\u0026quot;ap-northeast-1\u0026quot;) sagemaker_client = boto_session.client(service_name='sagemaker', region_name=\u0026quot;ap-northeast-1\u0026quot;) sagemaker_session = sagemaker.session.Session(boto_session=boto_session, sagemaker_client=sagemaker_client) # ExperimentAnalyticsã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹ trial_component_analytics = sagemaker.analytics.ExperimentAnalytics( experiment_name='sample-experiments01', sagemaker_session=sagemaker_session ) # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ– analytics_tables = trial_component_analytics.dataframe()  ã‚³ãƒ¼ãƒ‰ã®æµã‚Œã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n boto_sessionã¨sagemaker_clientã‚’ä½œæˆã™ã‚‹ sagemaker.session.Sessionã®å¼•æ•°ã«ãã‚Œãã‚Œã‚’æ¸¡ã™ sagemaker_sessionã‚’sagemaker.analytics.ExperimentAnalyticsã®å¼•æ•°ã«æ¸¡ã™ å–å¾—ã—ãŸå®Ÿé¨“çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–ã™ã‚‹  ã“ã“ã§ï¼Œæœ€åˆã®ã€Œboto_sessionã¨sagemaker_clientã‚’ä½œæˆã™ã‚‹ã€éƒ¨åˆ†ã§ï¼Œã€Œboto3.session.Sessionã®region_nameã€ã¨ã“ã®sessionã‚’ä½¿ã£ãŸã€Œclientã®region_nameã€ã«è©²å½“ã™ã‚‹regionã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ã“ã®2ã¤ã‚’ã‚»ãƒƒãƒˆã—ã¦ãŠãã“ã¨ã§ï¼Œä»Šå›ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nã“ã®å ´åˆã¯ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã§å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¿®æ­£å¤‰æ›´ãŒå¿…è¦ã«ãªã£ã¦ãã¾ã™ãŒï¼Œæ¬¡ã«èª¬æ˜ã™ã‚‹ç’°å¢ƒå¤‰æ•°ã«æ¸¡ã™æ–¹æ³•ã¯ã“ã®è¾ºã‚Šã®ä¿®æ­£ã¯å¿…è¦ãªã„ã®ã§ï¼Œç°¡å˜ã‹ãªã¨æ€ã„ã¾ã™ï¼\nç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹æ–¹æ³• Step Functionsã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã™ã‚‹jsonãƒ•ã‚¡ã‚¤ãƒ«ã®Environmentå¤‰æ•°ã«ã€ŒAWS_DEFAULT_REGIONã€ã‚’è¨­å®šã™ã‚‹æ–¹æ³•ã«ãªã‚Šã¾ã™ï¼\nStep Functionsã®å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿éƒ¨åˆ†ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã™ï¼ï¼ˆä»Šå›ã¯SageMakerã®ProcessingJobã‚’ä½¿ã£ã¦å®Ÿè¡Œã—ã¦ã„ã¾ã™ï¼‰\n\u0026quot;Parameters\u0026quot;: { \u0026quot;AppSpecification\u0026quot;: { \u0026quot;ImageUri\u0026quot;: \u0026quot;hogehoge.dkr.ecr.ap-northeast-1.amazonaws.com/mlops-experiments:latest\u0026quot;, \u0026quot;ContainerEntrypoint\u0026quot;: [ \u0026quot;python3\u0026quot;, \u0026quot;/opt/ml/code/get_experiments.py\u0026quot; ] }, \u0026quot;Environment\u0026quot;: { \u0026quot;AWS_DEFAULT_REGION\u0026quot;: \u0026quot;ap-northeast-1\u0026quot; } }  ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¸­èº«ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼sessionã®è¨­å®šãŒå¿…è¦ãªããªã‚Šã¾ã™ï¼\nimport sagemaker # ExperimentAnalyticsã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹ trial_component_analytics = sagemaker.analytics.ExperimentAnalytics( experiment_name='sample-experiments01' ) # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ– analytics_tables = trial_component_analytics.dataframe()  ãŠã‚ã‚Šã« ä»Šå›ã¯ï¼ŒStep Functionsã§SageMakerã®ProceesingJobã‚’ä½¿ã£ãŸéš›ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦æ–¹æ³•ã‚’å‚™å¿˜éŒ²ã¨ã—ã¦æ®‹ã—ãŸã‚‚ã®ã«ãªã‚Šã¾ã™ï¼\nConfigurationã®è¨­å®šã«å„ªå…ˆé †ä½ãŒã‚ã‚‹ã“ã¨ã‚’çŸ¥ã£ãŸã®ã§ï¼Œã“ã®è¾ºã‚Šã¯ä»Šå›ã«é™ã‚‰ãšæ³¨æ„ãŒå¿…è¦ã ãªã¨æ€ã„ã¾ã—ãŸï¼ä»Šå›ã®ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹å¯¾å‡¦æ–¹æ³•ã¯è¤‡æ•°ã‚ã‚‹ã®ã§ï¼Œé–‹ç™ºã—ã¦ã„ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ä½¿ã„åˆ†ã‘ã¦ã„ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\nã‚ã¨ï¼Œå€‹äººçš„ã«ã¯å®Ÿè¡Œã—ã¦ã„ã‚‹Step Functionsã®regionã‚’ã‚»ãƒƒãƒˆã—ã¦æ¬²ã—ã„æ°—æŒã¡ã‚‚ã‚ã‚Šã¾ã™ãŒï¼Œã¾ãƒ¼ã“ã‚Œã¯çŠ¶æ³æ¬¡ç¬¬ãªã®ã§ï¼Œãªã‚“ã¨ã‚‚è¨€ãˆãªã„æ°—ã‚‚ã—ã¾ã™\u0026hellip;\nå‚è€ƒ  Boto3 Docs - Configuration How to fix aws region error \u0026ldquo;ValueError: Must setup local AWS configuration with a region supported by SageMaker\u0026rdquo;  ","date":"2021-12-26","permalink":"https://masatakashiwagi.github.io/portfolio/post/value-error-local-aws-configuration/","tags":["Dev","AWS"],"title":"ValueError: Must setup local AWS configurationã®å¯¾å‡¦æ–¹æ³•"},{"content":"ã¯ã˜ã‚ã« ä»Šå›ã¯ï¼Œteamayaã¨ã„ã†å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§é€²ã‚ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿é€£æºã®è©±ã«ãªã‚Šã¾ã™ï¼ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã«ç½®ã„ã¦ã‚ã‚‹ã®ã§ï¼Œã”è‡ªç”±ã«ä½¿ç”¨ä¸‹ã•ã„ï¼\n å…·ä½“çš„ã«ã¯ï¼Œæ‰‹å…ƒã«ã‚ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã®ç‰¹å®šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«é€£æºã™ã‚‹ã¾ã§ã®è©±ã«ãªã‚Šã¾ã™ï¼\næ™®æ®µå®¶è¨ˆç°¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ‰‹å…¥åŠ›ã§ç®¡ç†ã—ã¦ã‚‹ã‚“ã§ã™ãŒï¼Œãã®ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã«é›†ã‚ã¦è‰²ã€…ã¨æ¤œè¨¼ã§ãã‚‹ã¨è‰¯ã„ãªãƒ¼ã¨ã„ã†æ€ã„ã‹ã‚‰ï¼Œãƒ‡ãƒ¼ã‚¿é€£æºã‚’å§‹ã‚ã¾ã—ãŸï¼åŠ ãˆã¦ï¼Œå¯è¦–åŒ–ã‚‚è‰¯ãã—ãŸã„æ€ã„ã‚‚ã‚ã‚Šï¼ŒData Studioã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œã£ãŸã‚Šã‚‚ã—ã¦ã„ã¾ã™ï¼\nãƒ‡ãƒ¼ã‚¿é€£æºã‚’ã™ã‚‹ã ã‘ã§ã‚ã‚Œã°ï¼ŒEmbulkã‚’å˜ä½“å®Ÿè¡Œã™ã‚‹ã®ã§ã“ã¨è¶³ã‚Šã¾ã™ãŒï¼Œä»Šå›ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ç«‹ã¡ä¸Šã’ãŸDigdag UIã‚’ä½¿ã£ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ï¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œï¼Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ã‚„å±¥æ­´ç®¡ç†ãªã©ãŒUIã‹ã‚‰ã ã¨ã—ã‚„ã™ãï¼Œä½¿ã„å¿ƒåœ°ãªã©ã‚’çŸ¥ã‚‹ãŸã‚ã«ã‚‚ä½¿ç”¨ã—ã¾ã—ãŸï¼\nã¾ãŸï¼ŒDockerç’°å¢ƒã§å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«æ§‹æˆã—ã¦ã„ã¾ã™ï¼DockeråŒ–ã™ã‚‹ã“ã¨ã§ï¼Œç°¡å˜ã«åˆ¥ç’°å¢ƒã«æŒã£ã¦ã„ãã“ã¨ãŒã§ãã¾ã™ã—ï¼Œã‚¹ã‚¯ãƒ©ãƒƒãƒ—\u0026amp;ãƒ“ãƒ«ãƒ‰ãŒã—ã‚„ã™ã„ã®ã‚‚ã‚ã‚Šã¾ã™ï¼\nä»Šå›ã¯ä»¥ä¸‹ã®2ç¨®é¡ã®æ–¹æ³•ã§ãƒ‡ãƒ¼ã‚¿ã‚’é€£æºã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ï¼å†…å®¹çš„ã«ã¯æ—¢ã«æŠ€è¡“è¨˜äº‹ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚‚ã®ãŒå¤šã„ã¨æ€ã„ã¾ã™ãŒï¼Œä»Šå›ã¯Dockerã‚³ãƒ³ãƒ†ãƒŠã§å„ã‚¿ã‚¹ã‚¯ãŒå®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã®ã§ï¼Œãã®è¾ºã‚Šã‚’å‚è€ƒé ‚ã‘ãŸã‚‰ã¨æ€ã„ã¾ã™ï¼\n Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰Embulkã‚’ç›´æ¥å®Ÿè¡Œã—ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚’è»¢é€ã™ã‚‹æ–¹æ³• Digdag UIã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚’è»¢é€ã™ã‚‹æ–¹æ³•  ã“ã¡ã‚‰ã‚‚è£å´ã§ã¯ï¼ŒEmbulkãŒå®Ÿè¡Œã•ã‚Œã¾ã™ï¼    ä»Šå›ã®ãƒ‡ãƒ¼ã‚¿é€£æºãƒ•ãƒ­ãƒ¼ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã™ï¼\nã‚¢ãƒ³ãƒ‰ãƒªãƒ¥ãƒ¼ãƒ»ã‚«ãƒ¼ãƒã‚®ãƒ¼ã®ä»¥ä¸‹ã®åè¨€ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«ï¼Œæ©Ÿæ¢°å­¦ç¿’ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’è‡ªåˆ†ã§ä½œã£ã¦ã„ããŸã‚ã«ï¼Œä¸€æ­©ä¸€æ­©é€²ã‚ã¦ã„ã¾ã™ï¼\n æœ€ã‚‚é«˜ã„ç›®æ¨™ã‚’é”æˆã™ã‚‹ã«ã¯ã€ä¸€æ­©ä¸€æ­©é€²ã‚€ã—ã‹ãªã„ã¨ã„ã†äº‹å®Ÿã‚’ã€é ­ã«å…¥ã‚Œã¦ãŠã‹ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\n BigQueryã¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®è¨­å®š GCPã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™»éŒ²æ–¹æ³•ã¯å‰²æ„›ã—ã¾ã™ãŒï¼ŒgmailãŒã‚ã‚Œã°ç°¡å˜ã«ç™»éŒ²ã§ãã¾ã™ï¼ç™»éŒ²ãŒå®Œäº†ã—ãŸã‚‰ï¼Œé©å½“ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¦ä¸‹ã•ã„ï¼\nGoogle Sheets APIã®æœ‰åŠ¹åŒ–ã‚’è¡Œã† ã€ŒAPIã¨ã‚µãƒ¼ãƒ“ã‚¹ã€ â†’ ã€Œãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ã¨ç”»é¢é·ç§»ã—ï¼Œæ¤œç´¢çª“ã«ã€ŒGoogle Sheets APIã€ã¨å…¥åŠ›ã—ã¦æ¤œç´¢ã™ã‚‹ã¨ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®APIã‚’æœ‰åŠ¹åŒ–ã§ãã‚‹ç”»é¢ã«é·ç§»ã™ã‚‹ã®ã§ï¼Œæœ‰åŠ¹åŒ–ã‚’è¡Œã„ã¾ã™ï¼ã“ã“ã§æœ‰åŠ¹åŒ–ã—ã¦ãŠã‹ãªã„ã¨ï¼Œã“ã®å¾Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿é€£æºãŒå‡ºæ¥ãªã„ã®ã§æ³¨æ„ä¸‹ã•ã„ï¼\nã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä½œæˆ ãã‚ŒãŒçµ‚ã‚ã£ãŸã‚‰ï¼Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™ï¼ã€ŒIAMã¨ç®¡ç†ã€ â†’ ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€ã¸ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸå¾Œï¼Œå¿…è¦ãªæƒ…å ±ã‚’å…¥åŠ›ã—ï¼Œã‚­ãƒ¼ã®ä½œæˆã‹ã‚‰JSONã‚’é¸æŠã—ã¦ã‚­ãƒ¼ã®ä½œæˆã‚’è¡Œã„ã¾ã™ï¼ãã†ã™ã‚‹ã¨ï¼Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã®ã§ï¼Œã“ã‚Œã‚’~/.gcpé…ä¸‹ã«ç½®ã„ã¦ãŠãã¾ã™ï¼\nã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ç™»éŒ² ãƒ‡ãƒ¼ã‚¿é€£æºã—ãŸã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ãï¼Œå³ä¸Šã®å…±æœ‰ãƒœã‚¿ãƒ³ã‹ã‚‰ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ ã€ã®æ ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ã‚³ãƒ”ãƒ¼\u0026amp;ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ï¼Œé€ä¿¡ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ï¼ãã†ã™ã‚‹ã“ã¨ã§ï¼Œã“ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§è»¢é€ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nã“ã“ã§ï¼Œãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®è¨±å¯ã‚’ã—ã¦ã„ãªã„å ´åˆï¼ŒEmbulkå®Ÿè¡Œæ™‚ã«ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ï¼\n Error: (ClientError) forbidden: The caller does not have permission\n BigQueryã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã«ï¼Œäº‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã®ã§ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã‚’é©å½“ã«æ±ºã‚ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã‚’è¡Œã£ã¦ãŠãã¾ã™ï¼\n1. Embulkã‚’ç›´æ¥å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’è¡Œã†å ´åˆ ã“ã®æ–¹æ³•ã¯ï¼ŒDockerã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰Embulkã‚’ç›´æ¥å®Ÿè¡Œã—ã¦ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«è»¢é€ã™ã‚‹æ–¹æ³•ã«ãªã‚Šã¾ã™ï¼\nEmbulkã®ç´°ã‹ã„èª¬æ˜ã¯å‰²æ„›ã—ã¾ã™ãŒï¼Œç°¡å˜ã«è¨€ãˆã°ï¼Œãƒãƒ«ã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å½¹å‰²ã¨ã—ã¦BigQueryãªã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ã«ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ï¼\nãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’è¡Œã†ãŸã‚ã«ç”¨æ„ã™ã‚‹ã‚‚ã®ã¨ã—ã¦ã¯ï¼Œä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n Gemfile Liquidãƒ•ã‚¡ã‚¤ãƒ« Dockerfile \u0026amp; docker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«  Gemfileã‚’ç”¨æ„ã™ã‚‹ Embulkã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’Gemfile/Gemfile.lockã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã™ã‚‹ãŸã‚ã«ç”¨æ„ã—ã¾ã™ï¼Embulkã«ã¯ï¼Œãƒ‡ãƒ¼ã‚¿ã®Input/Outputã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãŒã‚ãƒªï¼Œã“ã‚Œã‚’ä½¿ã†ã“ã¨ã§æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’é€£æºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n Input: embulk-input-google_spreadsheets Output: embulk-output-bigquery  source 'https://rubygems.org/' # No versions are specified for 'embulk' to use the gem embedded in embulk.jar. # Note that prerelease versions (e.g. \u0026quot;0.9.0.beta\u0026quot;) do not match the statement. # Specify the exact prerelease version (like '= 0.9.0.beta') for prereleases. gem 'embulk' # input spreadsheets plugin gem 'embulk-input-google_spreadsheets' # ouput bigquery plugin gem 'embulk-output-bigquery' gem 'tzinfo-data'  Liquidãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ Embulkã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦Liquidãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã‚’è¨˜è¿°ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒï¼Œä»¥ä¸‹ã®ãƒ¡ãƒªãƒƒãƒˆã§Liquidãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼\n å¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ åŒã˜è¨­å®šå†…å®¹ã‚’å…±é€šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä½¿ã†ã“ã¨ãŒã§ãã‚‹ etc\u0026hellip;  BigQueryã¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æƒ…å ±ã¯ï¼Œ.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ï¼Œç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ç®¡ç†ã—ã¦ã„ã¾ã™ï¼ã“ã‚Œã‚‰ã®å¤‰æ•°ã‚’Liquidãƒ•ã‚¡ã‚¤ãƒ«ã§ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼\nin: type: google_spreadsheets auth_method: service_account {% comment %} GCPã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ {% endcomment %} json_keyfile: {{ env.GCP_SERVICE_JSON }} {% comment %} ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URL {% endcomment %} spreadsheets_url: {{ env.SPREADSHEETS_TABLE }} default_timezone: 'Asia/Tokyo' {% comment %} ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ« {% endcomment %} worksheet_title: year_purchase_amount_2019 {% comment %} headerã‚’æŒ‡å®šã—ã¦ã„ã‚‹å ´åˆã¯2è¡Œç›®ã‹ã‚‰ã¨ãªã‚‹ {% endcomment %} start_row: 2 {% comment %} ã‚«ãƒ©ãƒ åã¨å‹ã‚’æŒ‡å®šã™ã‚‹ {% endcomment %} columns: - {name: id, type: long} - {name: date, type: timestamp, format: '%Y/%m/%d', timezone: 'Asia/Tokyo'} - {name: category, type: string} - {name: purchaser, type: string} - {name: purchase_amount, type: long} - {name: memo, type: string} out: type: bigquery mode: replace auth_method: service_account json_keyfile: {{ env.GCP_SERVICE_JSON }} {% comment %} BigQueryã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå {% endcomment %} project: {{ env.BIGQUERY_PROJECT }} {% comment %} BigQueryã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå {% endcomment %} dataset: {{ env.BIGQUERY_PURCHASE_AMOUNT_DATASET }} {% comment %} BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«å {% endcomment %} table: daily_purchase_amount auto_create_table: true source_format: NEWLINE_DELIMITED_JSON default_timezone: 'Asia/Tokyo' default_timestamp_format: '%Y-%m-%d' formatter: {type: jsonl} encoders: - {type: gzip} retries: 3  envãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ã‚‚è£œè¶³ã§ã—ã¦ãŠãã¾ã™ï¼é©å®œè¨­å®šã—ã¦ã„ã‚‹ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¾ã™ï¼\nSPREADSHEETS_TABLE=\u0026lt;è©²å½“ã™ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URL: https://docs.google.com/spreadsheets/d/hogehoge\u0026gt; BIGQUERY_PROJECT=\u0026lt;BigQueryã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå\u0026gt; BIGQUERY_PURCHASE_AMOUNT_DATASET=\u0026lt;BigQueryã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå\u0026gt; GCP_SERVICE_JSON=/root/.gcp/hoge.json  Dockerfile \u0026amp; docker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ ä»Šå›ã¯dockerç’°å¢ƒã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã®ã§ï¼ŒDockerfileã¨docker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼ï¼ˆå¾Œã»ã©ä½¿ã†Digdagã®å†…å®¹ã‚‚è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ï¼‰\nFROM openjdk:8-alpine LABEL MAINTAINER=masatakashiwagi ENV DIGDAG_VERSION=\u0026quot;0.9.42\u0026quot; ENV EMBULK_VERSION=\u0026quot;0.9.23\u0026quot; RUN apk --update add --virtual build-dependencies \\ curl \\ tzdata \\ coreutils \\ bash \\ \u0026amp;\u0026amp; curl --create-dirs -o /bin/digdag -L \u0026quot;https://dl.digdag.io/digdag-${DIGDAG_VERSION}\u0026quot; \\ \u0026amp;\u0026amp; curl --create-dirs -o /bin/embulk -L \u0026quot;https://dl.embulk.org/embulk-$EMBULK_VERSION.jar\u0026quot; \\ \u0026amp;\u0026amp; chmod +x /bin/digdag \\ \u0026amp;\u0026amp; chmod +x /bin/embulk \\ \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime \\ \u0026amp;\u0026amp; apk del build-dependencies --purge ENV PATH=\u0026quot;$PATH:/bin\u0026quot; # Install libc6-compat for Embulk Plugins to use JNI # cf: https://github.com/jruby/jruby/wiki/JRuby-on-Alpine-Linux # https://github.com/classmethod/docker-embulk RUN apk --update add libc6-compat # Copy Embulk configuration COPY ./embulk/task /opt/workflow/embulk/task # Make bundle WORKDIR /opt/workflow/embulk RUN embulk mkbundle bundle # Copy Gemfile file # This is the workaround, because jruby directory is not created COPY ./embulk/bundle/Gemfile /opt/workflow/embulk/bundle COPY ./embulk/bundle/Gemfile.lock /opt/workflow/embulk/bundle WORKDIR /opt/workflow/embulk/bundle # Install Embulk Plugins RUN embulk bundle # Set up Digdag Server COPY ./digdag /opt/workflow/digdag # ADD https://github.com/ufoscout/docker-compose-wait/releases/download/2.9.0/wait /bin/wait # RUN chmod +x /bin/wait WORKDIR /opt/workflow CMD [\u0026quot;tail\u0026quot;, \u0026quot;-f\u0026quot;, \u0026quot;/dev/null\u0026quot;]  bundleè¾ºã‚Šã§ã¾ã‚ã‚Šãã©ã„ã‚„ã‚Šæ–¹ã‚’ã—ã¦ã„ã¾ã™ãŒï¼ŒRUN embulk bundleã‚’å®Ÿè¡Œã—ãŸéš›ã«ä¸Šæ‰‹ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã‹ã£ãŸãŸã‚ï¼Œãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ©ã‚¦ãƒ³ãƒ‰ã¨ã—ã¦ï¼Œmkbundleã—ãŸå¾Œã«Gemfile/Gemfile.lockã‚’dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã«COPYã—ãŸä¸Šã§ï¼ŒRUN embulk bundleã‚’è¡Œã£ã¦ã„ã¾ã™ï¼\nEmbulkã‚’dockerã‚³ãƒ³ãƒ†ãƒŠã§å®Ÿè¡Œã™ã‚‹æ–¹æ³• ã§ã¯ï¼Œå®Ÿéš›ã«Embulkã®å®Ÿè¡Œã‚’è¡Œã†ãŸã‚ã«ï¼Œã¾ãšã¯Embulkã®ã‚³ãƒ³ãƒ†ãƒŠã‚µãƒ¼ãƒ“ã‚¹ã‚’ç«‹ã¡ä¸Šã’ã¾ã™ï¼\n# ã‚³ãƒ³ãƒ†ãƒŠã®ç«‹ã¡ä¸Šã’ docker compose up -d embulk  ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ã¦ãŠãã¾ã™ï¼ãã®å¾Œï¼Œdry-runã‚’è¡Œã†ãŸã‚ã«previewã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ï¼\n# dry-run docker exec embulk sh /bin/embulk preview -b embulk/bundle embulk/task/spreadsheet/export_hab_purchase_amount.yml.liquid  dry-runå®Ÿè¡Œå¾Œã®çµæœã‚’è¼‰ã›ã¦ãŠãã¾ã™ï¼\ndry-runãŒå¤§ä¸ˆå¤«ã ã£ãŸå ´åˆï¼Œæœ¬ç•ªå®Ÿè¡Œã‚’è¡Œã„ã¾ã™ï¼æœ¬ç•ªã¯runã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ï¼\n# production-run docker exec embulk sh /bin/embulk run -b embulk/bundle embulk/task/spreadsheet/export_hab_purchase_amount.yml.liquid  æœ¬ç•ªå®Ÿè¡ŒãŒä¸Šæ‰‹ãã„ãã¨BigQueryã«ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã§ãã¾ã™ï¼\n2. Digdag UIã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’è¡Œã†å ´åˆ æ¬¡ã«èª¬æ˜ã™ã‚‹ã“ã¡ã‚‰ã®æ–¹æ³•ã¯ï¼Œdigdag serverã‚’ç«‹ã¡ä¸Šã’ã¦ï¼ŒUIä¸Šã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«è»¢é€ã™ã‚‹æ–¹æ³•ã«ãªã‚Šã¾ã™ï¼ï¼ˆè£ã§EmbulkãŒå‹•ã„ã¦ã„ã¾ã™ï¼‰\nDigdagã®ç´°ã‹ã„èª¬æ˜ã¯å‰²æ„›ã—ã¾ã™ãŒï¼Œç°¡å˜ã«è¨€ãˆã°ï¼Œè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒƒãƒã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å®šç¾©ãƒ»ç®¡ç†ã§ãã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã«ãªã‚Šã¾ã™ï¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã‚„å¤±æ•—æ™‚ã®é€šçŸ¥ãªã©ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ï¼\nDigdagã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’è¡Œã†ãŸã‚ã«ç”¨æ„ã™ã‚‹ã‚‚ã®ã¨ã—ã¦ã¯ï¼Œä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n digãƒ•ã‚¡ã‚¤ãƒ« serverã®propertiesãƒ•ã‚¡ã‚¤ãƒ« docker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«  ä¸Šè¨˜ã«åŠ ãˆã¦ï¼Œ1ã§èª¬æ˜ã—ãŸEmbulkå®Ÿè¡Œã«å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”¨æ„ã—ã¾ã™ï¼\ndigãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã™ã‚‹ å€‹åˆ¥ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å˜ç™ºå®Ÿè¡Œã™ã‚‹å ´åˆã¯ï¼Œdigdag run hoge.digã§è‰¯ã„ã®ã§ã™ãŒï¼Œä»Šå›ã¯UIã‹ã‚‰å®Ÿè¡Œã—ãŸã„ã®ã§ï¼Œå³å¯†ã«ã¯digãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ãŒè¦ã‚Šã¾ã™ï¼è¨˜è¿°ã™ã‚‹å†…å®¹ã¨ã—ã¦ã¯ï¼Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å®Ÿè¡Œã—ã¦ã„ãã‚¿ã‚¹ã‚¯ã‚’ã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—ã¦ã„ãã¾ã™ï¼\nDigdagã§ã¯ï¼Œã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚„æˆåŠŸã—ãŸå ´åˆã«ï¼Œã©ã†ã„ã£ãŸå‡¦ç†ã‚’ã™ã‚‹ã®ã‹ã‚’æ›¸ãã“ã¨ãŒã§ãã‚‹ã®ã§ï¼Œä¾‹ãˆã°ï¼Œãã‚Œãã‚Œã®å ´åˆã§slackã«é€šçŸ¥ã‚’è¡ŒãˆãŸã‚Šã‚‚ã§ãã¾ã™ï¼ˆä»Šå›ã¯slacké€šçŸ¥ã¯å®Ÿè£…ã§ãã¦ã„ã¾ã›ã‚“ãŒï¼Œä»Šå¾Œå®Ÿè£…ã—ã¦ã„ããŸã„ã§ã™ï¼ï¼‰ï¼ãƒªãƒˆãƒ©ã‚¤å›æ•°ã®è¨­å®šã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®è¨­å®šã‚‚ã“ã“ã§ã§ãã¾ã™ï¼\n+task: _retry: 1 sh\u0026gt;: /bin/embulk run -b /opt/workflow/embulk/bundle /opt/workflow/embulk/task/spreadsheet/export_hab_purchase_amount.yml.liquid _error: echo\u0026gt;: workflow error... +success: echo\u0026gt;: workflow success!  ä»Šå›ã¯ä»¥ä¸‹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãªã£ã¦ã„ã¾ã™ï¼\n task:  ãƒªãƒˆãƒ©ã‚¤å›æ•°: 1å› Embulkã®å®Ÿè¡Œ ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯workflow error...ã‚’echoã™ã‚‹   success:  workflow success!ã‚’echoã™ã‚‹    successã¯taskãŒæ­£å¸¸ã«çµ‚äº†ã—ãŸå ´åˆã«ï¼Œå®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼\nserverã®propertiesãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã™ã‚‹ ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã™ã‚‹ãŸã‚ã«ï¼Œå¼•æ•°ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã™ãŒï¼Œãã‚Œã‚‰ã®è¨­å®šã‚’server.propertiesãƒ•ã‚¡ã‚¤ãƒ«ã«é›†ç´„ã—ã¦ã„ã¾ã™ï¼è¨­å®šå†…å®¹ã¯è‰²ã€…ã¨ã‚ã‚‹ã®ã§è©³ã—ãã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: server-mode-commandsã‚’å‚ç…§ä¸‹ã•ã„ï¼\nã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ï¼Œã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ï¼\nserver.bind = 0.0.0.0 server.port = 65432 server.admin.bind = 0.0.0.0 server.admin.port = 65433 server.access-log.pattern = json server.access-log.path = /var/log/digdag/access_logs log-server.type = local # databaseæƒ…å ± # database.type = memory database.type = postgresql database.user = digdag database.password = digdag database.host = postgres database.port = 5432 database.database = digdag database.maximumPoolSize = 32  ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã™ã‚‹ã¨ï¼Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ï¼Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è¨­å®šãŒå¿…è¦ã«ãªã£ã¦ãã¾ã™ï¼ä»Šå›ã¯PostgreSQLã‚’åˆ¥ã‚³ãƒ³ãƒ†ãƒŠã§ç«‹ã¦ã¦ï¼ŒDigdagã‚³ãƒ³ãƒ†ãƒŠã¨æ¥ç¶šã™ã‚‹ã“ã¨ã«ã—ã¦ã„ã¾ã™ï¼ã¡ãªã¿ã«ï¼Œã“ã‚Œã‚‰ã®æƒ…å ±ã‚’ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã§ä¿å­˜ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼ˆã“ã®å ´åˆã¯ï¼Œdatabase.type = memoryã¨ã—ã¦ä¸‹ã•ã„ï¼‰ï¼\ndocker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ è‰²ã€…ã¨è©¦ã—ã¦ä¸Šæ‰‹ãã„ã‹ãªã‹ã£ãŸã®ã§ã™ãŒï¼Œæœ€çµ‚çš„ã«ã¯ä»¥ä¸‹ã®å†…å®¹ã§è½ã¡ç€ãã¾ã—ãŸï¼serviceå…±é€šã®å®šç¾©ã¯x-templateã«ã¾ã¨ã‚ã¦ã„ã¾ã™ï¼serviceã¯3ã¤ã‚ã‚Šã¾ã™ãŒï¼ŒDigdagã‚’ä½¿ã†å ´åˆã¯digdagã¨postgresã®ã¿ã‚’ç«‹ã¡ä¸Šã’ã¦ä½¿ã„ã¾ã™ï¼\ndockerã®depends_onã¯ä¾å­˜é–¢ä¿‚ï¼ˆèµ·å‹•é †åºï¼‰ã‚’æŒ‡å®šã§ãã¾ã™ãŒï¼ŒDBèµ·å‹•å¾Œã®ã‚¢ãƒ—ãƒªèµ·å‹•ã¾ã§ã‚’åˆ¶å¾¡ã§ãã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ï¼Œpostgresã®èµ·å‹•å®Œäº†å‰ã«digdagãŒã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã—ã¾ã„èµ·å‹•å¤±æ•—ã™ã‚‹äº‹ãŒã‚ã‚Šã¾ã™ï¼\n Control startup and shutdown order in Compose  ã“ã®ãŸã‚ï¼Œcondition: service_startedã¨è¨­å®šã™ã‚‹ã“ã¨ã§ï¼ŒpostgresãŒèµ·å‹•å¾Œã«digdagãŒç«‹ã¡ä¸ŠãŒã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼\ndepends_on: postgres: condition: service_started  ã¾ãŸï¼Œttyã‚’trueã«è¨­å®šã—ã¦ã„ã‚‹ã®ã¯ï¼Œã‚³ãƒ³ãƒ†ãƒŠãŒæ­£å¸¸çµ‚äº†ã—ã¦æ­¢ã¾ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ãªã‚Šã¾ã™ï¼\nversion: '3.8' # Common definition x-template: \u0026amp;template volumes: - ~/.gcp:/root/.gcp:cached - /tmp:/tmp env_file: - .env services: digdag: container_name: digdag build: . tty: true ports: - 65432:65432 - 65433:65433 volumes: - /var/run/docker.sock:/var/run/docker.sock command: [\u0026quot;java\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;/bin/digdag\u0026quot;, \u0026quot;server\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;digdag/server.properties\u0026quot;, \u0026quot;--log\u0026quot;, \u0026quot;/var/log/digdag/digdag_server.log\u0026quot;, \u0026quot;--task-log\u0026quot;, \u0026quot;/var/log/digdag/task_logs\u0026quot;] depends_on: postgres: condition: service_started \u0026lt;\u0026lt;: *template postgres: image: postgres:13.1-alpine container_name: postgres ports: - 5432:5432 environment: POSTGRES_DB: digdag POSTGRES_USER: digdag POSTGRES_PASSWORD: digdag volumes: - /tmp/data:/var/lib/postgresql/data tty: true \u0026lt;\u0026lt;: *template embulk: container_name: embulk build: . \u0026lt;\u0026lt;: *template networks: default: external: name: teamaya  Digdagã‚’dockerã‚³ãƒ³ãƒ†ãƒŠã§å®Ÿè¡Œã™ã‚‹æ–¹æ³• ã§ã¯ï¼ŒDigdag UIã‚’ä½¿ã†ãŸã‚ã«Digdagã‚’ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ï¼\n# ã‚³ãƒ³ãƒ†ãƒŠã®ç«‹ã¡ä¸Šã’ docker compose up -d digdag  ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ã¦ãŠãã¾ã™ï¼docker psã‚³ãƒãƒ³ãƒ‰ã§ã‚³ãƒ³ãƒ†ãƒŠãŒç«‹ã¡ä¸ŠãŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã‚‰ï¼Œhttp://localhost:65432/ã§UIã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ï¼ä»¥ä¸‹ã®ç”»é¢ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰OKã§ã™ï¼\nNew projectã‹ã‚‰Nameã‚’è¨­å®šã—ãŸã‚‰ï¼ŒAdd fileã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ï¼Œdigãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼\u0026amp;ãƒšãƒ¼ã‚¹ãƒˆã—ã¾ã™ï¼è²¼ã‚Šä»˜ã‘ãŸã‚‰ï¼ŒSaveã§å†…å®¹ã‚’ä¿å­˜ã—ã¾ã™ï¼ãã—ãŸã‚‰ï¼ŒWorkflowsã®ã‚¿ãƒ–ã‚’é¸æŠã—ï¼Œå…ˆã»ã©è¿½åŠ ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã®ã§ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ï¼å³ä¸Šã®Runãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å®Ÿè¡ŒãŒå®Œäº†ã™ã‚‹ã¨ï¼Œä¸‹å›³ã®ã‚ˆã†ãªçµæœã«ãªã‚Šã¾ã™ï¼\nStatusãŒSuccessã«ãªã£ã¦ã„ã‚Œã°ï¼Œæ­£å¸¸çµ‚äº†ã§BigQueryã«ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹ã¨æ€ã†ã®ã§ï¼Œç¢ºèªã—ã¦ã¿ã¦ä¸‹ã•ã„ï¼\nãŠã‚ã‚Šã« ä»Šå›ã¯ï¼Œæ‰‹å…ƒã«ã‚ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’Digdag/Embulkã‚’ç”¨ã„ã¦BigQueryã«é€£æºã™ã‚‹ã‚’ç´¹ä»‹ã—ã¾ã—ãŸï¼\nã‚„ã£ã±ã‚Šï¼ŒUIã§ç›´æ„Ÿçš„ã«çŠ¶æ³ã‚„æƒ…å ±ãŒã‚ã‹ã‚‹ã®ã¯ãƒ¡ãƒªãƒƒãƒˆã ãªã¨æ€ã„ã¾ã™ï¼è¤‡æ•°ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå‹•ä½œã—ãŸã‚Šã™ã‚‹ç’°å¢ƒã ã¨ãã‚Œã‚‰ã‚‚ç®¡ç†ã§ãã‚‹ã®ã§è‰¯ã„ã¨æ€ã„ã¾ã™ï¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã‚„ã‚¨ãƒ©ãƒ¼ã‚„æˆåŠŸæ™‚ã®é€šçŸ¥è¨­å®šãªã©ã‚‚å‡ºæ¥ã‚‹ã®ã§æ´»ç”¨ã—ãŸã„ã¨æ€ã„ã¾ã™ï¼\nã¾ãŸä»Šå›ã¯ï¼Œãƒ‡ãƒ¼ã‚¿é€£æºã«Digdagã‚’ç”¨ã„ã¾ã—ãŸãŒï¼Œä»–ã«ã‚‚Apache Airflowã‚„ãã®ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚‹Cloud Composerã‚’ä½¿ã£ã¦ã‚‚åŒç­‰ã®ã“ã¨ãŒã§ãã‚‹ã¨æ€ã„ã¾ã™ï¼ã“ã®è¾ºã‚Šã‚‚åˆ¥é€”è©¦ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼\nå€‹äººçš„ãªæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã¯ï¼ŒDataformã‚„dbtã‚’ä½¿ã£ãŸã€Œãƒ‡ãƒ¼ã‚¿ã®å“è³ªç®¡ç†ã€ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ï¼Œãƒ‡ãƒ¼ã‚¿ã‚’Transformã—ãŸã‚Šï¼Œãƒ†ã‚¹ãƒˆã—ãŸã‚Šã—ã¦è€ƒãˆã¦ã„ããŸã„ã§ã™ï¼ã¾ãŸï¼Œãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹/ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ãƒˆã®è¨­è¨ˆãªã©ã‚’ä½µã›ã¦å­¦ç¿’ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼\nã“ã‚Œã¨ã¯åˆ¥è»¸ã§æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆã‚‚ã—ã¦ã„ã“ã†ã‹ãªã¨è€ƒãˆã¦ã„ã¾ã™ï¼\nå‚è€ƒ  Digdag å…¥é–€ Embulkã¨Digdagã¨ãƒ‡ãƒ¼ã‚¿åˆ†æåŸºç›¤ã¨ digdagã‚’Dockerizeã—ã¦ECSä¸Šã§é‹ç”¨ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸ - é›‘ãªãƒ¡ãƒ¢ Docker Compose ã® depends_on ã®ä½¿ã„æ–¹ã¾ã¨ã‚ Dockerã®TTYã£ã¦ä½•?  ","date":"2021-12-22","permalink":"https://masatakashiwagi.github.io/portfolio/post/integrate-spreadsheets-to-bigquery-with-digdag/","tags":["Dev","Data"],"title":"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰BigQueryã¸Digdagã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿é€£æº"},{"content":"ã¯ã˜ã‚ã« æœ€è¿‘ï¼Œãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨MLOpsã®é ˜åŸŸã¸ã®é–¢å¿ƒãŒå€‹äººçš„ã«é«˜ã¾ã£ã¦ã„ã¦ï¼Œä½•ã‹å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å‡ºæ¥ãªã„ã‹ã¨è€ƒãˆã¦ã„ãŸã¨ã“ã‚ï¼Œæ™®æ®µã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§è¨˜éŒ²ã—ã¦ã„ã‚‹å®¶è¨ˆç°¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨MLOpsã®æŠ€è¡“æ¤œè¨¼ã‚’ã—ã‚ˆã†ã¨è¨€ã†è€ƒãˆã«è‡³ã‚Šã¾ã—ãŸï¼\nãã‚‚ãã‚‚ï¼Œãªã‚“ã§ä¸Šè¨˜é ˜åŸŸã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ããŸã‹ã¨ã„ã†ã¨ï¼Œä»¥å‰ã¾ã§ã¯ï¼Œã‚ã‚‹å•é¡Œè¨­å®šã«å¯¾ã—ã¦ï¼Œã©ã†ã„ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãã®å•é¡Œã‚’è§£ãã‹ã¨ã„ã£ãŸãƒ¢ãƒ‡ãƒªãƒ³ã‚°éƒ¨åˆ†ã«èˆˆå‘³ãŒã‚ã‚Šï¼Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚„æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©¦ã™ã¨ã„ã£ãŸéƒ¨åˆ†ãŒæ¥½ã—ã„ã¨æ„Ÿã˜ã¦ã„ã¾ã—ãŸï¼ä¸€æ–¹ã§æœ€è¿‘ã¯ï¼Œãã“ã§ä½œã£ãŸãƒ¢ãƒ‡ãƒ«ã¯ãã®ã¾ã¾ã§ã¯æ©Ÿèƒ½ã›ãšï¼Œä½•ã‚‰ã‹ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¼‰ã›ã¦å‹•ã‹ã—ç¶šã‘ã‚‹ã“ã¨ã§çœŸä¾¡ã‚’ç™ºæ®ã™ã‚‹ã¨æ€ã£ã¦ã„ã¾ã™ã—ï¼Œå‹•ã‹ã—ç¶šã‘ã¦ä½¿ã£ã¦ã„ã‹ãªã„ã¨æ„å‘³ãŒãªãï¼Œã›ã£ã‹ãä½œã£ãŸãƒ¢ãƒ‡ãƒ«ãŒã‚‚ã£ãŸã„ãªã„ãªãƒ¼ã¨ã„ã†æ°—æŒã¡ãŒã‚ã‚Šã¾ã™ï¼\næ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ åŒ–ã®ãŸã‚ã«ã¯ï¼Œã©ã†ã„ã£ãŸã“ã¨ã‚’çŸ¥ã£ã¦ãŠãã¨ã„ã„ã®ã‹ã‚’è€ƒãˆãŸå ´åˆï¼Œãƒ‡ãƒ¼ã‚¿é€£æºã‚’å«ã‚ãŸãƒ‡ãƒ¼ã‚¿ã‚’è²¯ã‚ã‚‹éƒ¨åˆ†ã¨ãƒ¢ãƒ‡ãƒ«ä½œæˆå¾Œã®MLOpséƒ¨åˆ†ã‚’ç†è§£ã—ã¦ãŠãã“ã¨ãŒå¤§äº‹ã ã¨æ€ã†ã®ã§ï¼Œã“ã“ã‚’ã‚ˆã‚Šæ·±ã‚ã¦è¡ŒããŸã„ã¨æ€ã£ãŸæ¬¡ç¬¬ã§ã™ï¼\nãƒ‡ãƒ¼ã‚¿é€£æºå‘¨ã‚Šã¯è‡ªåˆ†è‡ªèº«ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹éš›ã«ã‚‚ï¼Œã€Œç°¡å˜ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã›ã‚‹ï¼Œå“è³ªãŒä¿ãŸã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã€ã¨ã„ã†ã®ã¯å¤§äº‹ãªéƒ¨åˆ†ã§ã‚ã‚Šï¼Œä¸–ã®ä¸­çš„ã«ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹æµã‚Œã¯ã“ã‚Œã‹ã‚‰ã‚‚é€²ã‚“ã§ã„ãï¼Œãƒ‡ãƒ¼ã‚¿åŸºç›¤ã‚’ä½œã‚Œã‚‹äººã®ä¾¡å€¤ã¯ä¸ŠãŒã£ã¦ã„ãã¨æ€ã†ã®ã§ï¼Œã˜ã‚ƒã‚ãã“ã‚’è‡ªåˆ†ã§ã‚‚å‡ºæ¥ã‚‹ã‚ˆã†ã«ãªã£ã¦ãŠã“ã†ã¨ã„ã†æ€ã„ãŒã‚ã‚Šã¾ã™ï¼\nã‚‚ã†ä¸€ã¤ã®MLOpsã¯æ§‹æˆè¦ç´ ãŒè‰²ã€…ã‚ã‚ŠæŠ€è¡“çš„ã«ã‚‚èˆˆå‘³æ·±ã„ï¼ˆã‚µãƒ¼ãƒ“ã‚¹åã¨ã‹ã¯çŸ¥ã£ã¦ã‚‹ã‘ã©ï¼Œã©ã†ã‚„ã£ã¦ä½¿ã†ã®ï¼Ÿçš„ãªéƒ¨åˆ†ã‚‚ã‚ã‚Šã¾ã™ï¼‰ã®ã¨ï¼Œã¾ã ã¾ã ã“ã®åˆ†é‡ã®çŸ¥è¦‹ã¯æ—¥æœ¬ã§ã‚‚å¤šããªã„ãªã¨ã„ã†å°è±¡ãªã®ã§ï¼Œã—ã£ã‹ã‚Šç†è§£ã—ã¦ãŠãã¨ä»Šå¾Œã‚ˆã‚Šæ´»ãã¦ãã‚‹ã‹ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼\nãã†ã„ã£ãŸæµã‚Œã®ä¸­ã§ï¼Œç†è§£ã‚‚å«ã‚ã¦å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã§ãã‚‹ã“ã¨ã‚’ã—ãŸã„ã¨ã„ã†ãŠæ°—æŒã¡ãŒã§ã™ï¼\næŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã¨ã—ã¦ã¯ï¼Œæ™®æ®µBigQueryä»¥å¤–ã¯æ¥­å‹™ã§ã‚‚ã‚ã¾ã‚Šè§¦ã‚Œã‚‹æ©Ÿä¼šãŒãªã„Google Cloud Platform (GCP) ã®ã‚µãƒ¼ãƒ“ã‚¹ã¨OSSã‚’çµ„ã¿åˆã‚ã›ã¦ã§ãã‚‹ã“ã¨ã‚’ã—ã‚ˆã†ã¨è€ƒãˆã¦ã„ã¾ã™ï¼\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: teamaya ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å§‹ã‚ã‚‹ã«ã‚ãŸã‚Šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æ±ºã‚ã‚‹ã¨ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã®ã§ï¼Œæœ€åˆã«æ±ºã‚ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸï¼æ²–ç¸„å¥½ããªã®ã§ï¼Œæ²–ç¸„ã®è¨€è‘‰ã‚’çµ„ã¿åˆã‚ã›ã¦ä½•ã‹åå‰ã‚’ä»˜ã‘ãŸã„ã¨è€ƒãˆã¦ã„ã¦ï¼Œæ²–ç¸„çœŒã¨æ±äº¬éƒ½ã®ãƒãƒ¼ãƒ•ã§ã‚ã‚‹å¦»ã«ã‚‚ç›¸è«‡ã—ãªãŒã‚‰ä»Šå›ã®ã€Œteamayaã€ã¨è¨€ã†åå‰ã«ã—ã¾ã—ãŸï¼\ngithubã®ãƒªãƒã‚¸ãƒˆãƒªã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼ï¼ˆã‚¹ã‚¿ãƒ¼è²°ãˆã‚‹ã¨æ³£ã„ã¦å–œã³ã¾ã™ğŸ˜‚ï¼‰\n teamayaã¯\u0026quot;team\u0026ldquo;ã¨\u0026rdquo;maya\u0026ldquo;ã‚’çµ„ã¿åˆã‚ã›ãŸé€ èªã§ã™ï¼teamã¯ã€Œã€”å‹•ç‰©ã«å¼•ã‹ã›ã¦ï½ã‚’ã€•é‹ã¶ã€é‹æ¬ã™ã‚‹ã€ã¨ã„ã†æ„å‘³ãŒã‚ã‚Šï¼Œmayaï¼ˆãƒãƒ¤ãƒ¼ï¼‰ã¯æ²–ç¸„ã®æ–¹è¨€ã§çŒ«ã¨ã„ã†æ„å‘³ãŒã‚ã‚‹ã®ã§ï¼ŒçŒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’é‹ã‚“ã§è²°ã†ã¨ã„ã†æ„å‘³ã‚’è¾¼ã‚ã¦ã“ã®åå‰ã«ã—ã¾ã—ãŸï¼\nã¡ãªã¿ã«ï¼Œãƒªãƒã‚¸ãƒˆãƒªã«ã‚ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ãƒã‚¤ãƒ“ã‚¹ã‚«ã‚¹ğŸŒºã‚’ä»˜ã‘ãŸçŒ«ğŸ˜¸ã¯å¦»ã«æ›¸ã„ã¦è²°ã„ã¾ã—ãŸï¼\nã©ã†ã„ã£ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãªã®ã‹ ä»Šã®ã¨ã“ã‚è€ƒãˆã¦ã„ã‚‹ã®ã¯ï¼Œå¤§ãã2ã¤ã«ãªã‚Šã¾ã™ï¼\n ãƒ‡ãƒ¼ã‚¿é€£æº  ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã«é€£æº é€£æºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ELTãƒ„ãƒ¼ãƒ«ã§å¤‰æ› \u0026amp; ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç®¡ç† ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–   æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ å®Ÿé¨“ç®¡ç† ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° \u0026amp; é€šçŸ¥    ã¾ãšï¼Œãƒ‡ãƒ¼ã‚¿é€£æºã«ã¤ã„ã¦ã¯ï¼ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã‚¯ãƒ©ã‚¦ãƒ‰ã¸ã®é€£æºï¼Œç‰¹ã«ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰BigQueryã«é€£æºã™ã‚‹éƒ¨åˆ†ã‚’å®Ÿæ–½ã—ã¦ï¼Œãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ï¼ˆDWHï¼‰ã‚’ä½œã‚ã†ã¨æ€ã£ã¦ã„ã¾ã™ï¼ãã“ã‹ã‚‰ELTãƒ„ãƒ¼ãƒ«ã§ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ãƒˆï¼ˆDMï¼‰ã‚’ä½œæˆã—ï¼ŒBIãƒ„ãƒ¼ãƒ«ï¼ˆData Studioãªã©ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚’è¡Œã†ã¨ã„ã£ãŸæµã‚Œã‚’æ¤œè¨¼ã—ã‚ˆã†ã¨è€ƒãˆã¦ã„ã¾ã™ï¼\nå€‹äººçš„ã«ã¯ï¼ŒDataformã‚„dbtã¨ã„ã£ãŸã‚µãƒ¼ãƒ“ã‚¹ã§ELTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œã£ã¦ï¼Œãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚„ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç®¡ç†ã‚’ä¸€é€šã‚Šè©¦ã—ã¦ã¿ãŸã„ã¨æ€ã£ã¦ã„ã¾ã™ï¼\næ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«é–¢ã—ã¦ã¯ï¼Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆã®ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„å®Ÿé¨“ç®¡ç†ãªã©ã‚’è¡Œã„ã¤ã¤ï¼Œã‚³ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆã‚„ãƒ‡ãƒ¼ã‚¿ãƒ»äºˆæ¸¬çµæœã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãªã©ã‚’ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„ã®ã¨ï¼ŒFeastãªã©ã®feature storeã‚’è©¦ã—ãŸã‚Šã‚‚ã—ãŸã„ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼\nç¾çŠ¶ã§ã¯ä¸Šè¨˜2ã¤ã‚’æ§‹ç¯‰ã—ã¦ã„ããŸã„ã¨æ€ã£ã¦ã¾ã™ãŒï¼Œé€²ã‚ã¦ã„ãä¸­ã§èˆˆå‘³ãŒæ¹§ã„ãŸã‚‚ã®ã‚’é©å®œå–ã‚Šå…¥ã‚Œã¦ã„ããŸã„ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼\nãŠã‚ã‚Šã« ä»Šå›ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–°ã—ãå§‹ã‚ãŸã®ã§ï¼Œãã®ç´¹ä»‹ã«ãªã‚Šã¾ã™ï¼ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã‚¯ãƒ©ã‚¦ãƒ‰ã«ãƒ‡ãƒ¼ã‚¿é€£æºã™ã‚‹éƒ¨åˆ†ã«ã¤ã„ã¦ã¯ï¼Œæ—¢ã«ä½œæˆã—ã¦ã„ã‚‹ã®ã§åˆ¥é€”å†…å®¹ã‚’ç´¹ä»‹ã—ãŸã„ã¨æ€ã„ã¾ã™ï¼\nè©¦è¡ŒéŒ¯èª¤ã—ãªãŒã‚‰é¢ç™½ãã†ãªã‚‚ã®ã¯è‰²ã€…ã¨å–ã‚Šå…¥ã‚Œã¦é€²ã‚ã¦è¡ŒããŸã„ã¨æ€ã†ã®ã§ï¼Œã‚‚ã—é¢ç™½ã„ãƒ„ãƒ¼ãƒ«ãªã©ãŒã‚ã‚Œã°Twitterã§æ•™ãˆã¦é ‚ã‘ã‚Œã°å¬‰ã—ã„ã§ã™ï¼\nå‚è€ƒ  MLOps.toys  ","date":"2021-12-12","permalink":"https://masatakashiwagi.github.io/portfolio/post/personal-project-teamaya/","tags":["Dev","Poem"],"title":"teamayaã¨ã„ã†å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã¯ã˜ã‚ã¦ã¿ãŸ"},{"content":"ã¯ã˜ã‚ã« Buy Me a Coffeeã¨ã„ã†ã‚³ãƒ¼ãƒ’ãƒ¼1æ¯ã‚’ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼æ´»å‹•ã®ã‚µãƒãƒ¼ãƒˆã¨ã„ã†å½¢ã§å¯„ä»˜ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚ã‚Šã¾ã™ï¼ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã®å­˜åœ¨ã¯ä»¥å‰ã‹ã‚‰ä»–ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å€‹äººãƒ–ãƒ­ã‚°ãªã©ã§çŸ¥ã£ã¦ã„ãŸã®ã§ã™ãŒï¼Œ@hurutoriyaã•ã‚“ãŒæŠ•ç¨¿ã•ã‚ŒãŸã“ã¡ã‚‰ã®è¨˜äº‹ã‚’è¦‹ã¦ï¼Œåƒ•ã‚‚åŒæ„ã™ã‚‹ã“ã¨ãŒå¤šã‹ã£ãŸã®ã§ï¼Œè‡ªåˆ†ã®å€‹äººãƒ–ãƒ­ã‚°ã§ã‚‚å°å…¥ã—ã¦ã¿ãŸã¨ã„ã†ãŠè©±ã§ã™ï¼\nã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®æ´»å‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ Buy Me a Coffeeä»¥å¤–ã«ã‚‚æœ€è¿‘ã¯è‰²ã€…ã¨ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®æ´»å‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å¯„ä»˜ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚ã‚‹ã®ã§ç´¹ä»‹ã—ã¦ãŠãã¾ã™ï¼\n Buy Me a Coffee: ã‚³ãƒ¼ãƒ’ãƒ¼1æ¯ï¼ˆå®Ÿéš›ã«ã¯$5ï¼‰ã‚’ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼æ´»å‹•ã®ãŸã‚ã«ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ Ko-fi: åå‰ã®é€šã‚Šï¼Œã‚µãƒãƒ¼ãƒˆã—ãŸã„äººã«å¯¾ã—ã¦ã‚³ãƒ¼ãƒ’ãƒ¼ä»£ã‚’é€ã‚‹ã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ OFUSE: 1æ–‡å­—2å††ã§OFUSEãƒ¬ã‚¿ãƒ¼ã‚„OFUSEã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›¸ã„ã¦ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹  Buy Me a Coffeeã‚’å°å…¥ã—ã‚ˆã†ã¨æ€ã£ãŸç†ç”± @hurutoriyaã•ã‚“ãŒæ›¸ã‹ã‚ŒãŸå†…å®¹ã¨æ¦‚ã­ä¸€ç·’ã§ã™ãŒï¼ŒãŠé‡‘ãŒæ¬²ã—ã„ã‹ã‚‰ã¨ã„ã†ã‚ã‘ã§ã¯ãªãï¼ˆãŠé‡‘ãŒæ¬²ã—ã„ãªã‚‰åºƒå‘Šã‚’è²¼ã‚‹ã¨æ€ã„ã¾ã™ï¼‰ï¼Œæ„Ÿè¬ã‚’ä¼ãˆã‚‹1ã¤ã®æ‰‹æ®µã¨ã—ã¦ï¼Œã‚³ãƒ¼ãƒ’ãƒ¼ã‚’1æ¯ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã™ã‚‹ã‚ˆãƒ¼ã¨ã„ã†è¡¨ç¾ãŒè‰¯ã„ãªã¨æ„Ÿã˜ã¦ã„ã¾ã™ï¼\nã„ã„ã­ï¼ãªã©ã‚‚è¨˜äº‹ã‚’æ›¸ã„ãŸå´ã‹ã‚‰ã™ã‚‹ã¨èª­ã‚“ã§ãã‚ŒãŸäººã‹ã‚‰ã®å¬‰ã—ã„ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®1ã¤ã ã¨æ€ã„ã¾ã™ï¼ãŸã ï¼Œã„ã„ã­ï¼ä»¥ä¸Šã«èª­ã‚“ã äººã«ã¨ã£ã¦ä¾¡å€¤ãŒã‚ã‚‹æŠ€è¡“è¨˜äº‹ãªã©ã«å¯¾ã—ã¦ã¯ï¼Œã“ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã§æ„Ÿè¬ã‚’ä¼ãˆã‚‹æ–¹æ³•ãŒã‚ã£ã¦ã‚‚ã„ã„ã®ã‹ãªã¨æ€ã„ã¾ã™ï¼ã‚µãƒãƒ¼ãƒˆã—ã¦è²°ã£ãŸå´ã‹ã‚‰ã™ã‚‹ã¨ï¼Œèª°ã‹ã®ãŸã‚ã«ãªã£ã¦ã‚‹ã¨ã„ã†æ„Ÿè¦šã‚’ã‚ˆã‚Šæ„Ÿã˜ã‚‹ã“ã¨ãŒã§ãã¾ã™ã—ï¼Œä½•ã‚ˆã‚Šã‚‚ã£ã¨æœ‰ç›Šãªå†…å®¹ã‚’å±Šã‘ã¦ã„ã“ã†ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚‚ç¹‹ãŒã‚‹ãªã¨æ€ã„ã¾ã™ï¼\nã“ã‚Œã‚‰ã®ç†ç”±ã¨åƒ•ã‚‚ã‚ˆã‚Šè‰¯ã„è¨˜äº‹ã‚’å±Šã‘ã¦ã„ããŸã„ã¨ã„ã†æƒ³ã„ã‹ã‚‰ï¼Œä»Šå›Buy Me a Coffeeã‚’å°å…¥ã—ã¦ã¿ã‚ˆã†ã¨æ€ã„ã¾ã—ãŸï¼\nãŠã‚ã‚Šã« å®Ÿè£…ã«ã¤ã„ã¦ã¯ï¼Œã“ã¡ã‚‰ã®ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ­ã‚´ã‚„ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ã¾ãŸï¼ŒæŒ¿å…¥ã™ã‚‹æ–‡å­—ã‚„ãã®ãƒ•ã‚©ãƒ³ãƒˆãƒ»è‰²ãªã©è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹Generateãƒšãƒ¼ã‚¸ãŒã‚ã‚Šï¼Œãã“ã‹ã‚‰Generateã‚’å®Ÿè¡Œã™ã‚‹ã¨ï¼ŒHTMLã«ä½¿ç”¨ã§ãã‚‹image codeãŒå‡ºæ¥ä¸ŠãŒã‚‹ã®ã§ï¼Œãã‚Œã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ç°¡å˜ã«ã‚µã‚¤ãƒˆã«å°å…¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nä»Šå›ã¯ï¼ŒBuy Me a Coffeeã®ã‚µãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒšãƒ¼ã‚¸æœ€ä¸‹éƒ¨ã«å°å…¥ã—ã¦ï¼Œãã®å°å…¥ã—ãŸãŠæ°—æŒã¡ã‚’æ›¸ã„ãŸãƒã‚¨ãƒ ã«ãªã‚Šã¾ã™ï¼\nå‚è€ƒ  æŠ•ã’éŠ­ã‚µãƒ¼ãƒ“ã‚¹ã®Buy me a cofee ã‚’Blog ã«å°å…¥ã—ã¦ã¿ãŸ ã‚³ãƒ¼ãƒ’ãƒ¼1æ¯ã§æ”¯æ´ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€Œko-fiã€ã¨ã€é–‹ç™ºè€…ãŒã‚³ãƒ¼ãƒ’ãƒ¼ã‚’å¥¢ã‚‰ã‚Œã‚‹ä»•çµ„ã¿ã®è©±â˜• ã•ã¾ã–ã¾ãªåç›ŠåŒ–æ©Ÿèƒ½ã‚’ã²ã¨ã¤ã«ã€‚ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼å¿œæ´ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€ŒOFUSEï¼ˆã‚ªãƒ•ã‚»ï¼‰ã€èª•ç”Ÿã€‚  ","date":"2021-12-07","permalink":"https://masatakashiwagi.github.io/portfolio/post/implement-buy-me-a-coffee/","tags":["Poem"],"title":"Buy Me a Coffeeã‚’ãƒ–ãƒ­ã‚°ã«è¿½åŠ ã—ãŸè©±"},{"content":"ã¯ã˜ã‚ã« æ™®æ®µã¯Pythonã®SciPyã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ã¦ï¼ŒABãƒ†ã‚¹ãƒˆå®Ÿæ–½å¾Œã®2ç¾¤é–“ã«ãŠã‘ã‚‹æœ‰æ„å·®ã‚’èª¿ã¹ã‚‹ãŸã‚ã«æ¤œå®šã‚’è¡Œã£ã¦ã„ã¾ã™ãŒï¼ŒPythonã‚’ä½¿ã£ã¦ã„ãªã„orã“ã®ã‚ˆã†ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«è§¦ã‚ŒãŸã“ã¨ãŒãªã„äººã§ã‚‚ç°¡å˜ã«æ¤œå®šãŒè¡Œãˆã‚‹ã‚ˆã†ã«ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½¿ã£ã¦Mann-Whitneyã®Uæ¤œå®šã‚’å®Ÿæ–½ã—ãŸã‚‚ã®ã«ãªã‚Šã¾ã™ï¼\nå…¬é–‹ä¸­ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ â†’ Mann-Whitney U-test in spreadsheet\nã‚³ãƒ”ãƒ¼ã—ã¦ã”è‡ªç”±ã«ãŠä½¿ã„ä¸‹ã•ã„ï¼ˆå…¨è‡ªå‹•ã§ãªã„éƒ¨åˆ†ãŒã‚ã‚‹ã®ã§ï¼Œã”ç•™æ„ä¸‹ã•ã„ï¼‰ï¼\nMann-Whitneyã®Uæ¤œå®šã¨ã¯ Mann-Whitneyï¼ˆãƒãƒ³ãƒ»ãƒ›ã‚¤ãƒƒãƒˆãƒ‹ãƒ¼ï¼‰ã®Uæ¤œå®šï¼ˆã‚¦ã‚£ãƒ«ã‚³ã‚¯ã‚½ãƒ³ã®é †ä½å’Œæ¤œå®šï¼‰ã¨ã¯ï¼Œ2ã¤ã®æ¯é›†å›£ãŒç‰¹å®šã®åˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ã‚’ä»®å®šã—ãªã„ã§ï¼Œã€Œ2ã¤ã®åˆ†å¸ƒã®é‡ãªã‚Šå…·åˆã€ã‚’æ¤œå®šã—ã¾ã™ï¼ï¼ˆãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ–¹æ³•ã®ä¸€ã¤ï¼‰\nã“ã‚Œã¯ï¼Œ2ã¤ã®æ¯é›†å›£ã®ä¸­å¤®å€¤ã®å·®ã«æ³¨ç›®ã—ã¦ã„ã¾ã™ï¼ â†’ ã“ã¡ã‚‰ã®è¨˜äº‹ã‚’è¦‹ã‚‹ã¨ï¼Œä¸­å¤®å€¤ã®æ¤œå®šã¨ã„ã†ã‚ã‘ã§ã¯ãªã„ã¿ãŸã„ã§ã™ï¼ï¼ˆè‡ªåˆ†ã‚‚èª¤ã£ã¦ç†è§£ã—ã¦ã„ã¾ã—ãŸï¼‰\nUæ¤œå®šã®ç‰¹å¾´ã¨ã—ã¦ã¯ï¼Œå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„ãªã©ãŒæŒ™ã’ã‚‰ã‚Œã¾ã™ï¼ä¸€æ–¹ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹tæ¤œå®šã®å ´åˆï¼Œå¹³å‡å€¤ã‚’è¦‹ã¦ã„ã‚‹ã®ã§å¤–ã‚Œå€¤ãŒã‚ã‚‹ã¨ãã®å½±éŸ¿ã‚’å—ã‘ã¾ã™ï¼ãã®ãŸã‚ï¼Œå¤–ã‚Œå€¤é™¤å»ãªã©ã®å¯¾å‡¦ãŒå¿…è¦ãªã‚±ãƒ¼ã‚¹ãŒç™ºç”Ÿã—ã¾ã™ï¼\nã“ã“ã§ï¼ŒUæ¤œå®šã«ã¯ä»¥ä¸‹ã®ä»®å®šãŒã‚ã‚Šã¾ã™ï¼\n 2ã¤ã®æ¯é›†å›£ã¯äº’ã„ã«ç‹¬ç«‹ 2ã¤ã®æ¯é›†å›£ã®åˆ†å¸ƒãŒæ­£è¦åˆ†å¸ƒã§ã‚ã‚‹ã¨ä»®å®šã§ããªã„ 2ã¤ã®æ¯é›†å›£ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒåŒæ•°ã§ãªãã¦ã‚‚è‰¯ã„  ã¾ãŸï¼Œå¸°ç„¡ä»®èª¬ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n å¸°ç„¡ä»®èª¬: 2ç¾¤é–“ã«å·®ãŒãªã„ï¼ˆ2ã¤ã®åˆ†å¸ƒãŒç­‰ã—ã„ï¼‰  æ¤œå®šã‚’è¡Œã†æ‰‹é † æ¤œå®šã‚’è¡Œã†æ‰‹é †ã‚’ç´¹ä»‹ã—ã¾ã™ï¼ã¾ãšAç¾¤ã¨Bç¾¤ã®2ã¤ã®ç¾¤ã‚’è€ƒãˆã¾ã™ï¼\n ãã‚Œãã‚Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’n1\u0008, n2ã¨ã—ãŸå ´åˆã«ï¼Œ2ã¤ã®ç¾¤ã‚’æ··ãœãŸãƒ‡ãƒ¼ã‚¿(n1+n2)ã‚’ç”¨æ„ã—ã¾ã™ï¼ 1ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ˜‡é †ã«ä¸¦ã³æ›¿ãˆã¾ã™ï¼ ä¸¦ã³æ›¿ãˆãŸã‚‚ã®ã«å¯¾ã—ã¦ï¼Œé †ä½ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ï¼ˆãƒ©ãƒ³ã‚¯ä»˜ã‘ï¼‰ï¼ã‚‚ã—åŒé †ä½ã‚’æŒã¤è¦ç´ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ï¼Œé †ä½ã®å¹³å‡ã‚’è¨ˆç®—ã—ï¼Œãã®é †ä½ã®å¹³å‡ã‚’å„è¦ç´ ã«å‰²ã‚Šå½“ã¦ã¾ã™ï¼ Aç¾¤ã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®é †ä½å’Œã‚’è¨ˆç®—ã™ã‚‹ï¼ˆ=R1ï¼‰ åŒæ§˜ã«Bç¾¤ã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®é †ä½å’Œã‚’è¨ˆç®—ã™ã‚‹ï¼ˆ=R2ï¼‰  ã“ã“ã¾ã§è¨ˆç®—ã™ã‚‹ã¨ï¼Œæ¤œå®šçµ±è¨ˆé‡ï¼ˆUå€¤ï¼‰ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n$$ U_1 = n_1n_2 + \\frac{n_1(n_1 + 1)}{2} - R_1 $$ $$ U_2 = n_2n_1 + \\frac{n_2(n_2 + 1)}{2} - R_2 $$ $$ U = min(U_1, U_2) $$\nUãŒè¨ˆç®—ã§ããŸã‚‰ï¼ŒMann-Whitneyæ¤œå®šè¡¨ã‚’ç”¨ã„ã¦æœ‰æ„å·®5%ã§æ£„å´ã§ãã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ï¼\nÎ±=0.05ã®è¡¨ã‚’çœºã‚ã¦ï¼Œä»Šå›ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºn1, n2ã«è©²å½“ã™ã‚‹å€¤ã¨è¨ˆç®—ã—ãŸUå€¤ã®å¤§å°é–¢ä¿‚ã‚’æ¯”è¼ƒã—ã¦ï¼Œè¨ˆç®—ã—ãŸå€¤ãŒå°ã•ã„å ´åˆã«ã¯ï¼Œå¸°ç„¡ä»®èª¬ã‚’æ£„å´ã—ã¾ã™ï¼Œã¤ã¾ã‚Šæœ‰æ„å·®ã‚ã‚Šã¨ãªã‚Šã¾ã™ï¼é€†ã«è¨ˆç®—ã—ãŸå€¤ã®æ–¹ãŒå¤§ãã„å ´åˆã«ã¯ï¼Œå¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ããªã„ã®ã§ï¼Œæœ‰æ„å·®ãªã—ã¨ãªã‚Šã¾ã™ï¼\nã“ã“ã§ï¼Œã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒn1\u0026gt;20ã¾ãŸã¯n2\u0026gt;20ã®æ™‚ã¯ï¼Œæ¤œå®šçµ±è¨ˆé‡Uã‚’æ¨™æº–åŒ–ã—ã¦zå€¤ã‚’æ±‚ã‚ã¦ï¼Œæ¨™æº–æ­£è¦åˆ†å¸ƒã§è¿‘ä¼¼ã™ã‚‹æ–¹æ³•ã‚’ç”¨ã„ã¾ã™ï¼å¹³å‡å€¤ï¼Œæ¨™æº–åå·®ï¼Œzå€¤ã¯ä»¥ä¸‹ã®è¨ˆç®—å¼ã§æ±‚ã‚ã¾ã™ï¼\n$$ \\mu_u = \\frac{n_1n_2}{2} $$ $$ \\sigma_u = \\sqrt{\\frac{n_1n_2(n_1+n_2+1)}{12}} $$ $$ z = \\frac{U - \\mu_u}{\\sigma_u} $$\nzå€¤ãŒè¨ˆç®—ã§ããŸã‚‰ï¼Œæ¨™æº–æ­£è¦åˆ†å¸ƒè¡¨ã‚’ç”¨ã„ã¦ï¼Œè©²å½“ã™ã‚‹på€¤ã‚’è¦‹ã«è¡Œãã¾ã™ï¼\n(zå€¤ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®çµ„ã¿è¾¼ã¿é–¢æ•°ã§ã‚ã‚‹NORMSDISTã«ä»£å…¥ã—ã¦ï¼Œ1ã‹ã‚‰å¼•ãã“ã¨ã§på€¤ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™: å¼=1-NORMSDIST(z))\n pâ‰§Î±ã®æ™‚ï¼Œå¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ããªã„ p\u0026lt;Î±ã®æ™‚ï¼Œå¸°ç„¡ä»®èª¬ã‚’æ£„å´ã™ã‚‹ï¼ã¤ã¾ã‚Šï¼Œæœ‰æ„å·®ã‚ã‚Šã¨ãªã‚‹  ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§Uæ¤œå®šã‚’è¡Œã† å…¬é–‹ã—ã¦ã„ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¯ã“ã¡ã‚‰ã«ãªã‚Šã¾ã™ï¼ï¼ˆå†æ²ï¼‰\nã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—ABã®èº«é•·ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¼‰ã›ã¦ã„ã¾ã™ï¼ã“ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå®šã—ãŸã„2ç¾¤ã®ãƒ‡ãƒ¼ã‚¿ã«é©å®œå¤‰æ›´ã—ã¦é ‚ãã¨ï¼Œ#æ¤œå®šã‚’è¡Œã†æ‰‹é † ã§ç´¹ä»‹ã—ãŸæ–¹æ³•ã«å‰‡ã£ã¦på€¤ã®è¨ˆç®—ãŒã•ã‚Œã¾ã™ï¼\nã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒn\u0026lt;=20ã®å ´åˆã¯ï¼ŒUå€¤ã§ã®è©•ä¾¡ã«ãªã‚‹ã®ã§ï¼Œãã®å ´åˆã¯ãƒªãƒ³ã‚¯ã«ã‚ã‚‹ãƒãƒ³ãƒ»ãƒ›ã‚¤ãƒƒãƒˆãƒ‹ãƒ¼ã®ï¼µæ¤œå®šè¡¨ã‚’ç”¨ã„ã¦ï¼Œè©²å½“ã™ã‚‹å€¤ã‹ã‚‰æ¤œå®šçµæœã‚’è¦‹ç©ã£ã¦è²°ã†ã¨è‰¯ã„ã§ã™ï¼\nâ€» è£œè¶³:\nã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿é †åºã¯æ„è­˜ã—ãªã„ã§å•é¡Œã‚ã‚Šã¾ã›ã‚“ï¼Œé †åºä¸¦ã³æ›¿ãˆã§è‡ªå‹•çš„ã«æ˜‡é †ã§ä¸¦ã³å¤‰ã‚ã‚Šã¾ã™ï¼ãŸã ã—ï¼Œé †ä½ã«ã¤ã„ã¦ã¯ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼ã§ã‚»ãƒ«ã®å³ä¸‹ã«è¡¨ç¤ºã•ã‚Œã‚‹é»’ã„éƒ¨åˆ†ã‚’ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¦ã„ã‚‹éƒ¨åˆ†ã¾ã§ä¸‹ã«ã‚ºãƒ©ã—ã¦è²°ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’å®Œç’§ã«ä½¿ã„ã“ãªã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ï¼Œç‰¹ã«é †ä½ã‚’ã¤ã‘ã¦ã‚‹éƒ¨åˆ†ãŒè‡ªå‹•åŒ–ã§ãã¦ã„ãªã„ã§ã™ï¼ã‚‚ã—ã”å­˜çŸ¥ã®æ–¹ã¯ï¼Œæ–¹æ³•ã‚’æ•™ãˆã¦è²°ãˆã‚‹ã¨å¤§å¤‰åŠ©ã‹ã‚Šã¾ã™ğŸ™ï¼‰\nãŠã‚ã‚Šã« ä»Šå›ã¯ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½¿ã£ã¦Mann-Whitneyã®Uæ¤œå®šã‚’è©¦ã—ã¦ã¿ãŸå†…å®¹ã«ãªã‚Šã¾ã™ï¼Pythonã‚’ä½¿ã£ã¦ã„ãªã„éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®æ–¹ã§ã‚‚æ¤œå®šã‚’è¡Œãˆã‚‹ã‚ˆã†ã«ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å®Ÿè£…ã—ã¾ã—ãŸï¼ABãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¦æ¤œå®šã™ã‚‹ã¾ã§ã‚’èª°ã§ã‚‚ç°¡å˜ã«ã§ãã‚‹ã‚ˆã†ã«ãªã‚Œã°è‰¯ã„ãªã¨æ€ã£ã¦ã¾ã™ï¼å®Ÿè£…ã—ã¦ã„ã¦ï¼Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã£ã¦æ„å¤–ã¨çµ„ã¿è¾¼ã¿ã®é–¢æ•°ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ”¹ã‚ã¦çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸğŸ˜„\nã¾ãŸï¼Œæ™®æ®µãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½•æ°—ãªãä½¿ã£ã¦ã„ã¾ã™ãŒï¼Œå†…éƒ¨ã®è¨ˆç®—æ–¹æ³•ã‚„ã©ã†ã‚†ã†æ‰‹ç¶šãã§å‡ºåŠ›ã•ã‚Œã‚‹ã®ã‹ï¼Œã¾ãŸãã®å€¤ã‚’ã¡ã‚ƒã‚“ã¨ç†è§£ã—ã¦ä½¿ã£ã¦ã„ã‹ãªã„ã¨ãªãƒ¼ã¨ã„ã†ã“ã¨ã‚’æ”¹ã‚ã¦æ„Ÿã˜ã¾ã—ãŸï¼ä¾‹ãˆã°ï¼Œscipy.stats.mannwhitneyuã¯på€¤ã‚’å‡ºã™ã ã‘ã§ã‚ã‚Œã°è‰¯ã„ãŒï¼ŒUå€¤ã‚’ä½¿ã„ãŸã„å ´åˆã«ã¯å°‘ã—ä½¿ã„ã¥ã‚‰ã„ã¨æ„Ÿã˜ã¾ã—ãŸï¼\nP.S. tæ¤œå®šã«ã¤ã„ã¦ã‚‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã®ã§ï¼Œã¾ãŸç´¹ä»‹ã—ãŸã„ã¨æ€ã„ã¾ã™ï¼\nå‚è€ƒ  Mannâ€“Whitney U test Mann-Whitney Table æ¨™æº–æ­£è¦åˆ†å¸ƒè¡¨ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ - NORMSDIST Divine, et al. (2018) Mann-Whitneyæ¤œå®šã¯ä¸­å¤®å€¤ã®æ¤œå®šã§ã¯ãªã„  ","date":"2021-11-16","permalink":"https://masatakashiwagi.github.io/portfolio/post/mann-whitney-utest-in-spreadsheet/","tags":["Data Science","Statistics"],"title":"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§è¡Œã†Mann-Whitneyã®Uæ¤œå®š"},{"content":"ã¯ã˜ã‚ã« AWSã®SageMakerä¸Šã§SageMaker Python SDKã‚’ä½¿ç”¨ã—ã¦ç‹¬è‡ªã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒï¼Œãã®éš›ã«å­¦ç¿’ã‚„è©•ä¾¡ãŒè¡Œãˆã‚‹ Estimator ã¨ã„ã†SageMakerã®interfaceãŒã‚ã‚Šã¾ã™ï¼\nä¸€æ–¹ã§ï¼ŒSageMaker Experimentsã§å®Ÿé¨“ç®¡ç†ã‚’è¡Œã„ãŸã„å ´åˆã«ã¯ï¼Œã“ã®Estimatorã«è‰²ã€…ã¨æ¸¡ã—ã¦ã‚ã’ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\nãã®ä¸­ã§ã‚‚å­¦ç¿’æ™‚ã«å‡ºåŠ›ã•ã‚Œã‚‹lossã®å€¤ã‚„è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã«ã¯ï¼ŒEstimatorã®metric_definitionsã«æ­£è¦è¡¨ç¾ã‚’è¨˜è¿°ã—ã¦ãƒ­ã‚°ã‹ã‚‰ä¸Šæ‰‹ãå–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\nã“ã‚Œã‚’ã‚ˆã‚Šç°¡å˜ã«ã™ã‚‹ãŸã‚ã«ï¼ŒCustomCallbacké–¢æ•°ã‚’ä½œæˆã—ãŸè©±ã«ãªã‚Šã¾ã™ï¼\nCallbacké–¢æ•°ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º Tensorflowï¼Œå³å¯†ã«ã¯Kerasã®Callbacké–¢æ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¾ã™ï¼tf.keras.callbacks.Callbackã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ãŸCustomCallBack(tf.keras.callbacks.Callback)ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆã—ã¾ã™ï¼ã“ã®ä½œæˆã—ãŸã‚¯ãƒ©ã‚¹ã‚’model.fitæ™‚ã«å¼•æ•°ã®callbacksã«æ¸¡ã—ã¦ã‚„ã‚‹ã“ã¨ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nä»Šå›ã¯SageMaker Experimentsã§ä½¿ã†ã“ã¨ã‚’æƒ³å®šã—ãŸã‚‚ã®ã§ï¼ŒEstimatorã®metric_definitionsã«æ¸¡ã™Regexã¨ã—ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã¦æ¬²ã—ã„ã¨ã—ã¾ã™ï¼ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯RMSEã¨ã—ãŸå ´åˆã‚’æƒ³å®šï¼‰ MetricDefinitionsã¯ã“ã¡ã‚‰ãŒå‚è€ƒã«ãªã‚Šã¾ã™ â†’ Define Metrics\nsagemaker.estimator.Estimator( ..., metric_definitions={ {'Name': 'Train Loss', 'Regex': 'train_loss: (.*?);'}, {'Name': 'Validation Loss', 'Regex': 'val_loss: (.*?);'}, {'Name': 'Train Metrics', 'Regex': 'train_root_mean_squared_error: (.*?);'}, {'Name': 'Validation Metrics', 'Regex': 'val_root_mean_squared_error: (.*?);'}, } )  ã—ã‹ã—ãªãŒã‚‰ï¼ŒKerasã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹éš›ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ï¼Œå­¦ç¿’æ™‚ã®Lossã¯ã€Œlossã€ï¼Œãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€Œroot_mean_squared_errorã€ã§prefixãŒç„¡ã„çŠ¶æ…‹ã«ãªã‚Šã¾ã™ï¼ã“ã‚Œã‚’Callbacké–¢æ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã“ã¨ã§prefixã«ã€Œtrain_ã€ã‚’ä»˜ã‘ã¦ï¼ŒRegexã§ç°¡å˜ã«å–å¾—ã—ãŸã„ã¨ã„ã†æ°—æŒã¡ã§ã™ï¼\nTensorflowå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®Writing your own callbacksã‚„tf.keras.callbacks.Callbackã‚’å‚è€ƒã«ä½œæˆã—ã¾ã—ãŸï¼\nimport tensorflow as tf class CustomCallback(tf.keras.callbacks.Callback): def on_train_begin(self, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the beginning of training. \u0026quot;\u0026quot;\u0026quot; def on_train_end(self, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the end of training. \u0026quot;\u0026quot;\u0026quot; def on_epoch_begin(self, epoch, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the start of an epoch. \u0026quot;\u0026quot;\u0026quot; def on_epoch_end(self, epoch, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the end of an epoch. \u0026quot;\u0026quot;\u0026quot; def on_train_batch_begin(self, batch, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the beginning of a training batch in fit methods. \u0026quot;\u0026quot;\u0026quot; def on_train_batch_end(self, batch, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the end of a training batch in fit methods. \u0026quot;\u0026quot;\u0026quot;  ä¸Šè¨˜ã‚³ãƒ¼ãƒ‰ã®ä¸­ã§å¿…è¦ãªã‚‚ã®ã‚’ä¿®æ­£ã™ã‚Œã°å¤§ä¸ˆå¤«ã§ã™ï¼ä»Šå›ã¯å­¦ç¿’ã®é–‹å§‹çµ‚äº†ã¨ã‚¨ãƒãƒƒã‚¯ã®çµ‚äº†æ™‚ã«å‘¼ã¶ã‚ˆã†ã«ä¿®æ­£ã—ã¾ã—ãŸï¼\nimport tensorflow as tf import datetime class CustomCallBack(tf.keras.callbacks.Callback): def on_train_begin(self, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the beginning of training. \u0026quot;\u0026quot;\u0026quot; print(f\u0026quot;Start training - {str(datetime.datetime.now())}\u0026quot;) # get parameters self.epochs = self.params['epochs'] # the epoch when training is stopped self.stopped_epoch = 0 # initialize the best loss as infinity self.best_loss = np.Inf # list of best metrics values self.best_metrics_values_list = [] def on_train_end(self, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the end of training. \u0026quot;\u0026quot;\u0026quot; if self.stopped_epoch \u0026gt; 0: best_values = ' - '.join(self.best_metrics_values_list) print(f\u0026quot;Epoch {self.stopped_epoch + 1}: early stopping\u0026quot;) print(f'Final results: {best_values}') print(f'Finish training - {str(datetime.datetime.now())}') def on_epoch_end(self, epoch, logs=None): \u0026quot;\u0026quot;\u0026quot;Called at the end of an epoch. \u0026quot;\u0026quot;\u0026quot; keys = list(logs.keys()) metrics_values_list = [] for key in keys: if key.startswith('val_'): metrics_values_list.append(f\u0026quot;{key}: {logs.get(key):.4f};\u0026quot;) else: metrics_values_list.append(f\u0026quot;train_{key}: {logs.get(key):.4f};\u0026quot;) values = ' - '.join(metrics_values_list) print(f\u0026quot;Epoch {epoch+1}/{self.epochs} - {values}\u0026quot;) current_loss = logs.get('val_loss') if np.less(current_loss, self.best_loss): self.best_loss = current_loss self.best_metrics_values_list = metrics_values_list else: self.stopped_epoch = epoch # fitæ™‚ã«callbacksã«ä½œæˆã—ãŸã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ãŸã‚‚ã®ã‚’æ¸¡ã™ model.fit( ..., callbacks=[CustomCallBack()], )  å‡ºåŠ›ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã«ãªã‚Šã¾ã™ï¼ä»Šå›ã¯printæ–‡ã§å‡ºåŠ›ã—ã¦ã„ã¾ã™ãŒï¼Œloggerã‚’ç”¨æ„ã—ã¦logger.infoã‚’ä½¿ã†ã®ã‚‚è‰¯ã„ã‹ã¨æ€ã„ã¾ã™ï¼\nStart training - 2021-11-09 23:48:12.787257 Epoch 1/10 - train_loss: 4.6889; - train_root_mean_squared_error: 2.1654; - val_loss: 11.1416; - val_root_mean_squared_error: 3.3379; ... Finish training - 2021-11-09 23:48:15.095133  ãŠã‚ã‚Šã« ä»Šå›ã¯SageMaker Experimentsã§å®Ÿé¨“ç®¡ç†ã‚’è¡Œã†ä¸Šã§ãƒ­ã‚°å‡ºåŠ›ã®å½¢ã‚’ä¿®æ­£ã—ãŸã„ã¨ã„ã†å‹•æ©Ÿã‹ã‚‰CallBacké–¢æ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¾ã—ãŸï¼Callbacké–¢æ•°ã®ä¸­èº«ã‚’çŸ¥ã‚‹ãŸã‚ã«ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’èª­ã‚“ã ã‚Šã—ã¦å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸï¼Tensorflowã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯æ‹¡å¼µæ€§ãŒã‚ã‚Šï¼Œã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®æ–¹æ³•ã‚‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ•´å‚™ã•ã‚Œã¦ã„ã‚‹ã®ã§ï¼Œæ¯”è¼ƒçš„å®¹æ˜“ã«ä¿®æ­£ã§ãã‚‹ã¨æ€ã„ã¾ã™ï¼ä»Šå›ã¯æ™‚é–“çµŒéã‚„äºˆæ¸¬æ™‚é–“ã®è¡¨ç¤ºã¯çœã„ã¦ã—ã¾ã£ãŸã®ã§ï¼Œä½™è£•ãŒã‚ã‚Œã°ãƒ­ã‚°ã«ã“ã‚Œã‚‰ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ããŸã„ã§ã™ï¼\nè¿½è¨˜  2022/02/24: æ›´æ–°  earlystoppingã«å¯¾å¿œã™ã‚‹å½¢å¼ã«CallBacké–¢æ•°ã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼current_loss = logs.get('val_loss')ã§logsã‹ã‚‰getã™ã‚‹valueã¯callbacks.EarlyStopping(monitor='val_loss')ã§monitorã«æŒ‡å®šã—ã¦ã„ã‚‹å€¤ã«ãªã‚Šã¾ã™ï¼\nå‚è€ƒ  Sagemaker Training APIs - Estimator Writing your own callbacks tf.keras.callbacks.Callback  ","date":"2021-11-10","permalink":"https://masatakashiwagi.github.io/portfolio/post/customize-tf-callback/","tags":["Dev","Machine Learning"],"title":"Tensorflowã®Callbacké–¢æ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º"},{"content":"ã¯ã˜ã‚ã« 6æœˆã‹ã‚‰å‹äººã®@navitacionã•ã‚“ã¨ä¸€ç·’ã«Podcastã®é…ä¿¡ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ãƒ†ãƒƒã‚¯ç³»ã®è©±é¡Œãªã©è‡ªåˆ†ãŸã¡ãŒèˆˆå‘³ã®ã‚ã‚‹å†…å®¹ã‚’ã‚ã‚Œã“ã‚Œã¨è©±ã™ã‚‚ã®ã«ãªã‚Šã¾ã™ï¼\nAnchorã¨ã„ã†ç„¡æ–™ã§é…ä¿¡ã§ãã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šï¼Œãƒãƒ£ãƒ³ãƒãƒ«åã¯ã€ŒDouble-M2.fmã€ã«ãªã‚Šã¾ã™ï¼\n å„Episodeã®è¦ç´„ã‚‚ã‚ã‚Šã¾ã™ã®ã§ï¼Œèˆˆå‘³ã‚’æŒã£ã¦é ‚ã„ãŸæ–¹ã¯ã“ã¡ã‚‰ã‹ã‚‰è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n ã“ã®è¨˜äº‹ã§ã¯ï¼Œnaviã•ã‚“ã¨å§‹ã‚ãŸã‚­ãƒƒã‚«ã‚±ã¨å®Ÿéš›ã®é…ä¿¡æ–¹æ³•ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ï¼é…ä¿¡æ–¹æ³•ã¯ã‚ã¾ã‚Šæ¤œç´¢ã—ã¦ã‚‚è¨˜äº‹ãŒç„¡ã‹ã£ãŸã‚Šã—ãŸã®ã§ï¼Œã“ã‚Œã‹ã‚‰å§‹ã‚ã‚ˆã†ã¨ã—ã¦ã„ã‚‹äººã®å‚è€ƒã«ãªã‚Œã°ã¨ï¼Œãã—ã¦Podcasté…ä¿¡è€…ãŒä¸€äººã§ã‚‚å¤šãå¢—ãˆã‚Œã°ãªãƒ¼ã¨æ€ã„ã¾ã™ï¼\né…ä¿¡ã®ã‚­ãƒƒã‚«ã‚± é…ä¿¡ã®ã‚­ãƒƒã‚«ã‚±ã¯åˆå›é…ä¿¡æ™‚ã«ã‚‚ãƒãƒ©ãƒƒã¨è§¦ã‚ŒãŸã®ã§ã™ãŒï¼Œå¤§ãã2ã¤ï¼ˆ+1ï¼‰ã‚ã‚Šã¾ã™ï¼\n ã‚³ãƒ­ãƒŠç¦ã§ï¼Œã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆãŒç„¡ããªã£ãŸã“ã¨ã§ï¼Œã‚¤ãƒ™ãƒ³ãƒˆå¾Œã«å‚åŠ è€…åŒå£«ã§é›‘è«‡ã—ãŸã‚Šï¼Œæƒ…å ±äº¤æ›ã—ãŸã‚Šã™ã‚‹æ©Ÿä¼šãŒç„¡ããªã£ã¦ã—ã¾ã£ãŸã®ã§ï¼Œãã‚Œã‚’å®šæœŸçš„ã«ã—ãŸã„ã¨ã„ã†æƒ³ã„ã‹ã‚‰ ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’æ„è­˜ã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ï¼Œãã‚Œã‚’ç¶™ç¶šçš„ã«è¡Œã£ã¦ã„ãå ´ã®ä¸€ã¤ã¨ã—ã¦ï¼ŒéŸ³å£°ã«ã‚ˆã‚‹æ–¹æ³•ã‚‚ã‚ã‚‹ã®ã§ã¯ã¨ã„ã†æƒ³ã„ã‹ã‚‰ è©±ã®ã‚¿ãƒã¨ã—ã¦ã„ã„ã‹ãªã¨ç¬‘  ä¸€ã¤ãšã¤èª¬æ˜ã—ã¦ã„ãã¨ï¼Œ ã¾ãšâ‘ ã«ã¤ã„ã¦ï¼Œã“ã‚Œã¯æ€ã£ã¦ã„ã‚‹äººãŒå¤šã„ã‚“ã˜ã‚ƒãªã„ã‹ãªã¨æ€ã„ã¾ã™ãŒï¼Œã‚³ãƒ­ãƒŠç¦ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã®ã‚¤ãƒ™ãƒ³ãƒˆã¯å¤šãé–‹å‚¬ã•ã‚Œã¦ãŠã‚Šï¼Œã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã«æ¯”ã¹ãŸã‚‰ç§»å‹•ã™ã‚‹æ‰‹é–“ã‚‚ãªããƒãƒ¼ãƒ‰ãƒ«ãŒä¸‹ãŒã£ã¦ï¼Œå‚åŠ äººæ•°ã®åˆ¶é™ã‚‚å®Ÿè³ªç„¡åˆ¶é™ã§ï¼ŒæŠ½é¸æ¼ã‚Œã®æ‡¸å¿µã‚‚ç„¡ããªã‚Šã¨è‰¯ã„ã“ã¨ã‚‚å¤šãã‚ã‚‹ä¸€æ–¹ã§ï¼Œã‚¤ãƒ™ãƒ³ãƒˆå¾Œã«ç™»å£‡è€…ä»¥å¤–ã®äººåŒå£«ã‚„ç™»å£‡è€…ã¨ã®ä¼šè©±ãŒã»ã¼ã»ã¼ç„¡ããªã£ã¦ï¼Œé›‘è«‡ã¨ã‹æƒ…å ±äº¤æ›ã—ãŸã‚Šã™ã‚‹æ©Ÿä¼šãŒã‹ãªã‚Šæ¸›ã£ãŸã¨å€‹äººçš„ã«æ„Ÿã˜ã¦ã„ã¾ã™ï¼\nãã†ã„ã£ãŸçŠ¶æ³ã§ï¼Œä¼šç¤¾ã®äººä»¥å¤–ã®äººã¨é›‘è«‡ãªã©ä¼šè©±ã™ã‚‹æ™‚é–“ãŒåœ§å€’çš„ã«æ¸›ã£ãŸã¨ã„ã†ã®ã‚‚ã‚ã‚Šï¼Œå®šæœŸçš„ã«æƒ…å ±äº¤æ›ã—ãŸã‚Šæ„è¦‹ã‚’è¨€ã„åˆãˆã‚‹å ´ãŒã‚ã‚‹ã¨è‰¯ã„ãªãƒ¼ã¨ã„ã†ã“ã¨ã§ä»Šå›Podcastã‚’å§‹ã‚ã¾ã—ãŸï¼ ï¼ˆæœ€è¿‘ã ã¨ï¼ŒTwitterãŒéŸ³å£°ä¼šè©±ã‚µãƒ¼ãƒ“ã‚¹ã®Spaceã‚’å§‹ã‚ã¦ï¼Œãã“ã§æ°—è»½ã«ä¼šè©±ãŒç”Ÿã¾ã‚Œã‚‹ã®ãŒã‚¹ã‚´ãè‰¯ã„ãªã¨æ„Ÿã˜ã¦ã¾ã™ï¼ï¼‰\nâ‘¡ã«ã¤ã„ã¦ã¯ï¼Œã‹ãªãƒ¼ãƒ¼ã‚Šã‚µãƒœã‚Šæ°—å‘³ã ã£ãŸã®ã§ã™ãŒï¼Œã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¡ã‚ƒã‚“ã¨ã—ã¦è¡Œã‹ãªã„ã¨ãªãƒ¼ã¨ã„ã†æ°—æŒã¡ãŒé«˜ã¾ã‚Šï¼Œãã‚Œã‚’å¼·åˆ¶çš„ã«è¡Œã†ä¸€ã¤ã®æ–¹æ³•ã ã£ãŸã‚Šã‚‚ã—ã¾ã™ï¼ Podcastã§è©±ã™ãŸã‚ã«ï¼Œä½•ã‹ã—ã‚‰ã®è©±é¡Œã‚’æ¢ã—ãŸã‚Šï¼Œæ›¸ç±ãƒ»è«–æ–‡ãªã©ã‚’èª­ã‚“ã§èª¿ã¹ãŸã‚Šã¨ãƒˆãƒ”ãƒƒã‚¯ã®å†…å®¹ã‚’æ•´ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨æ€ã„ã¾ã™ï¼ã¾ãŸï¼Œå†…å®¹ã‚’è‡ªåˆ†ã®è¨€è‘‰ã§ç›¸æ‰‹ã«èª¬æ˜ã™ã‚‹ã“ã¨ã§ç†è§£ã®åŠ©ã‘ã«ãªã‚‹ã¨æ€ã£ã¦ã„ã¾ã™ï¼ï¼ˆäººã«èª¬æ˜ã—ã¦ã¿ã‚‹ã¨ï¼Œæ€ã£ãŸã‚ˆã‚Šã‚ã‹ã£ã¦ãªã„ãªãƒ¼ã¨æ„Ÿã˜ã‚‹ã“ã¨ã‚ã‚‹ã‚ã‚‹ã ã¨æ€ã„ã¾ã™ï¼‰\nã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã®æ–¹æ³•ã®ä¸€ã¤ã¨ã—ã¦ï¼Œãƒ–ãƒ­ã‚°ã«ã¾ã¨ã‚ã‚‹ã¨ã„ã†ã“ã¨ä»¥å¤–ã«éŸ³å£°ã§ã‚‚ã‚„ã‚ã†ã‹ãªã¨ã„ã£ãŸã¨ã“ã‚ã§ã™ï¼ ã‚ã¨ï¼Œæ™®æ®µã‹ã‚‰ã€Œã“ã‚Œï¼Podcastã§è©±ã›ã‚‹ã‹ã‚‚ã€ã¨ã£ãŸæ„è­˜ã‚’ã™ã‚‹ã ã‘ã§ç†è§£ã®ä»•æ–¹ãŒå¤‰ã‚ã‚‹ã¨æ€ã†ã®ã§ï¼Œã“ã®ç¿’æ…£ã‚’ä»˜ã‘ãŸã„ç‹™ã„ã‚‚å€‹äººçš„ã«ã‚ã‚Šã¾ã™ï¼\næœ€å¾Œã«â‘¢ã«ã¤ã„ã¦ï¼Œã“ã‚Œã¯Twitterä¸Šã§ã¯ãŠäº’ã„èªçŸ¥ã—ã¦ã„ã¦ã‚‚ï¼Œãƒªã‚¢ãƒ«ã ã¨ä¼šã£ãŸã“ã¨ãªã„äººã¨ã®è©±ã®ãƒã‚¿ã®ä¸€ã¤ã«ã—ã‚ˆã†ã‹ãªã¨ã„ã†é­‚èƒ†ã§ã™ç¬‘\né…ä¿¡æ–¹æ³• é…ä¿¡ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ãŒï¼Œã“ã‚Œã¯åƒ•ãŒèã„ã¦ã„ã‚‹ä»–ã®Podcasté…ä¿¡è€…ã®ã‚’å‚è€ƒã«ã—ã¦ï¼ŒAnchorã«ã—ã¾ã—ãŸï¼Anchorã¯æºå¸¯ã§ã‚‚ç°¡å˜ã«éŒ²éŸ³ã™ã‚‹ã“ã¨ãŒã§ãã¦ï¼Œãã‚Œã‚’é…ä¿¡ã§ãã¡ã‚ƒã£ãŸã‚Šã‚‚ã—ã¾ã™ï¼\nä»¥ä¸‹ãŒåƒ•ãŸã¡ãŒé…ä¿¡ã—ã¦ã„ã‚‹å„ç¨®æ§‹æˆã«ãªã‚Šã¾ã™ï¼\nâ€» å…¨ã¦ç„¡æ–™ã§è¡Œã†ãŸã‚ã«ï¼Œã“ã‚Œã‚‰ã®æ§‹æˆã«ãªã£ã¦ã„ã¾ã™ï¼Œæœ‰æ–™ã§ã‚‚ã„ã„å ´åˆã¯ã“ã“ã§ç´¹ä»‹ã—ãŸã‚ˆã†ãªè¤‡æ•°ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã‚ãªãã¦æ¸ˆã‚€ã¨æ€ã„ã¾ã™ï¼\n ãƒ¡ãƒ¼ãƒ«: Gmail é…ä¿¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : Anchor éŒ²éŸ³: Zencastr ç”»é¢å…±æœ‰: Google Meet ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: Scrapbox + GitHub ç·¨é›†: Audacity éŸ³æ¥½ (BGM): Evoke Music ã‚¢ã‚¤ã‚³ãƒ³: Canva  1. ãƒ¡ãƒ¼ãƒ«  å„ç¨®ã‚µã‚¤ãƒˆã«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™»éŒ²ã™ã‚‹éš›ã«ã¯ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒå¿…é ˆãªã®ã§ï¼Œã¾ãšå…±é€šã§åˆ©ç”¨ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸï¼ ç°¡å˜ã«ä½œæˆã§ãã‚‹ã®ã§ï¼ŒGmailã‚’æ–°è¦ä½œæˆã—åˆ©ç”¨ã—ã¦ã„ã¾ã™ï¼  2. é…ä¿¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ   æœ€åˆã«ã‚‚æ›¸ãã¾ã—ãŸãŒï¼Œé…ä¿¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯Anchorã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ï¼ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ï¼ŒPodcast name, descriptionãªã©ã‚’è¨­å®šã™ã‚‹ã ã‘ã§å¤§ä¸ˆå¤«ã§ã™ï¼ç„¡æ–™ã§ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã®ã§ãŠã™ã™ã‚ã§ã™ï¼ New Episodeã‹ã‚‰éŒ²éŸ³ã—ãŸã‚Šï¼Œæ—¢ã«ã‚ã‚‹éŸ³æºã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã«ãªã£ã¦ã„ã¾ã™ï¼ã¾ãŸï¼ŒBGMãªã©ã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ï¼ ãŸã ï¼Œé éš”åœ°ã«ã„ã‚‹äººåŒå£«ã§ã®è¤‡æ•°äººéŒ²éŸ³ã¯å‡ºæ¥ãªã•ãã†ã ã£ãŸã®ã§ï¼Œåƒ•ãŸã¡ã¯éŒ²éŸ³ã¯å¾Œè¿°ã®åˆ¥ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã“ã¨ã«ã—ã¾ã—ãŸï¼ éŸ³æºã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ï¼Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã®æŠ•ç¨¿äºˆç´„ãŒã§ãã¾ã™ï¼ãã—ã¦ï¼Œæœ€åˆã®EpisodeãŒç™»éŒ²ã•ã‚Œã‚‹ã¨ï¼Œè‡ªåˆ†ãŸã¡ã ã‘ã®Public SiteãŒç”Ÿæˆã•ã‚Œï¼Œãã“ã§æ–°ã—ã„Podcastã‚’è´ãã“ã¨ãŒã§ãã¾ã™ï¼  WHERE TO LISTENã®éƒ¨åˆ†ã§ã™ãŒï¼Œæ–°ã—ã„PodcastãŒé…ä¿¡ã•ã‚ŒãŸã‚‰ï¼ŒRSSã®ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ãŒæ¤œçŸ¥ã—ã¦ï¼Œè‰²ã‚“ãªã‚¢ãƒ—ãƒªã§è´ãã“ã¨ãŒã§ãã¾ã™ï¼ãŸã ã—ï¼ŒSpotifyã¨Apple Podcastsã«é–¢ã—ã¦ã¯ï¼ŒRSSã®URLã‚’ç™»éŒ²ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼è©³ã—ãã¯ã“ã¡ã‚‰ã®noteè¨˜äº‹ãŒå‚è€ƒã«ãªã‚‹ã‹ã¨æ€ã„ã¾ã™ï¼ã¡ãªã¿ã«ï¼ŒRSSã®URLã¯é…ä¿¡ãŒé–‹å§‹ã—ãŸã‚‰è¡¨ç¤ºã•ã‚Œã‚‹Settings-\u0026gt;Distributionã‹ã‚‰ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n3. éŒ²éŸ³ éŒ²éŸ³ã¯Anchorä¸Šã§ã¯è¡Œã‚ãšï¼ŒZencastrã¨ã„ã†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã¾ã—ãŸï¼ã¾ãŸZencastrã¯è¤‡æ•°äººã®éŒ²éŸ³ã‚‚è¡Œã†ã“ã¨ãŒã§ãï¼Œéå¸¸ã«ä¾¿åˆ©ã§ã™ï¼\n ãƒ—ãƒ©ãƒ³ã¯ç„¡æ–™ã®Hobbyistã¨æœ‰æ–™ã®ProfessionalãŒã‚ã‚Šã¾ã™ï¼åƒ•ãŸã¡ã¯ç„¡æ–™ãƒ—ãƒ©ãƒ³ã‚’ä½¿ã£ã¦ã„ã¾ã™ãŒï¼Œåˆ¶é™ã¨ã—ã¦ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼\n ç„¡æ–™ãƒ—ãƒ©ãƒ³ã®åˆ¶é™ï¼š  1ï¼ã‚²ã‚¹ãƒˆã¯2åã¾ã§ 2ï¼1ãƒ¶æœˆã‚ãŸã‚Š8æ™‚é–“ã®éŒ²éŸ³æ™‚é–“    åŸºæœ¬çš„ã«äºŒäººã§ã®é…ä¿¡ã‹ã¤é€±1å›30åˆ†ç¨‹åº¦ã®éŒ²éŸ³æ™‚é–“ãªã®ã§ï¼Œç„¡æ–™ãƒ—ãƒ©ãƒ³ã§å…¨ãå•é¡Œã‚ã‚Šã¾ã›ã‚“ï¼ã¾ãŸï¼ŒZencastrã§ã¯ç”»é¢ã®éŒ²ç”»ã‚‚ã§ãã‚‹ã¿ãŸã„ã§ã™ï¼ï¼ˆâ€»ã‚³ãƒ­ãƒŠã®æœŸé–“ã¯ï¼Œç„¡æ–™ãƒ—ãƒ©ãƒ³ã§ã‚‚ã‚²ã‚¹ãƒˆã¨éŒ²éŸ³æ™‚é–“ãŒç„¡åˆ¶é™ã«ãªã£ã¦ã„ã‚‹ã¿ãŸã„ã§ã™ï¼‰\nã“ã¡ã‚‰ã‚‚AnchoråŒæ§˜ï¼Œã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆå¾Œï¼ŒCreate New Episodeã§æ–°è¦ä½œæˆã‚’è¡Œã†ã¨ç”»é¢ã¨éŸ³å£°ã®éŒ²ç”»ãƒ»éŸ³å£°éŒ²ç”»ï¼ˆç”»é¢è¡¨ç¤ºã‚ã‚Šï¼‰ãƒ»éŸ³å£°éŒ²ç”»ã®ã¿ã®3ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é¸æŠã—ã¾ã™ï¼\nã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥ã‚Œã¦ä½œæˆã™ã‚‹ã¨ï¼Œä¸‹è¨˜ã®ã‚ˆã†ãªç”»é¢ãŒå‡ºã¾ã™ï¼\nã“ã“ã§ï¼ŒInviteã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨åŒæ™‚ã«ä¼šè©±ã™ã‚‹äººã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã«ãƒªãƒ³ã‚¯ã‚’é€ä»˜ã™ã‚‹å½¢ã§æ‹›å¾…ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼Inviteã—ãŸäººãŒå…¥ã£ã¦ãã‚‹ã¨ï¼Œãã®ã¾ã¾é€šè©±çŠ¶æ…‹ã«ãªã‚ŠéŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã“ã¨ã§ï¼Œãã®ã¾ã¾ä¸¡æ–¹ã®éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nã‚ã¨ã¯ï¼ŒéŒ²éŸ³çµ‚äº†å¾Œå‚åŠ ã—ã¦ã„ãŸäººã®éŸ³å£°ã‚’MP3ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ï¼ˆã“ã‚Œã¯ç®¡ç†è€…ã®ã¿å¯èƒ½ãªæ“ä½œï¼‰\nåƒ•ãŸã¡ã¯ä½¿ã‚ãªã‹ã£ãŸã§ã™ãŒï¼ŒMacã§ãƒãƒƒãƒˆé€šè©±ã®éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹æ–¹æ³•ï¼ˆSoundflower, LadioCast, GarageBandï¼‰ã®è¨˜äº‹ã‚’ç´¹ä»‹ã—ã¦ãŠãã¾ã™ï¼â†’ Macã§ãƒãƒƒãƒˆé€šè©±ã®éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹æ–¹æ³•ï¼ˆSoundflower, LadioCast, GarageBandï¼‰\n4. ç”»é¢å…±æœ‰ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã‚Šè³‡æ–™ãªã‚Šã‚’è¦‹ãªãŒã‚‰ä¼šè©±ãŒã™ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ï¼Œç”»é¢å…±æœ‰ãŒå¿…è¦ã«ãªã£ã¦ãã¾ã™ï¼ãã®ãŸã‚ã«ï¼ŒGoogle Meetã‚’ä½¿ã£ã¦ç”»é¢å…±æœ‰ã—ãªãŒã‚‰ä¼šè©±ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼\n5. ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå°æœ¬ãƒ»è¦ç´„ãªã©ï¼‰ åéŒ²ã‚’è¡Œã†å‰ã«ï¼Œäº‹å‰ã«30åˆ†ç¨‹åº¦ä¼šè©±ã—ã¦ä½•ã‚’è©±ã™ã‹æ±ºã‚ã¦ã„ã¾ã™ï¼ãã®éš›ã«ï¼ŒScrapboxã‚’æ´»ç”¨ã—ã¦å°æœ¬ã‚’ä½œæˆã—ãŸã‚Šï¼Œãƒã‚¿å¸³ãªã©ã‚‚é›‘å¤šã«æ›¸ã„ã¦ã„ã¾ã™ï¼ã‚ã¨ã¯ï¼Œå…±æœ‰ã—ã¦ãŠããŸã„ã“ã¨ã‚’Scrapboxã«æ›¸ã„ã¦åŸºæœ¬çš„ã«ã¯ã“ã“ã‚’è¦‹ãªãŒã‚‰ã„ã¤ã‚‚åéŒ²ã—ã¦ã„ã¾ã™ï¼\nå‚è€ƒã«ã—ãŸè¨˜äº‹ â†’ åˆã‚ã¦ã®ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€è©¦ã—ã¦æ°—ã¥ã„ãŸã€Œå£°ã€ã®é†é†å‘³ã¨9ã¤ã®ãƒ†ã‚£ãƒƒãƒ—ã‚¹\nScrapboxã®ä»–ã«ã¯ï¼ŒGitHubã‚‚ä½¿ã£ã¦ã¾ã™ï¼ã“ã¡ã‚‰ã¯ï¼ŒOrganizationã‚’ä½œæˆã—ï¼Œãã“ã«Podcastç”¨ã®repositoryã‚’ã•ã‚‰ã«ä½œæˆã—ã¦ï¼Œè‡ªå·±ç´¹ä»‹ãƒšãƒ¼ã‚¸ã‚„å„é…ä¿¡ã®åéŒ²å†…å®¹ã®è¦ç´„ã‚’æ›¸ãè¨˜ã—ã¦ã„ã¾ã™ï¼ãƒšãƒ¼ã‚¸ã®æ›´æ–°æ™‚ã«ã¯issueã‚’ä½œæˆã—ï¼Œä½•ã‚’ã—ãŸã‹è¨˜éŒ²ãŒæ®‹ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼\n6. ç·¨é›† ç·¨é›†ã«é–¢ã—ã¦ã¯ï¼Œç‰¹åˆ¥ä½•ã‹ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã§ã™ï¼ãªã‚‹ã¹ãæ™‚é–“ã‚’ã‹ã‘ãšç„¡ç†ãªãé€²ã‚ã¦ã„ããŸã„ã¨æ€ã£ã¦ã„ã‚‹ã®ã§ï¼Œè¡Œã£ã¦ã„ã‚‹å†…å®¹ã¨ã—ã¦ã¯ä¸‹è¨˜2ç‚¹ã§ã™ï¼\n éŸ³é‡èª¿æ•´ãƒ»BGMæŒ¿å…¥ åéŒ²ä¸­ã«äºˆæœŸã—ãªã„å‰²ã‚Šè¾¼ã¿ãŒå…¥ã£ã¦ï¼ŒåéŒ²ã‚’æ­¢ã‚ãŸéš›ã®ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»ä¸è¦ãªä¼šè©±ã®å‰Šé™¤  ä¸€é€šã‚Šè‡ªåˆ†ãŸã¡ã®ä¼šè©±ã‚’èã„ã¦ï¼Œæ°—ã«ãªã‚‹éƒ¨åˆ†ãŒã‚ã‚Œã°ãƒˆãƒªãƒŸãƒ³ã‚°ãªã©ã—ã¦ã„ã‚‹ãã‚‰ã„ã«ãªã‚Šã¾ã™ï¼\nç·¨é›†ã‚½ãƒ•ãƒˆã¯Audacityã‚’ä½¿ã£ã¦ã„ã¦ï¼Œæ˜”ã‹ã‚‰ã‚ã‚‹éŸ³æ¥½ç·¨é›†ã‚½ãƒ•ãƒˆã«ãªã‚Šã¾ã™ï¼Windowsãƒ»Macã©ã¡ã‚‰ã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ Macã®å ´åˆã ã¨åˆã‚ã‹ã‚‰å…¥ã£ã¦ã„ã‚‹GarageBandãªã©ã‚‚ä½¿ãˆã‚‹ã¿ãŸã„ã§ã™ï¼\n7. éŸ³æ¥½ (BGM) Podcastã‚’é…ä¿¡ã™ã‚‹æ™‚ã«ã¯ï¼Œè‡ªåˆ†ãŸã¡ã®éŸ³å£°ã«åŠ ãˆã¦BGMã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ï¼ãŸã ï¼Œè‡ªåˆ†ãŸã¡ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«BGMã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã«ã¯ï¼Œè‘—ä½œæ¨©ãªã©ãŒçµ¡ã‚“ã§ãã‚‹ã®ã§ï¼Œå®‰æ˜“ã«å¥½ããªæ›²ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ï¼æ¥½æ›²1ã¤1ã¤ç¢ºèªã™ã‚‹ã®ã¯å¤§å¤‰ãªã®ã§ï¼Œä»Šå›ã¯è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼ã§AIãŒæ›²ã‚’ä½œæˆã—ã¦ãã‚Œã‚‹Evoke Musicã¨ã„ã†ã‚µã‚¤ãƒˆã®éŸ³æºã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼\nã“ã®ã‚µã‚¤ãƒˆã§ã¯ï¼Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ï¼Œãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åˆã£ãŸæ›²ã‚’AIãŒè‡ªå‹•ã§ä½œæˆã—ã¦ãã‚Œã¾ã™ï¼1æ›²ã‚ãŸã‚Šæ•°åˆ†ç¨‹åº¦ã®æ›²ã«ãªã‚Šã¾ã™ï¼\nâ€» Î²ç‰ˆã®æ™‚ã¯ç„¡æ–™ã§ä½¿ãˆã¦ã¾ã—ãŸãŒï¼Œä»Šã¯æœ‰æ–™ã«ãªã£ã¦ã—ã¾ã£ãŸã¿ãŸã„ã§ã™ï¼\n8. ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆãªã©ï¼‰ Anchorã«ã¯ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆãŒè¨­å®šã§ãã‚‹ã®ã§ï¼Œãã®ã‚¢ã‚¤ã‚³ãƒ³ãªã©ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ï¼ŒCanvaã¨ã„ã†ãƒ‡ã‚¶ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’åˆ©ç”¨ã—ã¾ã—ãŸï¼Canvaã¯è±Šå¯Œãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚¶ã‚¤ãƒ³ãŒã‚ã‚‹ã®ã§ï¼Œãã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã«è‡ªåˆ†ã§ã„ã„æ„Ÿã˜ã«ç·¨é›†ã™ã‚‹ã ã‘ã§ã‹ãªã‚Šã‚ªã‚·ãƒ£ãƒ¬ãªãƒ­ã‚´ãªã©ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nç„¡æ–™ãƒ—ãƒ©ãƒ³ã ã¨ä¿å­˜æ™‚ã®ç”»åƒã‚µã‚¤ã‚ºã‚„è§£åƒåº¦ãªã©ã‚’å¤‰æ›´ã§ããªã„ã®ã§ï¼Œå°‘ã—æ®‹å¿µã§ã™ãŒï¼Œã‹ãªã‚Šã‚ªã‚¹ã‚¹ãƒ¡ã®ã‚µã‚¤ãƒˆã§ã™ï¼æœ‰æ–™ã ã¨ã‚‚ã£ã¨å‡ºæ¥ã‚‹å¹…ãŒå¢—ãˆãã†ã§ã™ãŒï¼Œç¾çŠ¶ã ã¨ç„¡æ–™ãƒ—ãƒ©ãƒ³ã§ã‚‚ååˆ†ã‹ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼\nãŠã‚ã‚Šã« ä»Šå›ã¯6æœˆã‹ã‚‰é–‹å§‹ã—ãŸPodcastã«ã¤ã„ã¦ï¼Œã‚„ã‚ã†ã¨æ€ã£ãŸã‚­ãƒƒã‚«ã‚±ã¨ãã®é…ä¿¡æ–¹æ³•ã‚’ã¾ã¨ã‚ã¾ã—ãŸï¼é…ä¿¡æ–¹æ³•ã«ã¤ã„ã¦ã¯æ„å¤–ã¨è¨˜äº‹ãŒãªã‹ã£ãŸã®ã§ï¼Œã‚‚ã—ã“ã‚Œã‹ã‚‰é…ä¿¡ã—ã‚ˆã†ã¨è€ƒãˆã¦ã„ã‚‹äººã®å‚è€ƒã«ãªã‚Œã°å¬‰ã—ã„ã§ã™ï¼\nä»Šå›ç´¹ä»‹ã—ãŸæ–¹æ³•ä»¥å¤–ã«ã‚‚ï¼Œã‚‚ã£ã¨è‰¯ã„é…ä¿¡æ–¹æ³•ãŒã‚ã‚‹ã¨æ€ã†ã®ã§ï¼Œã”å­˜çŸ¥ã®æ–¹ã¯æ˜¯éæ•™ãˆã¦æ¬²ã—ã„ã§ã™ï¼ï¼ä¸€äººã§ã‚‚å¤šãã®ãƒ†ãƒƒã‚¯ç³»PodcastãŒå¢—ãˆã¦ç››ã‚Šä¸ŠãŒã‚‹ã¨è‰¯ã„ãªã¨æ€ã„ã¾ã™ï¼ï¼\nP.S. ç´°ã‹ã„è¨­å®šã‚„ç™»éŒ²ãªã©èããŸã„ã“ã¨ãŒã‚ã‚‹å ´åˆã«ã¯ï¼Œé æ…®ãªãTwitterãªã©ã§ã”é€£çµ¡é ‚ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ï¼\n","date":"2021-06-13","permalink":"https://masatakashiwagi.github.io/portfolio/post/podcast-broadcast-method/","tags":["Poem"],"title":"Podcastã«ã‚ˆã‚‹é…ä¿¡ã®ã‚­ãƒƒã‚«ã‚±ã¨ãã®æ–¹æ³•"},{"content":"Kaggle-Shopeeã‚³ãƒ³ãƒšã®æŒ¯ã‚Šè¿”ã‚Š 2021/03/09~2021/05/11ã¾ã§é–‹å‚¬ã—ã¦ã„ãŸShopeeã‚³ãƒ³ãƒšã®æŒ¯ã‚Šè¿”ã‚Šã«ãªã‚Šã¾ã™ï¼\n2é€±é–“ç¨‹åº¦ã—ã‹æ‰‹ã‚’å‹•ã‹ã›ãªã‹ã£ãŸã§ã™ãŒï¼Œä¹…ã—ã¶ã‚Šã«å‚åŠ ã—ãŸã®ã§å‚™å¿˜éŒ²ã¨ã—ã¦è¨˜éŒ²ã‚’æ®‹ã—ã¦ãŠãã¾ã™ï¼\næœ€çµ‚çš„ãªçµæœã¯179th/2464ã§éŠ…ãƒ¡ãƒ€ãƒ«ã§ï¼Œç‰¹ã«å‡ã£ãŸã“ã¨ã¯ä½•ã‚‚ã—ã¦ã„ãªã‹ã£ãŸã®ã§ï¼Œå¦¥å½“ã‹ãªã¨æ€ã„ã¾ã™ï¼\nã“ã®ã‚³ãƒ³ãƒšã¯ä¸Šä½10ãƒãƒ¼ãƒ ä¸­7ãƒãƒ¼ãƒ ãŒæ—¥æœ¬äººãƒãƒ¼ãƒ ã§ï¼Œæ—¥æœ¬äººã®ãƒ¬ãƒ™ãƒ«ã®é«˜ã•ã‚’æ”¹ã‚ã¦å®Ÿæ„Ÿã§ãã‚‹ã‚³ãƒ³ãƒšã§ã—ãŸï¼\næ¦‚è¦ ã‚³ãƒ³ãƒšã®å†…å®¹ã¯ç°¡å˜ã«è¨€ã†ã¨ï¼Œç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ç”¨ã„ã¦ã€2ã¤ã®ç”»åƒã®é¡ä¼¼æ€§ã‚’æ¯”è¼ƒã—ï¼Œã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒåŒã˜å•†å“ã§ã‚ã‚‹ã‹ã‚’äºˆæ¸¬ã™ã‚‹ã‚³ãƒ³ãƒšã«ãªã‚Šã¾ã™ï¼\n é–‹å‚¬æœŸé–“: 2021/03/09 ~ 2021/05/11 å‚åŠ ãƒãƒ¼ãƒ æ•°: 2464 äºˆæ¸¬å¯¾è±¡: posting_idåˆ—ã«ãƒãƒƒãƒã™ã‚‹å…¨ã¦ã®posting_idã‚’äºˆæ¸¬ã™ã‚‹ï¼ãŸã ã—ï¼Œposting_idã¯å¿…ãšself-matchã—ï¼Œã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸Šé™ã¯50å€‹ã¨ãªã£ã¦ã„ã‚‹ï¼ ãƒ‡ãƒ¼ã‚¿: æŠ•ç¨¿IDï¼Œç”»åƒï¼Œå•†å“ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼Œç”»åƒã®çŸ¥è¦šãƒãƒƒã‚·ãƒ¥(perceptual hash)ï¼Œãƒ©ãƒ™ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ID è©•ä¾¡æŒ‡æ¨™: F1-Score ãã®ä»–: ã‚³ãƒ¼ãƒ‰ã‚³ãƒ³ãƒš  My Solution  ç”»åƒç‰¹å¾´é‡ãƒ»ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ãƒ»ç”»åƒã®phashå€¤ã‚’concatã—ã¦çµæœã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ã—ãŸã‚‚ã®ã‚’æœ€çµ‚çš„ãªäºˆæ¸¬å€¤ã¨ã—ã¾ã—ãŸï¼ ä½•ã‚‚è¤‡é›‘ãªã“ã¨ã¯ã—ã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒï¼Œçµæœçš„ã«éŠ…ãƒ¡ãƒ€ãƒ«ã‚’å–ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸï¼  Image Model  eca_nfnet_l0  loss: ArcFace pooling: AdaptiveAvgPool2d scheduler: CosineAnnealingLR loss(criterion): CrossEntropyLoss size: 512*512   eca_nfnet_l1  loss: CurricularFace pooling: MAC scheduler: CosineAnnealingLR loss(criterion): FocalLoss size: 512*512   efficientnet_b3  loss: ArcFace pooling: GeM scheduler: CosineAnnealingLR loss(criterion): FocalLoss size: 512*512   swin_small_patch4_window7_224  loss: CurricularFace scheduler: CosineAnnealingLR loss(criterion): FocalLoss size: 224*224   common  augmentation by albumentations.  HorizontalFlip VerticalFlip Rotate RandomBrightness   optimizer  Adam      å°‘ã—å·¥å¤«ã—ãŸãƒã‚¤ãƒ³ãƒˆ  ç”»åƒç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹éƒ¨åˆ†ã§ï¼Œã„ãã¤ã‹å·¥å¤«ã—ãŸç‚¹ã‚’ã‚ã’ã¾ã™ï¼  CNN Image Retrievalã‚’å‚è€ƒã«ã—ã¾ã—ãŸï¼     lossã«ArcFaceã¨CurricularFaceã‚’ç”¨ã„ãŸ  ArcFaceã‚’ä½¿ã£ã¦ã„ã‚‹äººãŒå¤šã‹ã£ãŸãŒï¼ŒCurricularFaceã‚‚ä½¿ã„ã¾ã—ãŸï¼ã‚¹ã‚³ã‚¢çš„ã«ã¯CurricularFaceã®æ–¹ãŒã‚ˆã‹ã£ãŸã§ã™ï¼   ã„ãã¤ã‹ã®ãƒ¢ãƒ‡ãƒ«ã§poolingå±¤ã«GeMã¨MACã‚’ç”¨ã„ãŸ  Google Landmark Retrieval Challengeã§ä¸Šæ‰‹ãã„ã£ã¦ã„ãŸGeMã‚„MACãªã©ã®ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’ç”¨ã„ã¾ã—ãŸï¼   loss(criterion)ã«FocalLossã‚’ç”¨ã„ãŸ æœ€çµ‚çš„ã«å¾—ã‚‰ã‚ŒãŸç‰¹å¾´é‡ã‚’concatã—ãŸå¾Œï¼ŒZCAWhiteningã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›ã‚’è¡Œã£ãŸ  æœ‰åŠ¹ã§ãªã‹ã£ãŸã‚‚ã®  ä¸€æ–¹ã§ï¼Œä¸Šæ‰‹ãã„ã‹ãªã‹ã£ãŸå†…å®¹ã¨ã—ã¦ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ï¼  resnext50_32x4d swin_small_patch4_window7_224 with ArcFace CosFace, AdaCos PCA Whitening (worse than ZCAWhitening)    Text Model  paraphrase-xlm-r-multilingual-v1  loss: ArcFace scheduler: linear schedule with warmup loss(criterion): CrossEntropyLoss optimizer: AdamW   TF-IDF  textã®æ–¹ã®ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹ã«æ”¹è‰¯ã™ã‚‹æ™‚é–“ãŒå–ã‚Œãªã‹ã£ãŸã®ã§ï¼Œã»ã¨ã‚“ã©æ‰‹ã‚’ä»˜ã‘ã‚Œã¦ãªã‹ã£ãŸã§ã™ï¼\n transformerã¨TF-IDFã§å¾—ã‚‰ã‚ŒãŸç‰¹å¾´é‡ãã‚Œãã‚Œã«å¯¾ã—ã¦ï¼ŒCosine Similarityã‚’è¨ˆç®—ã—ï¼Œãƒ†ã‚­ã‚¹ãƒˆã®predictionã‚’ä½œæˆã—ã¾ã—ãŸï¼  æœ€çµ‚çš„ãªäºˆæ¸¬å€¤ã¯ç”»åƒç‰¹å¾´é‡ã¨ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã«åŠ ãˆã¦ï¼Œç”»åƒã®phashå€¤ã‚’è¿½åŠ ã—ã¦ï¼Œãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚’å–ã£ãŸå€¤ã¨ã—ã¦ã„ã¾ã™ï¼\nåçœ  post-processingãŒå…¨ç„¶ã§ãã¦ã„ãªã‹ã£ãŸ  ä»–ã®è§£æ³•ã‚’è¦‹ã‚‹ã«ï¼Œpost-processingã§ã‚¹ã‚³ã‚¢ãŒä¼¸ã³ã¦ã„ã‚‹ã®ã§ï¼Œã“ã®éƒ¨åˆ†ã¯çµæ§‹å¤§äº‹ã ã£ãŸã‚“ã ãªã¨æ„Ÿã˜ã¦ã„ã¾ã™ï¼ 6ä½ã®è§£æ³•ã«ã‚‚ã‚ã‚Šã¾ã—ãŸãŒï¼Œä»Šå›ã®ã‚³ãƒ³ãƒšã§ã¯ï¼Œlabel_groupã®é•·ã•ãŒ2ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‹ã‚‰ï¼Œã€Œäºˆæ¸¬ã—ãŸçµæœã®posting_idãŒ1ã¤ã—ã‹ãªã„å ´åˆï¼Œå¼·åˆ¶çš„ã«ä¼¼ãŸã‚‚ã®ã‚’æŒã£ã¦ãã¦ï¼Œ2ã¤ã«ã™ã‚‹ã€ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã§LBãŒã‹ãªã‚Šä¸ŠãŒã‚‹ã¿ãŸã„   Imageã¨Textã‚’Multi-modalçš„ã«ãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚“ã§å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã¦ã„ãªã‹ã£ãŸ ã‚°ãƒ©ãƒ•ç†è«–å…¨ç„¶ã‚ã‹ã£ã¦ãªã„ã§ã™ç¬‘ ç´°ã‹ã„éƒ¨åˆ†  ä»–ã®optimizerã‚’è©¦ã™  SAMã¨ã‹   Database-side feature augmentation (DBA) / Query Extension (QE)  å…¨ç„¶çŸ¥ã‚‰ãªã‹ã£ãŸã®ã§ï¼ŒEnd-to-end Learning of Deep Visual Representations for Image Retrievalã‚’èª­ã‚“ã§å‹‰å¼·ã—ãŸã„   é–¾å€¤ã®èª¿æ•´ ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ      ã“ã“ã‹ã‚‰ã¯ä¸Šä½ã®è§£æ³•ã‚’æ›¸ããŸã„ã¨æ€ã„ã¾ã™ï¼æ•°ã‚‚ãã‚Œãªã‚Šã«ã‚ã‚‹ã®ã§ï¼Œè¼‰ã›ã‚‹ã®ã¯ä¸Šä½5ã¤ã«ã—ã¾ã™ï¼æœ€å¾Œã«ä¸Šä½5ã¤ä»¥å¤–ã«ã‚‚Discussionsã«æŠ•ç¨¿ã•ã‚Œã¦ã„ã‚‹è§£æ³•ã®ãƒªãƒ³ã‚¯ã‚’è¼‰ã›ã¦ãŠãã¾ã™ï¼\n1st Place Solution è§£æ³•ã¯ã“ã¡ã‚‰ã«ãªã‚Šã¾ã™: 1st Place Solution - From Embeddings to Matches\nModel  Image: 2ã¤ã®ãƒ¢ãƒ‡ãƒ«  eca_nfnet_l1 * 2   Text: 5ã¤ã®ãƒ¢ãƒ‡ãƒ«  xlm-roberta-large xlm-roberta-base cahya/bert-base-indonesian-1.5G indobenchmark/indobert-large-p1 bert-base-multilingual-uncased   loss: ArcFace poolingã—ãŸå¾Œã«batch normalizationã¨feature-wise normalizationã‚’è¡Œã£ãŸ ArcFaceã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ãŸ  å­¦ç¿’æ®µéšã§å¾ã€…ã«marginã‚’å¤§ããã—ãŸï¼ˆåŸ‹ã‚è¾¼ã¿è¡¨ç¾ã®qualityã«å½±éŸ¿ã™ã‚‹ï¼‰  ç”»åƒã«å¯¾ã™ã‚‹margin: 0.8~1.0 ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹margin: 0.6~0.8   marginã‚’å¤§ããã™ã‚‹ã¨ï¼Œãƒ¢ãƒ‡ãƒ«ã®åæŸã«å•é¡ŒãŒå‡ºãŸã®ã§ï¼Œä»¥ä¸‹ã‚’è¡Œã£ãŸ  warmup stepsã‚’å¤§ããã™ã‚‹ cosineheadã«å¯¾ã™ã‚‹learning rateã‚’ã‚ˆã‚Šå¤§ããã™ã‚‹ gradient clippingã‚’è¡Œã†   class-size-adaptive marginã‚‚è©¦ã—ãŸãŒï¼Œä¸å‡è¡¡æ€§ãŒå°ã•ã‹ã£ãŸãŸã‚ï¼Œæ”¹å–„ã¯å°‘ã—ã ã‘ã ã£ãŸ  image: class_size^-0.1 text: class_size^-0.2     global average poolingã®å¾Œã«FCå±¤ã‚’è¿½åŠ ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ãŒæ‚ªããªã‚‹ãŒï¼Œfeature-wise normalizationã®å‰ã«batch normalizationã‚’è¿½åŠ ã™ã‚‹ã¨ã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã—ãŸ  Features  Combining Image \u0026amp; Text Matches  ãƒãƒƒãƒãƒ³ã‚°ã•ã›ã‚‹æ–¹æ³•ã‚’ã„ãã¤ã‹ãƒˆãƒ©ã‚¤ã—ãŸ   ç”»åƒã®embeddingã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ³ã‚°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®embeddingã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ³ã‚°ã‚’çµåˆã™ã‚‹ ç”»åƒã®embeddingã¨ãƒ†ã‚­ã‚¹ãƒˆã®embeddingã‚’concatã—ã¦ã‹ã‚‰ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹ 1ã¨2ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹   ã“ã‚Œã¯ï¼Œç”»åƒã®embeddingãŒå¼·ãç¤ºå”†ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãƒ»ãƒ†ã‚­ã‚¹ãƒˆã®embeddingãŒå¼·ãç¤ºå”†ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãƒ»ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®embeddingãŒã©ã¡ã‚‰ã‚‚é©åº¦ã«ç¤ºå”†ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã‚‹     Iterative Neighborhood Blending (INB)  QE/DBAã¨ã¯å°‘ã—ç•°ãªã‚‹ï¼Œembeddingã‹ã‚‰ãƒãƒƒãƒã™ã‚‹å•†å“ã‚’æ¤œç´¢ã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œã£ãŸ k-Nearest Neighbor Search:  è¿‘éš£æ¢ç´¢ãƒ©ãƒªãƒ–ãƒ©ãƒª: faiss (k=51: 50(è‡ªèº«ä»¥å¤–)) + 1(è‡ªèº«))   Threshold:  ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ã‚³ã‚µã‚¤ãƒ³è·é›¢(=1-ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦)ã«å¤‰æ›ã—ï¼Œdistance\u0026lt;thresholdã‚’æº€ãŸã™(matches, distances)ã®ãƒšã‚¢ã‚’å–å¾—ã—ãŸ é–¾å€¤å‡¦ç†ã‚’è¡Œã†å ´åˆï¼Œ1ã¤ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦å°‘ãªãã¨ã‚‚2ã¤ä»¥ä¸Šã®ãƒãƒƒãƒãŒã‚ã‚‹ã“ã¨ãŒã‚³ãƒ³ãƒšã§ä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ã®ã§ï¼ŒdistanceãŒmin2-thresholdã‚’è¶…ãˆãŸå ´åˆã«ã®ã¿ï¼ŒäºŒç•ªç›®ã«è¿‘ã„ãƒãƒƒãƒã‚’é™¤å¤–ã™ã‚‹   Neighborhood Blending:  kNNã«ã‚ˆã‚‹ã‚µãƒ¼ãƒã¨min2ã«ã‚ˆã‚‹é–¾å€¤å‡¦ç†ã‚’ã—ãŸå¾Œï¼Œå„ã‚¢ã‚¤ãƒ†ãƒ ã®(matches, similarities)ãƒšã‚¢ã‚’å–å¾—ã—ï¼Œã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹  å„ãƒãƒ¼ãƒ‰ã¯ã‚¢ã‚¤ãƒ†ãƒ ï¼Œã‚¨ãƒƒã‚¸ã®é‡ã¿ã¯2ã¤ã®ãƒãƒ¼ãƒ‰é–“ã®é¡ä¼¼æ€§ã‚’ç¤ºã™ è¿‘å‚ã®ã¿ãŒç¹‹ãŒã£ã¦ãŠã‚Šï¼Œé–¾å€¤æ¡ä»¶ã¨min2æ¡ä»¶ã‚’æº€ãŸã•ãªã„ãƒãƒ¼ãƒ‰ã¯åˆ‡æ–­ã•ã‚Œã‚‹   è¿‘å‚ã®ã‚¢ã‚¤ãƒ†ãƒ ã®æƒ…å ±ã‚’ä½¿ã„ãŸã„ã®ã§ï¼Œã‚¯ã‚¨ãƒªã‚¢ã‚¤ãƒ†ãƒ ã®embeddingã‚’æ”¹è‰¯ã—ï¼Œã‚ˆã‚Šã‚¯ãƒ©ã‚¹ã‚¿ã‚’æ˜ç¢ºã«ã™ã‚‹  é‡ã¿ã¨ã—ã¦é¡ä¼¼æ€§ã‚’æŒã¤è¿‘å‚ã®embeddingã‚’åŠ é‡åˆè¨ˆã—ï¼Œãã‚Œã‚’ã‚¯ã‚¨ãƒªembeddingã«è¿½åŠ ã™ã‚‹    ä¸Šå›³ã‚’ç°¡å˜ã«èª¬æ˜ã™ã‚‹ã¨ï¼Œæœ€åˆAã¯[B,C,D]ã¨ç¹‹ãŒã£ã¦ã„ã‚‹ãŒï¼ŒåŠ é‡åˆè¨ˆã—ãŸçµæœé–¾å€¤=0.5ã®å ´åˆï¼ŒCã¨ã®æ¥ç¶šãŒåˆ‡ã‚Œã¦ï¼ŒAã¯[B,D]ã®ã¿ã¨æ¥ç¶šã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ ã“ã®NBã®å‡¦ç†ã‚’è©•ä¾¡æŒ‡æ¨™ã®æ”¹å–„ãŒæ­¢ã¾ã‚‹ã¾ã§ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã™ã‚‹ æœ€çµ‚çš„ãªNBã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ä»¥ä¸‹ã«ãªã‚‹    About Threhsold Tuning:  èª¿æ•´ã™ã‚‹é–¾å€¤ã¯å…¨éƒ¨ã§10ç¨®é¡ã‚ã‚‹  stage1ã®text, image, combinationã®é–¾å€¤ãŒ3ã¤ stage2ã®é–¾å€¤ãŒ1ã¤ stage3ã®é–¾å€¤ãŒ1ã¤ ç›´æ¥æœ€çµ‚çµåˆéƒ¨åˆ†ã«ç¹‹ãŒã‚‹stage1ã®text, imageã®é–¾å€¤ãŒ2ã¤ stage1~3ã®min2é–¾å€¤ãŒ3ã¤   æœ€çµ‚çš„ã«ã¯stage2,3ã®é–¾å€¤ã‚’2ã¤èª¿æ•´ã™ã‚‹ã ã‘ã§ã‚ˆã‹ã£ãŸ     Visualizations of Embeddings before/after INB  INBã®åŠ¹æœã‚’å¯è¦–åŒ–ã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹  (SHOPEE) Embedding Visualizations before/after INB è¦‹ã‚‹ã‹ã‚‰ã«å„ç‚¹ãŒå‡é›†ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿ã‚’å½¢æˆã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹      Others  ç”»åƒã«å¯¾ã™ã‚‹CutMix(p=0.1) ç”»åƒã®augmentation  horizontal flipã®ã¿ãŒã‚ˆã‹ã£ãŸ   madgrad optimizer: https://github.com/facebookresearch/madgrad å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ä½¿ã£ãŸå­¦ç¿’  2nd Place Solution è§£æ³•ã¯ã“ã¡ã‚‰ã«ãªã‚Šã¾ã™: 2nd place solution (matching prediction by GAT \u0026amp; LGB), 2nd Place Solution Code\nSummary  1st stage: ç”»åƒãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’å¾—ã‚‹ãŸã‚ã«Metric Learningã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ 2nd stage: åŒã˜label groupã«å±ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒšã‚¢ã‹ã©ã†ã‹ã‚’è­˜åˆ¥ã™ã‚‹ãŸã‚ã«\u0026quot;ãƒ¡ã‚¿\u0026quot;ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹  Model  image: 2ã¤ã®ãƒ¢ãƒ‡ãƒ«  backbone  nfnet-F0 ViT   loss: CurricularFace optimizer: SAM embeddingã®çµåˆ: F.normalize(torch.cat([F.normalize(emb1), F.normalize(emb2)], axis=1))   text: 3ã¤ã®ãƒ¢ãƒ‡ãƒ« + TF-IDF  indonesian-bert multilingual-bert paraphrase-xlm   image+text: nfnet-F0ã¨indonesian-bertã®FCå±¤ã®embeddingã‚’çµåˆã—ãŸã‚‚ã® Training Tips:  label groupã®ã‚µã‚¤ã‚ºã«åŸºã¥ã„ãŸSample Weighting  1 / (label group size) ** 0.4      Features Graph features  ãã‚Œãã‚Œã®ã‚¢ã‚¤ãƒ†ãƒ ã®top-Kã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®å¹³å‡ã¨åˆ†æ•£  K=5, 10, 15, 30, etc   æ¨™æº–åŒ–ï¼ˆmean=0, std=1ï¼‰ Pagerank  Others  ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã• #ã®è¨˜å· Levenshteinè·é›¢ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚º ç”»åƒã®é«˜ã•ã¨å¹… Query Extension  Ensemble Methodology  ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãã‚Œãã‚Œã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ã‚¹ãƒˆãªé–¾å€¤ã‚’è¨ˆç®—ã™ã‚‹ ä¸Šè¨˜é–¾å€¤ã§ãã‚Œãã‚Œã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤ã‚’å·®ã—å¼•ã å·®ã—å¼•ã‹ã‚ŒãŸäºˆæ¸¬å€¤ã‚’åˆè¨ˆã™ã‚‹ åˆè¨ˆå€¤\u0026gt;0ã®å ´åˆï¼Œã‚¢ã‚¤ãƒ†ãƒ ãƒšã‚¢ãŒåŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã«å±ã™ã‚‹ã¨ã™ã‚‹ ãŠäº’ã„ã«ã‚¨ãƒƒã‚¸ã‚’æŒãŸãªã„ãƒšã‚¢ã‚’å‰Šé™¤ã™ã‚‹  A-Bã¯ã‚ã‚‹ãŒï¼ŒB-AãŒãªã„å ´åˆã¯ä¸¡æ–¹ã‚’å‰Šé™¤ã™ã‚‹    Post-Processing  ä¸­é–“ä¸­å¿ƒæ€§ãŒæœ€ã‚‚é«˜ã„ã‚¨ãƒƒã‚¸ã‚’å†å¸°çš„ã«å‰Šé™¤ã™ã‚‹ï¼ˆGraph-Basedï¼‰  Others  Performance and Memory Tunings  CuDF, cupy, cugraph: GPUã‚’æœ‰åŠ¹ã«ä½¿ã†ãŸã‚ã«ã¯å¤§äº‹ ForestInference: 40åˆ†ã‹ã‹ã‚‹CPUã§ã®æ¨è«–ãŒ2åˆ†ã«ãªã‚‹   Not worked  Graph-basedã®ç‰¹å¾´é‡ å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã®ä¸­å¿ƒæ€§ã¨jaccard End-to-end model Local feature matching    3rd Place Solution è§£æ³•ã¯ã“ã¡ã‚‰ã«ãªã‚Šã¾ã™: 3rd Place Solution (Triplet loss, Boosting, Clustering)\nModel  image: 2ã¤ã®ãƒ¢ãƒ‡ãƒ«  backbone  efficientnet_b2 ViT (DINO)     text: 2ã¤ã®ãƒ¢ãƒ‡ãƒ« (ç•°ãªã‚‹tokenizersã¨CLIP)  indonesian-bert multilingual-bert   common  loss: TripletLoss (margin=0.1) å„ã‚¨ãƒãƒƒã‚¯ï¼Œlabel_groupsã‹ã‚‰é‡è¤‡ã—ãŸãƒšã‚¢ã‚’ä½œæˆã—ï¼Œå„ãƒãƒƒãƒã§label_groupsã‹ã‚‰1ãƒšã‚¢ãŒæŒ¿å…¥ã•ã‚Œã‚‹ï¼ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯128ã‚’ä½¿ã£ã¦ã„ãŸãŸã‚ï¼Œãƒãƒƒãƒæ¯ã«64ã®é‡è¤‡ã‚’å–å¾—ã—ï¼Œãƒ©ãƒ³ãƒ€ãƒ ãª5ç‚¹ã§ãã‚Œã‚‰ã®å„ã€…ã‚’æ¯”è¼ƒã™ã‚‹ 5fold CVã§ï¼Œvalidationã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹æ™‚ã¯ï¼Œvalidation-foldã®ä¸­ã‹ã‚‰å€™è£œã‚’é¸ã¶ã®ã§ã¯ãªãï¼Œå­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«å…¨ä½“ã‹ã‚‰å€™è£œã‚’æ¢ã—ãŸ  ã“ã®æ–¹æ³•ã¯CV/LBã®gapã‚’æŠ‘ãˆã¦ï¼Œç›¸é–¢ã‚’å–ã‚‹ã“ã¨ãŒå‡ºæ¥ã‚‹ oofã‚’ç”¨æ„ã—ã¦ï¼Œ2nd-levelã®äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹ CVã‹ã‚‰å¾—ã‚‰ã‚ŒãŸ5ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§ï¼Œãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ¨è«–ã‚’è¡Œã£ãŸ ã‚ˆã‚Šé€Ÿãæ¨è«–ã™ã‚‹ãŸã‚ã«ã¯ï¼Œvalidationãªã—ã®1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«fitã•ã›ã‚‹ã“ã¨   ArcFaceã¯ä¸Šæ‰‹ãã„ã‹ãªã‹ã£ãŸ    Features  è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ï¼Œç•°ãªã‚‹è¡¨ç¾æ–¹æ³•ã‚’ä½œæˆã™ã‚‹ã®ãŒè‰¯ã„ å…¨ã¦ã®embeddingsã‹ã‚‰å€™è£œã¨ãªã‚‹è¿‘ã—ã„ã‚‚ã®ã‚’çµåˆã—ï¼Œãƒšã‚¢ãŒå®Ÿéš›ã«é‡è¤‡ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã«ã‹ã‹ã‚ã‚‰ãšã€binary targetã‚’ä½¿ç”¨ã—ã¦ãƒšã‚¢ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã™ã‚‹  3Mç‚¹ã®ãƒšã‚¢ãŒã‚ã‚Šï¼Œé‡è¤‡ç‡ã¯4%ã ã£ãŸ   ã“ã‚Œã‚‰ã«å¯¾ã—ã¦ï¼ŒGBM(=CatBoost)ã‚’ä½œæˆã—ï¼Œembeddingæ¯ã«è¨ˆç®—ã™ã‚‹  pairwise-distances (ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼Œãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãªã©) ä¸¡æ–¹ã®ç‚¹å‘¨è¾ºã®å¯†åº¦ points ranks   æœ€çµ‚çš„ã«ã¯500å€‹ç‰¹å¾´é‡ã‚’ä½œæˆã—ï¼ŒCVã‚„LBã‚’ä½¿ã„ãªãŒã‚‰ï¼Œé‡è¤‡ç¢ºç‡ã«ã‚ˆã‚‹é–¾å€¤ã®å€™è£œã‚’å‡ºã™\u0008 -\u0026gt; LB:0.76+  Post-Processing  ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã£ãŸãŒï¼Œembeddingsã‚’ä½¿ã†ã®ã§ã¯ãªãï¼Œpairwise-distanceã‚’ä½¿ã† é‡è¤‡æ¨å®šã®ãŸã‚ã«GBM(=CatBoost)ã®ç¢ºç‡ã‚’ä½¿ã„ï¼Œé¡ä¼¼åº¦ã‚’æ±‚ã‚ã‚‹ å‡é›†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¡ç”¨  å„å˜ä¸€ç‚¹ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ã¨ã—ã¦é–‹å§‹ã—ï¼Œå¹³å‡çš„ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãŒé–¾å€¤ã«ç­‰ã—ããªã‚‹ã¾ã§ãã‚Œã‚‰ã‚’ãƒãƒ¼ã‚¸ã—ã¦ã„ã ã‚¯ãƒ©ã‚¹ã‚¿ãŒå˜ä¸€ã®å ´åˆï¼Œæœ€ã‚‚è¿‘å‚ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ãƒãƒ¼ã‚¸ã™ã‚‹ -\u0026gt; LB:0.79    Others  æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«  half precision(torch AMP)ã‚’ä½¿ã£ã¦å­¦ç¿’ã¨æ¨è«–ã‚’è¡Œã£ãŸ ç”»åƒãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼Œç”»åƒã®èª­ã¿è¾¼ã¿ã¨ãƒªã‚µã‚¤ã‚ºã«NVIDIA DALIã‚’ä½¿ã£ãŸ GBMã®æ¨è«–ã«ã¯ï¼ŒRapids ForestInference Libraryã‚’ä½¿ã£ãŸ   ä¸Šè¨˜ã®æ–¹æ³•ã‚’ä½¿ã‚ãªã„ã¨ï¼Œ2æ™‚é–“ã§å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã ã£ãŸ  4th Place Solution è§£æ³•ã¯ã“ã¡ã‚‰ã«ãªã‚Šã¾ã™: 4th Place Solution\nModel  image: backboneã«nfnetã¨efficientnet  pooling: GeMï¼†Avg pooling embeddingãŒå¤§ãã„ã»ã©ï¼ŒLBã®ã‚¹ã‚³ã‚¢ãŒã‚ˆããªã£ãŸ loss: ArcFace marginã®èª¿æ•´ãŒå¤§äº‹ã ã£ãŸ   text: BERTãƒ™ãƒ¼ã‚¹ + TF-IDF  TF-IDF: ã‹ãªã‚Šå¤§ãã„embeddingã‚’ç”Ÿæˆã—ï¼Œnotebookä¸Šã§ã¯ãƒ¡ãƒ¢ãƒªã®åˆ¶ç´„ã‚’å—ã‘ã‚‹ãŸã‚ï¼ŒRandom Sparse Projectionã§æ¬¡å…ƒå‰Šæ¸›ã‚’è¡Œã£ãŸ loss: ArcFace marginã®èª¿æ•´ãŒå¤§äº‹ã ã£ãŸ    Ensemble  ç”»åƒã®embeddingãƒ»ãƒ†ã‚­ã‚¹ãƒˆï¼ˆBERTãƒ™ãƒ¼ã‚¹ï¼‰ã®embeddingãƒ»TF-IDFã®embeddingã‚’çµåˆã—ã¦ï¼Œæ­£è¦åŒ–ã—ãŸ ã“ã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã®ãã‚Œãã‚Œã«å¯¾ã—ã¦ï¼Œpairwiseã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ï¼Œ3ã¤ã®è¡Œåˆ—ã‚’ä½œæˆã—ãŸ  æœ€åˆã«äºŒä¹—ã—ï¼Œãã®å¾ŒåŠ é‡å¹³å‡ã‚’å–ã£ã¦è¡Œåˆ—ã‚’çµåˆã—ãŸ    Post-Processing  é–¾å€¤ã®èª¿æ•´ Rank2 matching  ã‚‚ã—ï¼ŒAãŒRank2ã«Bã‚’æŒã£ã¦ãŠã‚Šï¼ŒBã¯Rank2ã«Aã‚’æŒã£ã¦ã„ã‚‹å ´åˆï¼ŒãŠäº’ã„ã«è¿½åŠ ã™ã‚‹   Rank2ã¨Rank3ã®é•ã„ãŒå¤§ãã„å ´åˆï¼ŒRank2ã®IDã‚’è¿½åŠ ã™ã‚‹ å°‘ãªãã¨ã‚‚1ã¤ã®ä»–ã¨ã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆRank2ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒæ¥µç«¯ã«å°ã•ããªã‘ã‚Œã°ï¼‰ Query Expansion ãƒãƒƒãƒã—ã¦ã„ãªã„è¡Œã¨ã®å†ãƒãƒƒãƒãƒ³ã‚°  ãã®ä»–ä¸Šä½è§£æ³•ã®ãƒªãƒ³ã‚¯  Kaggle Shopeeã‚³ãƒ³ãƒšPrivate LBå¾…æ©Ÿæ ï¼†ãƒ—ãƒåçœä¼š 5th Place Solution 6th place solution 7th place solution 8th Place Solution Overview Public 16th / Private 10th Solution 11th Place Solution 14th Place Gold - Image Text Decision Boundary 15th place solution Public 13th / Private 16th solution 18th place solution - You really don\u0026rsquo;t need big models 19 place. Voting and similarity chain 26th Place Solution : Effective Cluster Separation and Neighbour Search [31st Place] Object Detection approach Public 39th / Private 37th Solution 48th Place Silver - Simple Baseline Public 56th / Private 57th Solution 62th Place Solution (Stacking Logistic Regression) 72nd place solution  ","date":"2021-05-14","permalink":"https://masatakashiwagi.github.io/portfolio/post/kaggle-shopee-solution/","tags":["Kaggle"],"title":"Kaggle-Shopeeã‚³ãƒ³ãƒšã®æŒ¯ã‚Šè¿”ã‚Šã¨ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³"},{"content":"ã¯ã˜ã‚ã« ä»Šã¾ã§ä»•äº‹ã§ã¯ï¼Œé–‹ç™ºç’°å¢ƒã¨ã—ã¦IntelliJã‚’ä½¿ã£ã¦ã„ãŸã®ã§ã™ãŒï¼Œæœ€è¿‘ã¯VSCodeã®äººæ°—ãŒé«˜ãExtensionsã‚‚ä¾¿åˆ©ãªã‚‚ã®ãŒå¤šãã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ï¼Œå€‹äººçš„ãªä½œæ¥­ã‚’ã™ã‚‹æ™‚ã¯VSCodeã‚’ä½¿ã£ã¦ã¿ã‚ˆã†ã¨æ€ã£ã¦ä½¿ã£ã¦ã„ã¾ã™ï¼ ãã‚“ãªä¸­ã§ï¼Œã‚¿ã‚¤ãƒˆãƒ«ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«VSCodeã‹ã‚‰git pushã—ã‚ˆã†ã¨ã—ãŸã‚‰ï¼Œ\u0026lt;ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå\u0026gt;@github.com: Permission denied (publickey).ã¨ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã®ã§ï¼Œãã‚Œã‚’è§£æ¶ˆã—ã¦VSCodeã§git pushã§ãã‚‹ã‚ˆã†ã«ã—ãŸå‚™å¿˜éŒ²ã«ãªã‚Šã¾ã™ï¼\nã‚¨ãƒ©ãƒ¼åŸå› ï¼ˆSSHæ¥ç¶šã‚¨ãƒ©ãƒ¼ï¼‰ ã€ŒPermission denied (publickey)ã€ã¨ã‚ã‚Šï¼ŒGitHubã«SSHæ¥ç¶šã™ã‚‹ãŸã‚ã«ï¼Œå…¬é–‹éµã‚’ç™»éŒ²ã—ã¦ãŠã‹ãªã„ã¨ã„ã‘ãªã„ã®ã§ã™ãŒï¼Œãã‚Œã‚’ã—ã¦ã„ãªã‹ã£ãŸã®ã§ï¼Œã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã¨ã„ã†ã“ã¨ã«ãªã‚Šã¾ã™ï¼\nä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’æ‰“ã¤ã“ã¨ã§æ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nssh -T git@github.com \u0026gt; git@github.com: Permission denied (publickey).  ã§ã¯ã©ã†ã™ã‚Œã°ã„ã„ã‹ã¨ã„ã†ã¨ï¼Œéµã‚’ç”Ÿæˆã—ã¦Githubã«ç™»éŒ²ã™ã‚Œã°ã„ã„ã¨ã„ã†ã“ã¨ã«ãªã‚Šã¾ã™ï¼\nå…¬é–‹éµã¨ç§˜å¯†éµã®ä½œæˆ è©³ç´°ãªä½œæˆæ–¹æ³•ã¯ã“ã¡ã‚‰ã®è¨˜äº‹ãŒå‚è€ƒã«ãªã‚Šã¾ã™ï¼\nç°¡å˜ã«æ‰‹é †ã‚’è¼‰ã›ã¦ãŠãã¾ã™ï¼\ncd ~/.ssh ssh-keygen -t rsa -b 4096 -C \u0026quot;\u0026lt;ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹\u0026gt;\u0026quot; -f github_rsa # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ã„ãã¤ã‹è¨­å®šã—ã¦ï¼Œéµã‚’ç”Ÿæˆ # ä»¥ä¸‹å®Ÿè¡Œçµæœï¼ˆä¸€éƒ¨ãƒã‚¹ã‚¯ã—ã¦ã¾ã™ï¼‰ Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in github_rsa. Your public key has been saved in github_rsa.pub. The key fingerprint is: SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \u0026lt;ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹\u0026gt; The key's randomart image is: +---[RSA 4096]----+ |=== | |.B o . | |o.. . * . o | |. . . B +. oo .o*| | . o * OSo.oooo*+| | . = + = o ..*..| | E . . o . . ..| | . . | | | +----[SHA256]-----+  éµã®ç¨®é¡ã‚’RSAã«ã—ï¼Œéµã®é•·ã•ã‚’4096ã«ã—ã¦ã„ã¾ã™ï¼ãƒ•ã‚¡ã‚¤ãƒ«åã¯github_rsaã¨è¨­å®šã—ã¾ã—ãŸï¼\nGithubã«ç”Ÿæˆã—ãŸå…¬é–‹éµã‚’ç™»éŒ² cd ~/.ssh ssh-add -K github_rsa # ç§˜å¯†éµã‚’ssh-agentãƒ‡ãƒ¼ãƒ¢ãƒ³ã«ç™»éŒ² pbcopy \u0026lt; github_rsa.pub # pbcopyã‚³ãƒãƒ³ãƒ‰ã§å…¬é–‹éµã®ä¸­èº«ã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼  ã“ã®å¾Œã¯ï¼Œã‚³ãƒ”ãƒ¼ã—ãŸå…¬é–‹éµã®ä¸­èº«ã‚’Githubã«ç™»éŒ²ã—ã¾ã™ï¼\nGithubã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‹ã‚‰Settingsã«é€²ã¿ï¼ŒSSH and GPG keysã‚’é¸æŠã—ï¼ŒNew SSH keyã‚’æŠ¼ã—ã¦ï¼Œå…ˆç¨‹ã‚³ãƒ”ãƒ¼ã—ãŸä¸­èº«ã‚’ãƒšãƒ¼ã‚¹ãƒˆã—ï¼Œåå‰ã‚’æ±ºã‚ã¦ä¿å­˜ã—ã¾ã™ï¼\nSSHæ¥ç¶šç¢ºèª ä¿å­˜ãŒå®Œäº†ã—ãŸã‚‰ï¼ŒSSHæ¥ç¶šã§ãã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã«ï¼Œä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’æ‰“ã£ã¦ç¢ºèªã—ã¾ã™ï¼\nssh -T git@github.com \u0026gt;Hi \u0026lt;ãƒ¦ãƒ¼ã‚¶ãƒ¼å\u0026gt;! You've successfully authenticated, but GitHub does not provide shell access.  Remoteè¨­å®šã®ä¸Šæ›¸ã ã“ã“ã¾ã§æ¥ãŸã‚‰å¾Œä¸€æ¯ã§ï¼Œæœ€å¾Œã«remoteã®è¨­å®šã‚’ä¸Šæ›¸ãã—ã¾ã™ï¼ ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã§ãƒªãƒã‚¸ãƒˆãƒªåã‚’æ›¸ã„ã¦ï¼Œå®Ÿè¡Œã™ã‚Œã°OKï¼\ngit remote set-url origin git@github.com:\u0026lt;ãƒ¦ãƒ¼ã‚¶ãƒ¼å\u0026gt;/\u0026lt;ãƒªãƒã‚¸ãƒˆãƒªå\u0026gt;.git  VSCodeã‹ã‚‰git push ä»Šã¾ã§ã®è¨­å®šãŒå®Œäº†ã—ã¦ã„ã‚Œã°ï¼Œä¸Šè¨˜ç”»åƒã®æ‰‹é †ã§VSCodeã®ç”»é¢ã‹ã‚‰ç°¡å˜ã«gitã«commitã‚„pushãªã©ã®æ“ä½œã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ï¼\nã•ã„ã”ã« ã¾ã ã¾ã VSCodeåˆå¿ƒè€…ãªã®ã§ï¼Œä½¿ã„ã‚„ã™ã„Extensionsã‚’å–ã‚Šå…¥ã‚Œã¦é–‹ç™ºç’°å¢ƒã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼\nå‚è€ƒ  åˆã‚ã¦ã®gitã¯5ã‚¹ãƒ†ãƒƒãƒ—ã§å®Œäº† GitHubã§sshæ¥ç¶šã™ã‚‹æ‰‹é †~å…¬é–‹éµãƒ»ç§˜å¯†éµã®ç”Ÿæˆã‹ã‚‰~  ","date":"2021-03-26","permalink":"https://masatakashiwagi.github.io/portfolio/post/vscode_git_connect/","tags":["Dev"],"title":"VSCodeã¨gitã‚’é€£æºã—ã¦pushã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã¾ã§"},{"content":"ã¯ã˜ã‚ã« Pytorchã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ã„ãŸéš›ã«ï¼Œã€ŒRuntimeError: CUDA error: device-side assert triggeredã€ãŒç™ºç”Ÿã—ï¼ŒåŸå› ãŒã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã®ã§ï¼Œèª¿ã¹ãŸã“ã¨ã‚’ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ï¼\nã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã®åŸå›  èª¿ã¹ã¦ã¿ã‚‹ã¨ï¼ŒåŸå› ã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ï¼\n ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®VersionãŒé•ã† ãƒ©ãƒ™ãƒ«/ã‚¯ãƒ©ã‚¹ã®æ•°ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥å‡ºåŠ›ã®shapeãŒç•°ãªã‚‹ Lossé–¢æ•°ã®å…¥åŠ›ãŒæ­£ç¢ºã§ãªã„  ãªã©ãªã©\u0026hellip;\nã‚ˆãã‚ã‚‹ã®ãŒï¼Œä¸‹2ã¤ã‹ãªã¨æ€ã„ã¾ã™ï¼\nãƒ©ãƒ™ãƒ«/ã‚¯ãƒ©ã‚¹ã®æ•°ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥å‡ºåŠ›ã®shapeãŒç•°ãªã‚‹ æƒ³å®šã—ã¦ã„ã‚‹ãƒ©ãƒ™ãƒ«ã‚‚ã—ãã¯ã‚¯ãƒ©ã‚¹æ•°ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ã®ã‚¯ãƒ©ã‚¹æ•°ãŒç•°ãªã‚‹å ´åˆï¼Œã“ã®å ´åˆã¯FCå±¤ã®æœ€å¾Œã«nn.Linear(input, num_class)ã‚’å…¥ã‚Œã¦èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\nLossé–¢æ•°ã®å…¥åŠ›ãŒæ­£ç¢ºã§ãªã„ åƒ•ãŒé­é‡ã—ãŸã®ã¯ã“ã¡ã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãªã‚Šã¾ã™ï¼\nä¾‹ãˆã°ï¼ŒBCELossã‚’è€ƒãˆãŸå ´åˆï¼Œè¨ˆç®—ã™ã‚‹ãŸã‚ã«ã¯å€¤ã¨ã—ã¦ã¯0~1ã‚’å–ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ãã®ãŸã‚æ™®é€šã¯æœ€çµ‚å‡ºåŠ›ã«Sigmoidé–¢æ•° or Softmaxé–¢æ•°ã‚’å…¥ã‚Œã‚‹ã‹ã¨æ€ã„ã¾ã™ï¼\nãã‚Œä»¥å¤–ã«ã‚‚Lossã®è¨­è¨ˆã§ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦ãŠãã¨è‰¯ã„ã‹ã¨æ€ã„ã¾ã™ï¼\nclass BCELoss(nn.Module): def __init__(self): super().__init__() self.bce = nn.BCELoss() def forward(self, input, target): input = torch.where(torch.isnan(input), torch.zeros_like(input), input) input = torch.where(torch.isinf(input), torch.zeros_like(input), input) input = torch.where(input\u0026gt;1, torch.ones_like(input), input) # 1ã‚’è¶…ãˆã‚‹å ´åˆã«ã¯1ã«ã™ã‚‹ target = target.float() return self.bce(input, target)  ä»–ã®è§£æ±ºæ–¹æ³• ä»–ã«ã‚‚èª¿ã¹ã¦ã„ã‚‹ã¨è§£æ±ºæ–¹æ³•ã¨ã—ã¦CUDAã®è¨­å®šã‚’ä»¥ä¸‹ã«ã™ã‚‹ã¨è‰¯ã„ãªã©ã‚‚ã‚ã‚Šã¾ã—ãŸãŒï¼Œè§£æ±ºã™ã‚‹ã‹ã©ã†ã‹ã¯ã‚ˆãã‚ã‹ã‚‰ãªã„ã§ã™ï¼\nCUDA_LAUNCH_BLOCKING=1  ãŠã‚ã‚Šã« ä»Šå›ã¯ï¼ŒPytorchã§ã®ãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ã«ã¤ã„ã¦æ•´ç†ã—ã¾ã—ãŸï¼Œãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«ã¯ãƒ¢ãƒ‡ãƒ«ã®In/Outã‚„Lossé–¢æ•°ã®å®šç¾©ã‚’ãã¡ã‚“ã¨ç†è§£ã—æŠŠæ¡ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã¨æ”¹ã‚ã¦æ„Ÿã˜ã¾ã—ãŸï¼åŒæ§˜ã®ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸå ´åˆã«ã¯ï¼Œã“ã®è¾ºã‚Šã‚’ã¾ãšã¯èª¿ã¹ã¦ã¿ã‚‹ã®ãŒè‰¯ã•ãã†ã§ã™ï¼\nå‚è€ƒ  CUDA error 59: Device-side assert triggered  ","date":"2021-02-01","permalink":"https://masatakashiwagi.github.io/portfolio/post/cuda_error_device-side_assert_triggered/","tags":["Dev"],"title":"RuntimeError: CUDA error: Device-side assert triggeredã®è§£æ±ºæ–¹æ³•"},{"content":"Kaggle-MoAã‚³ãƒ³ãƒšã«Team 90\u0026rsquo;sã§åˆå‚åŠ  ã“ã®ãƒ–ãƒ­ã‚°ã¯2020/9/4~12/1ã¾ã§é–‹å‚¬ã—ã¦ã„ãŸMoAã‚³ãƒ³ãƒšã§ã®å–ã‚Šçµ„ã¿ã‚’ç´¹ä»‹ã™ã‚‹å†…å®¹ã§ã™ï¼ ï¼ˆã‚³ãƒ³ãƒšã®è©³ç´°ãªå†…å®¹ã«ã¤ã„ã¦ã¯å‰²æ„›ã—ã¾ã™ï¼‰\nä»Šå›ã®ã‚³ãƒ³ãƒšã§ã¯ï¼ŒåŒä¸–ä»£ã®ãƒ¡ãƒ³ãƒãƒ¼ã§ãƒãƒ¼ãƒ ã‚’çµ„ã‚“ã§å–ã‚Šçµ„ã¿ã¾ã—ãŸï¼\nãƒãƒ¼ãƒ çµæˆã®çµŒç·¯ã¯ï¼ŒTwitterã§ãŠäº’ã„ãŒ90å¹´ç”Ÿã¾ã‚Œã¨ã„ã†ã“ã¨ã‚’çŸ¥ã£ã¦ï¼ŒåŒä¸–ä»£ã§Kaggleãƒãƒ¼ãƒ çµ„ã‚“ã§æˆ¦ã„ãŸã„ã­ãƒ¼ã¨ã„ã†æ„Ÿã˜ã ã£ãŸã¨æ€ã„ã¾ã™ï¼ ãã‚ŒãŒå°‘ã—å‰ã®ã“ã¨ã§å½“æ™‚å–ã‚Šçµ„ã‚ã‚‹è‰¯ã„æ„Ÿã˜ã®ã‚³ãƒ³ãƒšãŒãªã‹ã£ãŸã®ã§ã™ãŒï¼Œä»Šå›ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒšã§å–ã‚Šçµ„ã‚ãã†ã¨ã„ã†ã“ã¨ã§å§‹ã¾ã‚Šã¾ã—ãŸï¼ ãƒãƒ¼ãƒ ã§ã®å–ã‚Šçµ„ã¿ã¯ã¨ã«ã‹ãå­¦ã³ãŒå¤šãï¼Œçµ‚ç›¤ã¾ã§ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ã¤ã“ã¨ãŒã§ããŸã®ãŒå¤§ãã‹ã£ãŸã§ã™ï¼\nã¾ãŸï¼Œè­°è«–ã™ã‚‹ã“ã¨ã§ç†è§£ãªã©ã‚‚æ·±ã¾ã£ã¦ã„ãã®ã§ï¼Œã‚³ãƒ³ãƒšã‚’é€šã—ã¦ã‚ˆã‚Šæˆé•·ã§ããŸã‚“ã˜ã‚ƒãªã„ã‹ãªã¨æ€ã„ã¾ã™ï¼\nä»Šå›ã®åƒ•ãŸã¡ã®ãƒãƒ¼ãƒ ã§ã®å–ã‚Šçµ„ã¿æ–¹ã‚’ç´¹ä»‹ã™ã‚‹ã¨\n1. æƒ…å ±ã¯Slackã§å…±æœ‰ 2. åˆ†ææ–¹é‡ã‚„å®Ÿé¨“çµæœã¯Githubã®issueã§ç®¡ç† 3. æ¯é€±æœ«ã«2æ™‚é–“ç¨‹åº¦ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³\nã¨ã„ã£ãŸæ„Ÿã˜ã§ã™ï¼\n3ç•ªç›®ã®é€±æœ«ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã¯å¼·åˆ¶ã§ã¯ãªãï¼Œå‚åŠ å¯èƒ½ãªäººãŒå‚åŠ ã™ã‚‹å½¢å¼ã§é‹ç”¨ã—ã¦ã¾ã—ãŸï¼ ï¼ˆã¨è¨€ã„ã¤ã¤ã‚‚ã¿ã‚“ãªçœŸé¢ç›®ã«æ¯å›å‚åŠ ã—ã¦ã¾ã—ãŸç¬‘ï¼‰ ä»Šå›ã¯ãƒãƒ¼ãƒ ã§ã®å–ã‚Šçµ„ã¿æ–¹é‡ã®å…·ä½“çš„ãªå†…å®¹ã«ã¤ã„ã¦å°‘ã—ã ã‘æ˜ã‚Šä¸‹ã’ã¾ã™ï¼\n1. æƒ…å ±ã¯Slackã§å…±æœ‰ Slackã‚’ã©ã†ã‚†ã†æ„Ÿã˜ã§æ´»ç”¨ã—ã¦ã„ãŸã®ã‹ã¨ã„ã†ã¨ï¼Œ\nã‚³ãƒ³ãƒšã®Discussionã‚„Notebookã®å†…å®¹ã«ã¤ã„ã¦ç–‘å•ç‚¹ãªã©ã‚’è©±ã—åˆã£ãŸã‚Šï¼Œãã‚Œä»¥å¤–ã«ã‚‚é€²ã‚æ–¹ã®ç›¸è«‡ã‚„é›‘è«‡ãªã©ã‚’åŸºæœ¬çš„ã«è¡Œã£ã¦ã„ã¾ã—ãŸï¼ ã‚ã¨ã¯submitã™ã‚‹æ™‚ã¯ä¸€è¨€å£°ã‚’ã‹ã‘ã‚‹ãªã©ã®submitç®¡ç†ã‚‚ã—ã¦ã„ã¾ã—ãŸï¼\nã“ã†ã‚†ã†ã®ãŒã‚ã‚Œã°è‰¯ã‹ã£ãŸãªãƒ¼ã¨ã„ã†ã¨ã“ã‚ã§ã¯ï¼Œæ–°ç€ã®Discussionã‚„Notebookã‚’Kaggleã‹ã‚‰é€£æºã—ã¦é€šçŸ¥ã™ã‚‹ä»•çµ„ã¿ã‚’ç”¨æ„ã—ã¦ãŠã‘ã‚Œã°å°šè‰¯ã‹ã£ãŸã®ã‹ãªã¨æ€ã„ã¾ã—ãŸï¼\n2. åˆ†ææ–¹é‡ã‚„å®Ÿé¨“çµæœã¯Githubã®issueã§ç®¡ç† Githubã‚’ã©ã†ã‚†ã†æ„Ÿã˜ã§æ´»ç”¨ã—ã¦ã„ãŸã®ã‹ã¨ã„ã†ã¨ï¼Œ\nåˆ†æã§ã®å®Ÿé¨“æ¯ã«1ã¤ã®issueã‚’ç«‹ã¦ã¦ï¼Œãã“ã§ã©ã†ã‚†ã†å®Ÿé¨“ã‚’ã—ãŸã®ã‹submitã—ãŸçµæœã®ã‚¹ã‚³ã‚¢ãŒã©ã†ã ã£ãŸã®ã‹ãªã©ã‚’è¨˜éŒ²ã¨ã—ã¦æ®‹ã—ã¦ã¾ã—ãŸï¼ ã¾ãŸï¼Œå…±é€šã§ä½¿ãˆã‚‹ç‰¹å¾´é‡ç”Ÿæˆã®ã‚³ãƒ¼ãƒ‰ã ã£ãŸã‚Šï¼ŒCVã®åˆ‡ã‚Šæ–¹ã®ã‚³ãƒ¼ãƒ‰ãªã©ã®å…±æœ‰ã‚‚è¡Œã£ã¦ã¾ã—ãŸï¼\nãã®ä»–ã«ã¯Discussionã®å†…å®¹ã‚’æ•´ç†ã—ãŸã‚Šï¼Œæƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹ãŸã‚ã«æ´»ç”¨ã—ãŸã‚Šã—ã¦ã„ã¾ã—ãŸï¼\n3. æ¯é€±æœ«ã«2æ™‚é–“ç¨‹åº¦ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ é€±æœ«ã«Google meetã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã§ã—ã¦ã„ã¦ï¼Œãã“ã§ä½•ã‚’ã—ã¦ã„ãŸã‹ã¨ã„ã†ã¨ï¼Œ\nåŸºæœ¬çš„ã«ã¯ï¼Œä»Šé€±ä½•ã‚’ã—ãŸã®ã‹ã‚’å„ã€…å…±æœ‰ã—ãŸã‚Šï¼Œã‚ã‹ã‚‰ãªã„éƒ¨åˆ†ã‚’è©±ã—åˆã£ã¦ã©ã†ã‚†ã†ãµã†ã«æ¬¡é€²ã‚ã¦è¡Œãã‹ãªã©ã‚’ãƒãƒ¼ãƒ ã§è€ƒãˆã¦ã„ã¾ã—ãŸï¼ ã‚ã¨ã¯ï¼Œæ¬¡ã®é€±ã§ã©ã†ã‚†ã†ã“ã¨ã‚’ã™ã‚‹ã‹ã®æ–¹å‘æ€§ã‚’æ±ºã‚ã¦çµ‚ã‚ã‚‹æ„Ÿã˜ã§ã—ãŸï¼\nã‚‚ã¡ã‚ã‚“é›‘è«‡ã‚„ä»•äº‹ã§ã®è‹¦åŠ´ã‚’åŠ´ã£ãŸã‚Šã‚‚ã—ã¦ã„ã¾ã—ãŸç¬‘\næœ€çµ‚é †ä½ æœ€çµ‚é †ä½ã¯4373ãƒãƒ¼ãƒ ä¸­34ä½ã®éŠ€ãƒ¡ãƒ€ãƒ«ã§ã€é‡‘ãƒ¡ãƒ€ãƒ«ã¾ã§ã‚ã¨ã‚‚ã†å°‘ã—ã®ã¨ã“ã‚ã¾ã§è¡Œã£ãŸã®ã§ï¼Œã¨ã¦ã‚‚æ‚”ã—ã„çµæœã¨ãªã‚Šã¾ã—ãŸï¼\nå€‹äººçš„ã«ã¯Inferenceã®å‡¦ç†ãŒã‚¨ãƒ©ãƒ¼ã§é€šã‚‰ãªã„çŠ¶æ³ã«æœ€å¾Œã®3æ—¥ãã‚‰ã„ã§ãªã£ã¦æ³£ããã†ã«ãªã‚Šã¾ã—ãŸï¼ ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã«ã¯weight0ã®çŠ¶æ…‹ã§éå¸¸ã«ç”³ã—è¨³ãªã‹ã£ãŸãªã¨æ€ã£ã¦ã¾ã™æ³£\nå­¦ç¿’æ™‚ã«å›ã—ã¦ã„ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ï¼Œã‚¹ã‚³ã‚¢ãŒãƒãƒ¼ãƒ å†…ã§ä½œã£ãŸãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã‚‚ä¸Šä½5ã¤ä»¥å†…ã«å…¥ã£ã¦ã„ãŸã®ã§ï¼Œã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ™‚ã«ã¯åŠ¹ã„ã¦ãŸã ã‚ã†ãªã¨æ€ã†ã¨å°šæ›´ã§ã™ï¼ å€‹äººçš„ãªæˆé•·ã¨ã—ã¦ã¯ï¼Œãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦NeuralNetãŒæœ‰åŠ¹ã«ä½œç”¨ã™ã‚‹å ´é¢ã«ã¤ã„ã¦å¤šå°‘ç†è§£ãŒæ·±ã¾ã£ãŸã¨æ„Ÿã˜ã¦ã„ã¾ã™ï¼\nä»Šå›ã®MoAã§ã¯ï¼Œãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã®äºˆæ¸¬ã ã£ãŸã®ã§ï¼Œä¸€åº¦ã«å¤§é‡ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹å ´åˆã«ã¯NNãŒæœ‰åŠ¹ã§ã‹ã¤GBDTç³»ã¨æ¯”è¼ƒã—ã¦è¨ˆç®—é€Ÿåº¦ã‚‚é€Ÿã„ã‚“ã ãªã¨æ„Ÿã˜ã¾ã—ãŸï¼\nã¾ãŸï¼Œç‰¹å¾´é‡çš„ã«ã‚‚äº¤äº’ä½œç”¨çš„ãªéƒ¨åˆ†ã¯NNå†…éƒ¨ã®ä¸­é–“å±¤ã®çµ„ã¿æ–¹ãªã©ã§å®Ÿç¾ã§ãã‚‹ã®ã§ï¼ŒGBDTç³»ã¿ãŸãå¤§é‡ã«ç‰¹å¾´é‡ã‚’ç”¨æ„ã—ãªãã¦ã‚‚å¯¾å‡¦ã§ãã‚‹ã®ãŒå¤§ãã„ã®ã‹ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼ï¼ˆä»Šå›ã®ã‚±ãƒ¼ã‚¹ã ã¨GBDTã§å¤§é‡ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã¨ãªã‚‹ã¨é€Ÿåº¦çš„ãªéƒ¨åˆ†ã§ç‰¹å¾´é‡ãŒè†¨å¤§ã«ãªã‚‹ã¨ã‹ãªã‚Šå³ã—ã„æ„Ÿã˜ã§ã—ãŸï¼‰\nã‚ã¨ã¯ï¼ŒNNã®å®Ÿè£…ã‚’Pytorchã§è¡Œã£ãŸã“ã¨ã‚‚ã‚ã‚Šï¼ŒPytorchã®æ‰±ã„æ–¹ãŒã‚ã‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã¯å¤§ãã„ã¨æ€ã£ã¦ã„ã¾ã™ï¼ï¼ˆä»•äº‹ã§ã¯Tensorflowã ã£ãŸã‚Šã™ã‚‹ã®ã§\u0026hellip;ï¼‰\nPytorchã§ã®å®Ÿè£…ã«é–¢ã—ã¦ã¯ã‚‚ã£ã¨é€²ã‚ã¦è¡ŒããŸã„ã®ã¨ã‚³ãƒ¼ãƒ‰ã®æ•´ç†ã‚‚åˆã‚ã›ã¦ã—ã¦è¡ŒããŸã„ã®ã§ï¼Œæ¬¡ã«å‚åŠ äºˆå®šã®ã‚³ãƒ³ãƒšã§ã¯ãã®è¾ºã‚Šã‚‚æ„è­˜ã—ã¦æŒ‘ã‚ãŸã‚‰ãªãƒ¼ã¨æ€ã„ã¾ã™ï¼\n","date":"2020-12-11","permalink":"https://masatakashiwagi.github.io/portfolio/post/kaggle-moa/","tags":["Kaggle"],"title":"Kaggle-MoAã®æŒ¯ã‚Šè¿”ã‚Š"},{"content":"åˆæœŸåŒ–ã—ãŸãƒªã‚¹ãƒˆã®æ›´æ–°å‡¦ç†ã§ãƒãƒã£ã¦ã—ã¾ã£ãŸ ä»Šå›ã¯ï¼ŒåˆæœŸåŒ–ã—ãŸãƒªã‚¹ãƒˆã‚’æ›´æ–°ã—ãŸéš›ã«ãƒãƒã£ã¦ã—ã¾ã£ãŸå¤±æ•—ãŒã‚ã‚‹ã®ã§ï¼Œå‚™å¿˜éŒ²ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ï¼ è©³ã—ã„å†…å®¹ã¯å‚è€ƒã‚µã‚¤ãƒˆã«è¼‰ã£ã¦ã„ã¾ã™ï¼ï¼ˆã‹ãªã‚Šã‚ã‹ã‚Šã‚„ã™ã„ã§ã™ï¼ï¼‰\npythonã§æ±ºã¾ã£ãŸå½¢ã®ãƒªã‚¹ãƒˆã‚’äºˆã‚ä½œæˆã—ã¦ãŠããŸã„å ´åˆã«ï¼Œä»¥ä¸‹ã®ã‚ˆã†ã«ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã¨æ€ã„ã¾ã™ï¼\nshape you want: [[0, 0], [0, 0], [0, 0]] # è¦ç´ ãŒ2ã¤ã‚ã‚‹ãƒªã‚¹ãƒˆãŒ3ã¤ \u0026gt;\u0026gt;\u0026gt; list1 = [[0] * 2] * 3 \u0026gt;\u0026gt;\u0026gt; list1 [[0, 0], [0, 0], [0, 0]]  ãã—ã¦ï¼Œä¸Šè¨˜ãƒªã‚¹ãƒˆã‚’ä½•ã‹ã—ã‚‰ã®å€¤ã§æ›´æ–°ã—ãŸã„å ´åˆã‚’è€ƒãˆã¾ã™ï¼ ä»Šå›ã ã¨ï¼Œ[0][0]ã®è¦ç´ ã‚’æ›´æ–°ã™ã‚‹ã¨ã—ã¾ã™ï¼\n\u0026gt;\u0026gt;\u0026gt; list1[0][0] = 3.5 \u0026gt;\u0026gt;\u0026gt; list1 [[3.5, 0], [3.5, 0], [3.5, 0]]  çµæœã¯ï¼Œå„ãƒªã‚¹ãƒˆã®0ç•ªç›®ã®è¦ç´ ãŒå…¨ã¦æ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ï¼ ã“ã®åŸå› ã¯ï¼Œlist1 = [[0] * 2] * 3ã¨æ›¸ãã¨ï¼Œè¦ç´ ã®ãƒªã‚¹ãƒˆãŒå…¨ã¦åŒã˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãªã£ã¦ã—ã¾ã„ï¼Œã©ã“ã‹ã®è¦ç´ ã‚’å¤‰æ›´ã™ã‚‹ã¨å…¨ã¦å¤‰ã‚ã£ã¦ã—ã¾ã†ã‹ã‚‰ã§ã™ï¼\nå¯¾å‡¦æ³• ä¸Šè¨˜ã®çµæœã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã¯ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã‚’ä½¿ã†ã¨è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ å…ˆç¨‹ã®ä¾‹ã®å ´åˆï¼Œä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãã¨ã„ã„ã§ã™ï¼\n\u0026gt;\u0026gt;\u0026gt; list2 = [[0] * 2 for i in range(3)] \u0026gt;\u0026gt;\u0026gt; list2 [[0, 0], [0, 0], [0, 0]]  å†…åŒ…è¡¨è¨˜ã‚’ä½¿ã†ã¨ï¼Œãƒªã‚¹ãƒˆã¯ãã‚Œãã‚Œç•°ãªã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ï¼ ã§ã™ã®ã§ï¼Œ[0][0]ã®è¦ç´ ã‚’æ›´æ–°ã™ã‚‹ã¨ï¼Œæ„å›³ã—ãŸéƒ¨åˆ†ã ã‘ãŒæ›´æ–°ã•ã‚Œå•é¡Œã‚ã‚Šã¾ã›ã‚“ï¼\n\u0026gt;\u0026gt;\u0026gt; list2[0][0] = 3.5 \u0026gt;\u0026gt;\u0026gt; list2 [[3.5, 0], [0, 0], [0, 0]]  ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹éš›ã¯ã“ã‚Œã‚‰ã«æ³¨æ„ã—ã¦ãŠã‹ãªã„ã¨ï¼Œæœ¬æ¥ã®æ„å›³ã¨ã¯é•ã†å‹•ãã«ãªã£ã¦ã—ã¾ã„ã¾ã™ï¼\nã“ã†ã‚†ã†ãƒŸã‚¹ã‚’æ°—ã«ã—ãŸããªã„å ´åˆã«ã¯ï¼Œnumpyã®arrayã§ä½œã‚ŠãŸã„shapeã‚’ä½œæˆã—ï¼Œãã®å¾Œã«ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚Œã°è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ï¼\n\u0026gt;\u0026gt;\u0026gt; np.zeros((2, 3)).tolist() # 0ã§åˆæœŸåŒ– [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]] # 0ä»¥å¤–ã®å ´åˆ np.ones((2, 3)).tolist() # 1ã§åˆæœŸåŒ– np.full((2, 3), 5).tolist() # ä»»æ„ã®å€¤ã§åˆæœŸåŒ–  å‚è€ƒ  Pythonã®ãƒªã‚¹ãƒˆï¼ˆé…åˆ—ï¼‰ã‚’ä»»æ„ã®å€¤ãƒ»è¦ç´ æ•°ã§åˆæœŸåŒ–  ","date":"2020-09-12","permalink":"https://masatakashiwagi.github.io/portfolio/post/list-objects/","tags":["Dev"],"title":"ãƒã‚¹ãƒˆã—ãŸãƒªã‚¹ãƒˆã®æ›´æ–°å‡¦ç†"},{"content":"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ ã“ã¡ã‚‰ã®Qiitaã®è¨˜äº‹ã§Hugoã‚’ä½¿ã£ã¦ç°¡å˜ã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ä½œæˆã§ãã‚‹ã¨ã„ã†ã®ã‚’è¦‹ã‹ã‘ãŸã®ã§ï¼Œä»¥å‰ã¾ã§ä½¿ã£ã¦ã„ãŸpersonal pageã‚’ç§»æ¤ã—ã¾ã—ãŸï¼ ç§»æ¤ã—ãŸéš›ã«å°‘ã—è©°ã¾ã£ãŸéƒ¨åˆ†ãŒã‚ã‚‹ã®ã§ï¼ŒTipsã¨ã—ã¦ã“ã®è¨˜äº‹ã§ç´¹ä»‹ã—ã¾ã™ï¼\nã“ã®è¨˜äº‹ã¯ä»¥å‰ã«ä½¿ç”¨ã—ã¦ã„ãŸHugo Themeã®å†…å®¹ã«ãªã‚Šã¾ã™\næœ€åˆã¯Hugo Theme Cactus Plusã¨ã„ã†ãƒ†ãƒ¼ãƒã§ä½œæˆã—ã¦ã„ãŸã®ã§ã™ãŒï¼Œå†åº¦ä½œã‚Šç›´ã—ã¦ã¾ã™ï¼ ï¼ˆå†ä½œæˆã—ãŸç†ç”±ã¯ï¼Œå°‘ã—ã ã‘å‡ã£ãŸãƒ†ãƒ¼ãƒã‚’ä½¿ã£ã¦è¦‹ãŸããªã£ãŸãŸã‚ã§ã™ç¬‘ï¼‰ ä½œã‚Šç›´ã—ãŸãƒ†ãƒ¼ãƒã¯Hugo Future Imperfect Slimã«ãªã‚Šã¾ã™ï¼\nHugoã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚¶ã‚¤ãƒ³ãŒå¤šã„ã®ã§éå¸¸ã«ã‚ªã‚¹ã‚¹ãƒ¡ã§ã™ï¼\nåŸºæœ¬çš„ãªæ§‹ç¯‰æ–¹æ³•ã¯ä¸Šè¨˜Qiitaã®è¨˜äº‹ã«æ²¿ã£ã¦è¡Œã£ã¦ã„ã¾ã™ï¼ åˆ¥é€”è¿½åŠ ã—ãŸè¦ç´ ã¨ã—ã¦ã¯ï¼Œæœ€åˆã«ä½œæˆã—ãŸHugo Theme Cactus Plusã¨ä½œã‚Šç›´ã—ãŸHugo Future Imperfect Slimãã‚Œãã‚Œã‚ã‚Šã¾ã™ã®ã§ï¼Œã“ã®éš›ã©ã¡ã‚‰ã‚‚ç´¹ä»‹ã—ã¾ã™ï¼\n  Hugo Theme Cactus Plus\n ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¿½åŠ è¨­å®š Custom-CSSã®è¨­å®šï¼ˆcustom-cssã®è¨­å®šã¯ç°¡å˜ã«è¨­å®šã§ãã¾ã™ã®ã§ï¼Œä»Šå›ã¯å‰²æ„›ã—ã¾ã™ï¼‰    Hugo Future Imperfect Slim\n faviconã®è¨­å®š github.ioã§ã‚µã‚¤ãƒˆã‚’hostã—ãŸå ´åˆã®pathè¨­å®š    å€‹äººçš„ã«ã¯ï¼Œ1å›ç›®ã«ä½œæˆã—ãŸãƒ†ãƒ¼ãƒã‚ˆã‚Š2å›ç›®ã®æ–¹ãŒç°¡å˜ã§ã—ãŸï¼\nHugo Theme Cactus Plus: ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¿½åŠ è¨­å®š Hugo Theme Cactus Plusã®ãƒ†ãƒ¼ãƒã§ã¯ï¼Œãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§About/Archive/Tagsã®3ã¤ãŒãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¨ã—ã¦å­˜åœ¨ã—ã¦ã„ã¾ã™ï¼ ä»Šå›ã¯ãã“ã«Projectsã‚’æ–°ã—ãè¿½åŠ ã—ã¾ã—ãŸã®ã§ï¼Œãã®æ–¹æ³•ã‚’è¨˜è¼‰ã—ã¾ã™ï¼ å®Ÿæ–½ã™ã‚‹ã“ã¨ã¨ã—ã¦ã¯ï¼Œä»¥ä¸‹ã®4ã‚¹ãƒ†ãƒƒãƒ—ã«ãªã‚Šã¾ã™ï¼\n contenté…ä¸‹ã«projectsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ï¼Œ_index.mdãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹ï¼ è¨˜äº‹ãªã©ã®ãƒšãƒ¼ã‚¸æƒ…å ±ã¯contentã§ç®¡ç†ã—ã¾ã™ï¼  â”œâ”€â”€ content â”‚Â â”œâ”€â”€ about â”‚Â â”œâ”€â”€ posts â”‚Â â””â”€â”€ projects â”‚Â â””â”€â”€ _index.md   themes/layouts/partialsé…ä¸‹ã«ã‚ã‚‹nav.htmlã«Projectsã®ãƒªãƒ³ã‚¯ã‚’è¿½è¨˜ã™ã‚‹ï¼ ã“ã‚Œã¯Tagsãªã©ã®ãƒªãƒ³ã‚¯ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ï¼Œnameã®éƒ¨åˆ†ã¯projectsã«ä¿®æ­£ã™ã‚Œã°å¤§ä¸ˆå¤«ã§ã™ï¼ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã«Projectsã‚’è¡¨ç¤ºã•ã›ã‚‹ãŸã‚ã«ï¼Œã“ã®éƒ¨åˆ†ã‚’ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\n  themes/layouts/sectioné…ä¸‹ã«about.htmlã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ï¼Œprojects.htmlã«renameã™ã‚‹ï¼ ã“ã“ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§ï¼Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼\n  æœ€å¾Œã«ï¼Œã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§hugoã‚’å®Ÿè¡Œã™ã‚‹ï¼ hugoã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ï¼Œå¿…è¦ãªã‚‚ã®ãŒè‡ªå‹•ç”Ÿæˆãƒ»åæ˜ ã•ã‚Œã¾ã™ï¼\n  ä»¥ä¸Šã§ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ ï¼ˆä»–ã®ãƒ†ãƒ¼ãƒã§ã¯ï¼Œã‚‚ã†å°‘ã—ç°¡å˜ã«ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¿½åŠ ãŒå¯èƒ½ãªã‚‚ã®ã‚‚ã‚ã‚Šã¾ã™ï¼‰\nHugo Future Imperfect Slim: faviconã®è¨­å®š faviconã‚’è¨­å®šã™ã‚‹æ–¹æ³•ã¯ï¼Œä¸‹è¨˜ã®3ã‚¹ãƒ†ãƒƒãƒ—ã«ãªã‚Šã¾ã™ï¼\n ã¾ãšï¼Œä¸‹è¨˜ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®config.tomlã®å†…å®¹ã®ã†ã¡ï¼Œfaviconã¨faviconVersionã‚’å¤‰æ›´ã—ã¾ã™ï¼  [params.meta] description = \u0026quot;A theme by HTML5 UP, ported by Julio Pescador. Slimmed and enhanced by Patrick Collins. Multilingual by StatnMap. Powered by Hugo.\u0026quot; author = \u0026quot;HTML5UP and Hugo\u0026quot; favicon = false \u0026lt;-- trueã«å¤‰æ›´ã™ã‚‹ svg = true faviconVersion = \u0026quot;1\u0026quot; \u0026lt;-- 1ã‚’å‰Šé™¤ã™ã‚‹ msColor = \u0026quot;#ffffff\u0026quot; iOSColor = \u0026quot;#ffffff\u0026quot;   config.tomlã‚’ä¿®æ­£ã—ãŸã‚‰ï¼Œstaticé…ä¸‹ã«faviconãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹ï¼\n  static/faviconé…ä¸‹ã«favicon.icoã¨favicon-32x32.pngã‚’é…ç½®ã™ã‚‹ï¼ ãªãœfavicon-32x32ã‹ã¨ã„ã†ã¨ï¼Ÿ\n layouts/partials/meta.htmlã®rel=iconã«ä»¥ä¸‹ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹  favicon-32x32 favicon-16x16 site.webmanifest    ãªã®ã§ï¼Œã“ã‚Œã«åˆã‚ã›ã¦åå‰ã‚’å¤‰æ›´ã™ã‚‹ã‹webmanifestã‚’æ–°ã—ãä½œæˆã—ï¼Œãã®ä¸­ã«è«¸ã€…ã®å†…å®¹ã‚’è¨˜è¼‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼\n  github.ioã§ã‚µã‚¤ãƒˆã‚’hostã—ãŸå ´åˆã®pathè¨­å®š ä»Šå›ä½œæˆã—ãŸã‚µã‚¤ãƒˆã‚’github.ioã§hostã—ãŸå ´åˆã«ç™ºç”Ÿã—ãŸå†…å®¹ã§ã™ï¼ å„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®URLã¨ã—ã¦ï¼Œhttps://\u0026lt;ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå\u0026gt;.github.io/portfolio/home/ãªã©ã¨ãªã£ã¦æ¬²ã—ã„ã®ã§ã™ãŒï¼Œ https://\u0026lt;ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå\u0026gt;.github.io/portfolio/portfolio/home/ã¨portfolioãŒé‡ãªã£ã¦ã—ã¾ã†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼\nä¸Šè¨˜ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹æ–¹æ³•ã®ç´¹ä»‹ã«ãªã‚Šã¾ã™ï¼ config.tomlãƒ•ã‚¡ã‚¤ãƒ«ã«å„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¨­å®šã‚’ã™ã‚‹ç®‡æ‰€ãŒã‚ã‚Šã¾ã™ï¼\n[menu] [[menu.main]] name = \u0026quot;Home\u0026quot; identifier = \u0026quot;home\u0026quot; url = \u0026quot;/\u0026quot; \u0026lt;-- /ã‚’å‰Šé™¤ã™ã‚‹ pre = \u0026quot;\u0026lt;i class='fa fa-home'\u0026gt;\u0026lt;/i\u0026gt;\u0026quot; weight = 1 [[menu.main]] name = \u0026quot;About\u0026quot; identifier = \u0026quot;about\u0026quot; url = \u0026quot;/about/\u0026quot; \u0026lt;-- å…ˆé ­ã®/ã‚’å‰Šé™¤ã™ã‚‹ pre = \u0026quot;\u0026lt;i class='far fa-id-card'\u0026gt;\u0026lt;/i\u0026gt;\u0026quot; weight = 2 [[menu.main]] name = \u0026quot;Blog\u0026quot; identifier = \u0026quot;blog\u0026quot; url = \u0026quot;/blog/\u0026quot; \u0026lt;-- å…ˆé ­ã®/ã‚’å‰Šé™¤ã™ã‚‹ pre = \u0026quot;\u0026lt;i class='far fa-newspaper'\u0026gt;\u0026lt;/i\u0026gt;\u0026quot; weight = 3  urlã®éƒ¨åˆ†ã§å…ˆé ­ã®/ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ï¼Œä¸Šè¨˜å•é¡Œã‚’å›é¿ã™ã‚‹ã“ã¨ã§ãã¾ã™ï¼\n ä»¥ä¸Šã§ä»Šå›ç´¹ä»‹ã™ã‚‹å†…å®¹ã¯çµ‚äº†ã«ãªã‚Šã¾ã™ï¼\nå‚è€ƒã¨ãªã‚‹è¨˜äº‹ãªã©ãŒã‚ã¾ã‚Šãªã‹ã£ãŸã®ã§ï¼Œè©¦è¡ŒéŒ¯èª¤ã—ãªãŒã‚‰è¡Œã„ã¾ã—ãŸï¼\nãã®ãŸã‚ï¼Œã‚‚ã£ã¨ç°¡å˜ã«ã™ã‚‹æ–¹æ³•ãŒä»–ã«ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ã®ã§ï¼Œã‚‚ã—ä»–ã«ã‚ã‚Œã°ï¼ŒTwitterãªã©ã§ã‚³ãƒ¡ãƒ³ãƒˆé ‚ã‘ã‚‹ã¨å¤§å¤‰åŠ©ã‹ã‚Šã¾ã™ï¼\n","date":"2020-07-13","permalink":"https://masatakashiwagi.github.io/portfolio/post/hugo-portfolio/","tags":["Dev"],"title":"Hugoã‚’ä½¿ã£ãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ"},{"content":"ã¯ã˜ã‚ã« Kaggleã‚’å§‹ã‚ã¦åŠå¹´ã»ã©çµŒã¡ï¼Œå€‹äººçš„ã«ã“ã®åŠå¹´ã§å¾—ãŸã‚‚ã®ã‚’æ•´ç†ã™ã‚‹ã¨ã„ã†æ„å‘³ã§ã€Œkaggle ãã®2 Advent Calendar 2019ã€ã®20æ—¥ç›®ã‚’æ‹…å½“ã—ã¾ã™ï¼\nç°¡å˜ãªè‡ªå·±ç´¹ä»‹ã¨ã—ã¦ï¼Œæ™®æ®µã¯éƒ½å†…ã®ãƒ™ãƒ³ãƒãƒ£ãƒ¼ä¼æ¥­ã§ä¸»ã«è£½é€ æ¥­ã®ãŠå®¢ã•ã‚“ã‚’ç›¸æ‰‹ã«ãƒ‡ãƒ¼ã‚¿åˆ†æã®ä»•äº‹ã¨è‡ªç¤¾è£½å“ã®é–‹ç™ºã‚’8:2ãã‚‰ã„ã®å‰²åˆã§æ‹…å½“ã—ã¦ã„ã¾ã™ï¼\nå®Ÿã¯JTCã‹ã‚‰è»¢è·ã—ã¦ä»Šã®ä¼šç¤¾ã¯2ç¤¾ç›®ã§ï¼Œåƒã„ã¦2å¹´å¼±ã«ãªã‚Šã¾ã™ï¼\nã¡ãªã¿ã«å‰è·ã®JTCã§ã¯ï¼Œãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«å°å…¥ãªã©ã®SEçš„ãªã“ã¨ã‚’ã—ã¦ã¾ã—ãŸï¼ãªã®ã§ï¼Œãƒãƒªãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚’ã—ã¦ã„ãŸã‚ã‘ã§ã¯ãªã„ã§ã™ç¬‘\nKaggleã¯è»¢è·ã—ãŸæ™‚ãã‚‰ã„ã‹ã‚‰çŸ¥ã£ã¦ï¼Œã™ãã‚„ã‚Šå§‹ã‚ãŸã„ã¨æ€ã£ã¦ãŸã®ã§ã™ãŒï¼Œè‰²ã€…ã¨ä»•äº‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆå…±ã«ä½™è£•ãŒç„¡ãã¦æº€ã‚’è¾ã—ã¦åŠå¹´ã»ã©å‰ã‹ã‚‰æœ¬æ ¼çš„ã«å‚åŠ ã—å§‹ã‚ã¾ã—ãŸï¼\nKaggleã‚’å§‹ã‚ã¦å¾—ãŸã‚‚ã® ä»Šå›ã¯ãã‚“ãªåŠå¹´ã»ã©å‰ã‹ã‚‰Kaggleã‚’å§‹ã‚ã¦å¾—ãŸã‚‚ã®ã¨ã—ã¦ï¼Œå¤§ãã3ã¤ã‚ã‚Šï¼Œãã‚Œã«ã¤ã„ã¦æ›¸ãã¾ã™ï¼\n ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–¢é€£ã®çŸ¥è­˜ å®Ÿå‹™ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ äººã¨ã®ç¹‹ãŒã‚Š  ãã‚Œãã‚Œç°¡å˜ã§ã™ãŒï¼Œæ›¸ã„ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼\n1. ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–¢é€£ã®çŸ¥è­˜ ã‚ˆãè¨€ã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ãŒï¼ŒKaggleã¯å®ã®å±±ã§ã‚ã‚Šä¸–ç•Œä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãƒ»æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®çŸ¥æµã‚„æƒ…å ±ãŒç‰¹ã«ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã§å…±æœ‰ã•ã‚Œã¦ã„ã‚‹ã®ãŒé­…åŠ›ã®ä¸€ã¤ã§ã™ï¼æ˜ã‚Œã°æ˜ã‚‹ã»ã©è‰²ã€…ã¨å‡ºã¦æ¥ã‚‹ã®ã§ï¼Œã“ã‚Œã‚’æ´»ç”¨ã—ãªã„æ‰‹ã¯ãªã„ãªã¨ã„ã†å°è±¡ã§ã™ï¼\nãã®ä¸­ã§ã‚‚ï¼Œç‰¹ã«å€‹äººçš„ã«å¾—ã¦è‰¯ã‹ã£ãŸçŸ¥è¦‹ã¨ã—ã¦ã¯ä»¥ä¸‹ã®4ã¤ã‹ãªã¨æ€ã„ã¾ã™ï¼\n1ã¤ç›®ã¯ï¼Œ\n ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°  ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«åŸºã¥ãç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã¯ã‚‚ã¡ã‚ã‚“çŸ¥ã£ã¦ã„ã¾ã—ãŸãŒï¼Œãã‚Œã‚’ä½œã‚‹ç™ºæƒ³ã§ã‚ã£ãŸã‚Šçµ„ã¿ç«‹ã¦æ–¹ãŒéå¸¸ã«å‹‰å¼·ã«ãªã£ã¦ã¾ã™ï¼ ã¾ãŸé–¢é€£ã—ã¦ï¼Œã©ã®å˜ä½ã§é›†ç´„ã—ãŸç‰¹å¾´é‡ã‚’ä½œã‚‹ã‹ï¼Œã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚„ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„ï¼Œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ä»•æ–¹ã§ã‚ã£ãŸã‚Šã¨ç‰¹å¾´é‡ã®ä½œã‚Šæ–¹ã¯éå¸¸ã«å‚è€ƒã«ãªã£ã¦ã¾ã™ï¼    2ã¤ç›®ã¯ï¼Œ\n ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆã¯Kaggleã‚’å§‹ã‚ã¦ã‹ã‚‰ç‰¹ã«æ„è­˜ã•ã›ã‚‰ã‚ŒãŸéƒ¨åˆ†ã«ãªã‚Šã¾ã™ï¼å‚è€ƒã«ãªã‚‹æƒ…å ±ã‚’ã„ãã¤ã‹ä¸Šã’ã¦ãŠãã¾ã™[1, 2, 3]ï¼    ã“ã‚Œã‚’æ„è­˜ã—ã¦è‰¯ã‹ã£ãŸã“ã¨ã¨ã—ã¦ã¯\u0026hellip;\n ç‰¹å¾´é‡ã®ç®¡ç†ãŒæ¥½ã«ãªã‚‹ è©¦è¡ŒéŒ¯èª¤ã—ãŸçµæœã‚’ãƒ­ã‚°ã¨ã„ã†å½¢ã§å¾Œã‹ã‚‰ç¢ºèªã§ãã‚‹ çµæœã®å†ç¾æ€§ã‚‚å®¹æ˜“ã«ãªã‚‹ è¨ˆç®—å›ã—ãŸå¾Œã¯å¯ã¦ã‚‰ã‚Œã‚‹ç¬‘  ä»–ã«ã‚‚è‰²ã€…ã¨è‰¯ã„ã“ã¨ã¯ã‚ã‚‹ã®ã§ï¼Œæ˜¯éã‚ªã‚¹ã‚¹ãƒ¡ã—ãŸã„ã§ã™ï¼å¾Œã€…ã®å†åˆ©ç”¨ã®ãŸã‚ã«ã‚‚æ•´ç†ã—ã¦ãŠãã¨ï¼Œä¸€ã‹ã‚‰å…¨ã¦ã‚’ä½œã‚Šå‡ºã•ãªãã¦ã‚‚è‰¯ã„ã®ã§ï¼Œæœ‰ç”¨ã‹ã¨æ€ã„ã¾ã™ï¼\n3ã¤ç›®ã¯ï¼Œ\n ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®é‡è¦æ€§  ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’è€ƒãˆã‚‹ä¸Šã§ã¯å¤§äº‹ãªè¦ç´ ã§ï¼ŒKaggleã§ã¯ç‰¹ã«pubulic LBã§ä¸Šä½ã«å…¥ã£ã¦ã„ã¦ã‚‚ï¼Œãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãã¡ã‚“ã¨ã—ã¦ã„ãªã„ã¨private LBã§å¤§ããshake downã—ã¦ã—ã¾ã†çµæœã«ãªã‚‹ã“ã¨ãŒã‚ˆãï¼Ÿã‚ã‚‹ã®ã‹ãªã¨ã„ã†å°è±¡ã§ã™ï¼  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®çµæœãŒè‰¯ãã¦ã‚‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å…¨ç„¶è‰¯ããªã„ã¨ãªã‚‹ã¨ä½¿ã„ç‰©ã«ãªã‚‰ãªã„ã®ã§ã€ã“ã®è¾ºã‚Šã¯å®Ÿå‹™ã§ã‚‚æ´»ãã¦ãã‚‹éƒ¨åˆ†ã«ãªã‚Šã¾ã™ï¼é‹ç”¨æ®µéšã§å…¨ç„¶ä½¿ãˆãªã„ãƒ¢ãƒ‡ãƒ«ãŒå‡ºæ¥ä¸ŠãŒã‚‹ã®ã‚’å›é¿ã§ãã‚‹æ–¹æ³•ã®1ã¤ï¼      4ã¤ç›®ã¯ï¼Œ\n NNã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ä½¿ã†æ–¹æ³•  Neural Networkã¯ç”»åƒèªè­˜ã®é ˜åŸŸã§ä½¿ã‚ã‚Œã¦ã¾ã™ãŒï¼Œãã‚Œã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ä½¿ã†æ–¹æ³•ãŒKaggleã§ã¯è¦‹ã‹ã‘ã¾ã™ï¼  ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ãƒ³ãƒšã§ã¯ï¼ŒGBDTç³»ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ–¹ãŒã¾ã ã¾ã ç²¾åº¦çš„ã«ã¯è‰¯ã„ã§ã™ãŒï¼Œãƒ¢ãƒ‡ãƒ«ã®å¤šæ§˜æ€§ã‚„ç‰¹å¾´é‡æŠ½å‡ºã®è‡ªå‹•åŒ–çš„ãªéƒ¨åˆ†ã§NNãƒ¢ãƒ‡ãƒ«ã‚‚ååˆ†ã«æ´»ç”¨ã§ãã‚‹ã¨æ€ã£ã¦ã¾ã™ï¼   ã“ã®è¾ºã‚Šã¯ã‚‚ã£ã¨kernelãªã©ã§ç†è§£ã—ã¦è‡ªåˆ†ã®æ­¦å™¨ã«ã—ã¦ã„ããŸã„ãªã¨ã„ã†æ„Ÿã˜ã§ã™ï¼ãŸã ï¼Œå‰ã¾ã§ã¯é¸æŠè‚¢ã«ã‚‚ãªã‹ã£ãŸæ°—ãŒã™ã‚‹ã®ã§ï¼æ§˜ã€…ãªæ‰‹æ³•ã‚’è¦‹ãŸçµæœå¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ã‹ãªã¨ï¼    2. å®Ÿå‹™ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ Kaggleã§å®Ÿæ–½ã™ã‚‹å†…å®¹ã¨å®Ÿå‹™ã§ã®å†…å®¹ãŒå¿…ãšã—ã‚‚ç›´çµã™ã‚‹ã‚ã‘ã§ã¯ãªã„ã§ã™ãŒï¼Œåˆ†æã‚¹ã‚­ãƒ«ã®å‘ä¸Šã¯å®Ÿå‹™ã§ã‚‚å¤§ããæ´»ãã¦ã¾ã™ï¼\nä¾‹ãˆã°ï¼Œå®Ÿå‹™ã§ãƒ‡ãƒ¼ã‚¿å—é ˜å¾Œï¼ŒEDAã‚’é€²ã‚ã‚‹ä¸­ã§ãƒ‡ãƒ¼ã‚¿ã®å‹˜æ‰€ã‚’æ´ã‚€ã®ãŒä»¥å‰ã‚ˆã‚Šæ—©ããªã£ãŸã®ã¨ï¼Œä½•ã‚’ã©ã†ã™ã‚Œã°è‰¯ã„ã‹ã‚’æ´ã‚€ã®ãŒä»¥å‰ã‚ˆã‚Šã‚¹ãƒ”ãƒ¼ãƒ‰ãŒä¸ŠãŒã£ãŸã¨æ„Ÿã˜ã¦ã¾ã™ï¼ãã‚Œã«ã‚ˆã£ã¦ï¼Œæ¡ˆä»¶ã‚’é€²ã‚ã¦ã„ãã‚¹ãƒ”ãƒ¼ãƒ‰ãŒä¸ŠãŒã£ãŸã®ã§ï¼Œè‰²ã€…ã¨è©¦è¡ŒéŒ¯èª¤ã§ãã‚‹æ™‚é–“ã‚’ç¢ºä¿ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¨æ€ã„ã¾ã™ï¼\nã¾ãŸï¼ŒKaggleã§æœ‰åŠ¹ãªæ‰‹æ³•ã‚’è£½å“ã¸ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã™ã‚‹ã“ã¨ã‚‚é€²ã‚ã¦ã„ã‚‹ã®ã§ï¼Œè‡ªåˆ†è‡ªèº«ã ã‘ã§ãªãä¼šç¤¾ã¸ã‚‚é‚„å…ƒã§ãã¤ã¤ã‚ã‚‹ã®ã‹ãªã¨ã„ã†æ„Ÿã˜ã§ã™ï¼\nä¸€æ–¹ã§KaggleãŒæ¥½ã—ã™ãã¦ï¼Œä»•äº‹ä¸­ã§ã‚‚ã‚³ãƒ³ãƒšã®ã“ã¨ãŒæ°—ã«ãªã£ã¦æ‰‹ã‚’å‹•ã‹ã—ãŸããªã£ãŸã‚Šï¼Œä¼‘æ—¥ã ã„ãŸã„è²»ã‚„ã—ã¦ã‚‹ã®ã§å‡ºä¸ç²¾ã«ãªã£ãŸã‚Šã—ã¦ã¾ã™ç¬‘\nTwitterã§ã‚‚æ›¸ãã¾ã—ãŸãŒï¼Œè‰¯ãã‚‚æ‚ªãã‚‚ä¸–ç•Œä¸­ã®äººãŸã¡ã¨ç«¶ã„åˆã£ã¦è©•ä¾¡ã•ã‚Œã‚‹ã®ã§ï¼Œè² ã‘ãŸããªã„ç²¾ç¥ã¯ä¼šç¤¾ã§ã‚‚ç™ºæ®ã•ã‚Œã¦ã¾ã™ï¼\näººã¨ã®ç¹‹ãŒã‚Š Kaggleã‚’å§‹ã‚ã¦ã‹ã‚‰ï¼Œã‚‚ãã‚‚ãä¼šã‚„å‹‰å¼·ä¼šã«å‚åŠ ã™ã‚‹é »åº¦ãŒå¢—ãˆãŸã‹ãªã¨æ„Ÿã˜ã¦ã¾ã™ï¼å¤§ä½“æœ€å¾Œã«ã¯æ‡‡è¦ªä¼šãŒã‚ã‚‹ã®ã§ï¼Œã‚³ãƒ³ãƒšã®è©±ã‚„ä»•äº‹ã®è©±ã§ç››ã‚Šä¸ŠãŒã£ã¦è‰²ã€…ã¨æƒ…å ±äº¤æ›ãŒå‡ºæ¥ã¦ã„ã¦æ¥½ã—ã„é™ã‚Šã§ã™ï¼\nã‚ã¨ã¯ï¼Œã‚³ãƒ³ãƒšçµ‚äº†å¾Œã®åçœä¼šã«å‚åŠ ã™ã‚‹ã“ã¨ã§ã‚³ãƒ³ãƒšã§ã®è‹¦ã—ã¿ãªã©ã‚’å…±æœ‰ã§ãã‚‹ã®ã‚‚è‰¯ã„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ã ãªã¨æ€ã„ã¾ã™ï¼ãã†ã„ã£ãŸå ´ã§ç¤¾å†…ä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãƒ»æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®æ–¹ã€…ã¨ãŠè©±ã—ã§ãã‚‹ã®ã¯éå¸¸ã«è‰¯ã„åˆºæ¿€ã«ãªã‚Šã¾ã™ï¼è‡ªåˆ†ãŒçŸ¥ã‚‰ãªã„ã“ã¨ã‚’çŸ¥ã£ã¦ã‚‹äººãŒã‚ã£ã¡ã‚ƒã„ã‚‹ã®ã§ï¼Œå‹‰å¼·ã«ãªã‚Šã¾ãã‚Šã§ã™ï¼\nå‰ã€…ã‹ã‚‰ç¤¾å¤–ã§ã®ç¹‹ãŒã‚Šã‚’å¢—ã‚„ã—ãŸã„ã¨æ€ã£ã¦ãŸã¨ã“ã‚ã§Kaggleã¨ã„ã†å…±é€šã®è©±é¡ŒãŒã‚ã‚‹ã®ã§ï¼Œæ¯”è¼ƒçš„è©±ãŒã—ã‚„ã™ã„ç’°å¢ƒãŒã§ãã¦Kaggleæ§˜æ§˜ã§ã™ï¼ã‚‚ã£ã¨Kaggleã§ã®ç¹‹ãŒã‚Šã‚’å¢—ã‚„ã—ã¦ï¼ŒãŠäº’ã„åˆ‡ç£‹ç¢ç£¨ã§ãã‚‹ç’°å¢ƒã«æŒã£ã¦ã„ããŸã„ã§ã™ã­ï¼\nãŠã‚ã‚Šã« ã¾ã ã¾ã åŠå¹´ã—ã‹çµŒã£ã¦ã„ãªã„ã§ã™ãŒï¼Œæ¿ƒã„çµŒé¨“ã‚„çŸ¥è¦‹ã‚’Kaggleã‚’é€šã—ã¦å¾—ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ï¼Œã“ã‚Œã‹ã‚‰ã‚‚ç¶™ç¶šã—ã¦ã„ããŸã„ã§ã™ï¼\näººã¨ã®ç¹‹ãŒã‚Šçš„ã«ã¯ï¼Œã‚‚ã†å°‘ã—ä»•äº‹é¢ã§ã‚‚è‰²ã€…ã¨ç›¸è«‡ã§ãã‚‹é–¢ä¿‚æ€§ã‚’ä½œã£ã¦ï¼Œã©ã‚“ãªã“ã¨ã‚’ã‚„ã£ã¦ã¦ã©ã†ã‚†ã†èª²é¡Œã‚„å•é¡Œæ„è­˜ãŒã‚ã‚‹ã‹ã¨ã‹èã„ã¦ã¿ãŸã„ã§ã™ï¼\nã‚ã¨ã¯å¹¸ã„ã«ã‚‚ï¼Œå‹‰å¼·ä¼šã§çŸ¥ã‚Šåˆã£ãŸæ–¹ã¨ã‚³ãƒ³ãƒšã§ãƒãƒ¼ãƒ ã‚’çµ„ã‚“ã§é ‚ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ï¼Œæ¬¡ã¯ãƒãƒ¼ãƒ ã§å‚åŠ ã™ã‚‹æ¥½ã—ã¿ã‚‚å‘³ã‚ã„ã¾ã™ï¼\næœ€å¾Œã«Kaggleã§ã¯ã€ã¾ã•ã«ä»¥ä¸‹ã®è©±ã‚’ä½“ç¾ã§ãã‚‹ã®ã§ã¯ã¨æ€ã£ã¦ã¾ã™ï¼\n é ­ã§ç†å±ˆã‚’ã‚ã‹ã£ãŸã¨ã“ã‚ã§ï¼Œä½“æ„Ÿã‚’ä¼´ã‚ãªã„çŸ¥è­˜ã¯æ´»ç”¨ã§ããªã„ï¼ˆãƒãƒªã‚¬ãƒã‚µãƒ¼ãƒ“ã‚¹ï¼‰\n P.S. DSBã‚³ãƒ³ãƒšã§ãƒ¡ãƒ€ãƒ«ã‚’ç²å¾—ã—ã¾ã™ï¼\nå‚è€ƒ  [1] Kaggleã§ä½¿ãˆã‚‹Featherå½¢å¼ã‚’åˆ©ç”¨ã—ãŸç‰¹å¾´é‡ç®¡ç†æ³• [2] ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒ³ãƒšã§ä½¿ã£ã¦ã„ã‚‹ãƒ¯ã‚¤ã®å­¦ç¿’ãƒ»æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ™’ã—ã¾ã™ [3] hakubishin3/kaggle_ieee  ","date":"2019-12-20","permalink":"https://masatakashiwagi.github.io/portfolio/post/kaggle-get-something/","tags":["Poem","Kaggle"],"title":"Kaggleã‚’å§‹ã‚ã¦åŠå¹´çµŒã£ã¦å€‹äººçš„ã«å¾—ãŸã‚‚ã®"},{"content":"ã¯ã˜ã‚ã« ä»Šå›ã¯ï¼Œå…ˆæ—¥åˆã‚ã¦è¦‹ãŸãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®Excel Binary Workbook (xlsb)ã«é–¢ã—ã¦ï¼Œpythonã§csvã«ãƒ‘ãƒ¼ã‚¹ã™ã‚‹è©±ã§ã™ï¼\n.xlsxã¯ã‚ˆãã‚ã‚‹Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã§ã™ãŒï¼Œãã‚Œã®ãƒã‚¤ãƒŠãƒªãƒ¼å½¢å¼ã§ã‚ã‚‹.xlsbã«é–¢ã—ã¦ã®è©±ã§ã™ï¼ï¼ˆä»Šã¾ã§è¦‹ãŸã“ã¨ãªã‹ã£ãŸæ‹¡å¼µå­ã§ã™ç¬‘ï¼‰\nExcelã®é—‡ã‚„Excelã¨ã®æ ¼é—˜ã¯è‰²ã€…ã‚ã‚Šã¾ã™ãŒï¼Œä»Šå›ã¯ãã“ã‚’ã‚°ãƒƒã¨å ªãˆã¦é€²ã‚ãŸã„ã¨æ€ã„ã¾ã™ç¬‘\n.xlsbã¨ã¯ Weblioè¾æ›¸ã«ã‚ˆã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ï¼\n .xlsbã¨ã¯ï¼ŒExcel 2007ã§ä½œæˆã—ãŸãƒ–ãƒƒã‚¯ã‚’ã€ŒXMLå½¢å¼ã§ãªã„ãƒã‚¤ãƒŠãƒªãƒ–ãƒƒã‚¯ã€ã¨ã—ã¦ä¿å­˜ã™ã‚‹éš›ã«ç”¨ã„ã‚‰ã‚Œã‚‹æ‹¡å¼µå­ã§ã‚ã‚‹ï¼.xlsbã§ãƒ–ãƒƒã‚¯ã‚’ä¿å­˜ã—ãŸå ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ãŒãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜ã•ã‚Œï¼ŒXMLãƒ™ãƒ¼ã‚¹ã§ã‚ã‚‹.xlsxãªã©ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ä¿å­˜ã—ãŸå ´åˆã¨æ¯”ã¹ã¦ï¼Œãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’æ•°åˆ†ã®1ç¨‹åº¦ã«æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ï¼\n å—ã‘å–ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯.xlsbå½¢å¼ã§ã‚‚100MBãã‚‰ã„ã‚ã£ãŸãŸã‚ï¼Œ.xlsxå½¢å¼ã ã¨ã‹ãªã‚Šå®¹é‡ãŒå¤§ããï¼Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¨å‡¦ç†ãŒé‡ãŸããªã‚‹ã“ã¨ãŒæƒ³åƒã§ãã‚‹ã®ã§ï¼Œåœ§ç¸®ã—ãŸã®ã ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ï¼\nExcelã‚’æ‰±ãˆã‚‹pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª openpyxl å®šç•ªã®openpyxlã§ã™ï¼\nä¸Šè¨˜ãƒšãƒ¼ã‚¸ã«ã‚‚è¨˜è¼‰ã•ã‚Œã¦ã¾ã™ãŒï¼ŒExcelãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã§ã‚ã‚‹.xlsxã‚’æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ï¼\n openpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files.\n ã„ã¤ã‚‚ã®ã‚ˆã†ã«ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§å‡¦ç†ã—ã‚ˆã†ã¨ã—ãŸã¨ã“ã‚ï¼Œä¸‹è¨˜ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼\nopenpyxl.utils.exceptions.InvalidFileException: openpyxl does not support binary format .xlsb, please convert this file to .xlsx format if you want to open it with openpyxl  ã‚‚ã†ä¸€åº¦openpyxlã®èª¬æ˜ã‚’è¦‹ã‚‹ã¨ï¼Œç¢ºã‹ã«æ‰±ãˆã‚‹æ‹¡å¼µå­ã¯xlsx/xlsm/xltx/xltmã¨ãªã£ã¦ã„ã‚‹ã®ã§ã€.xlsbã¯æ‰±ãˆãªã„ã®ãŒåˆ†ã‹ã‚Šã¾ã™ï¼\nãã“ã§ï¼Œ.xlsbã®æ‹¡å¼µå­ãŒæ‰±ãˆã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª¿ã¹ãŸã¨ã“ã‚ï¼Œpyxlsbã¨ã„ã†ã®ãŒã‚ã‚‹ã¿ãŸã„ãªã®ã§ï¼Œãã‚Œã‚’ä½¿ã†ã“ã¨ã«ã—ã¾ã—ãŸï¼\npyxlsb pyxlsbã¯å…¬å¼ã®èª¬æ˜ã«ã‚ã‚‹ã‚ˆã†ã«ï¼Œxlsbå½¢å¼ã‚’æ‰±ãˆã‚‹pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ãªã‚Šã¾ã™ï¼\n pyxlsb is an Excel 2007-2010 Binary Workbook (xlsb) parser for Python.\n ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¯pipã§ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\npip install pyxlsb  å…¬å¼ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¼‰ã—ã¦ãŠãã¾ã™ï¼\nimport csv from pyxlsb import open_workbook with open_workbook('Book1.xlsb') as wb: for name in wb.sheets: with wb.get_sheet(name) as sheet, open(name + '.csv', 'w') as f: writer = csv.writer(f) for row in sheet.rows(): writer.writerow([c.v for c in row])  ã‚‚ã—pandasã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ãŸã„å ´åˆã¯ï¼Œå‚è€ƒãƒšãƒ¼ã‚¸ã®ã‚³ãƒ¼ãƒ‰ã§å¯èƒ½ã¨ãªã‚Šã¾ã™ï¼\nãŸã ã—ï¼Œæ™‚åˆ»å¤‰æ›ã«é–¢ã—ã¦å°‘ã—æ³¨æ„ãŒå¿…è¦ãªã®ã§ï¼Œè¨˜è¼‰ã—ã¦ãŠãã¨å…¬å¼ã«ã‚‚ã‚ã‚‹é€šã‚Šï¼Œæ—¥ä»˜ã¯floatã«å¤‰æ›ã•ã‚Œã¦ã—ã¾ã†ãŸã‚ï¼Œconvert_dateé–¢æ•°ã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\n Note that dates will appear as floats. You must use the convert_date(date) method from the corresponding Workbook instance to turn them into datetime.\n ãªã®ã§ï¼Œå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã«æ™‚åˆ»ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã«ã¯ä¸Šè¨˜å¤‰æ›ã‚’ã‚³ãƒ¼ãƒ‰ã®ä¸­ã«å…¥ã‚Œã¦å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã®ã§ã”æ³¨æ„ä¸‹ã•ã„ï¼\nprint(wb.convert_date(41235.45578)) \u0026gt;\u0026gt;\u0026gt; datetime.datetime(2012, 11, 22, 10, 56, 19)  ä»Šå›ã¯å€‹äººçš„ã«åµŒã£ã¦ã—ã¾ã£ãŸ.xlsbå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ã†æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã—ãŸãŒï¼Œå‡ºæ¥ã‚Œã°ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’ã™ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã§æ‰±ã„ãŸããªã„ã®ãŒæœ¬éŸ³ã§ã™ï¼\nã‚‚ã¡ã‚ã‚“ç°¡å˜ãªãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã¨ã‹è¡¨è¨ˆç®—ã¨ã‹ExcelãŒæ´»èºã™ã‚‹å ´é¢ã¯å¤šã€…ã‚ã‚‹ã¨æ€ã†ã®ã§ï¼Œä½¿ã„åˆ†ã‘ã¦ã„ããŸã„ã¨ã¯æ€ã„ã¾ã™ï¼\nå‚è€ƒ  Stack Overflow - Read XLSB File in Pandas Python  è¿½è¨˜  2020/01/05: æ›´æ–°  pandasã®ã€Œversion=1.0.0ã€ã§.xlsbãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¿ãŸã„ã§ã™ï¼æ–¹æ³•ã¯pd.read_excelã®å¼•æ•°ã§engine=\u0026quot;pyxlsb\u0026quot;ã¨æŒ‡å®šã™ã‚‹ã ã‘ã§ã™ï¼\n# Returns a DataFrame pd.read_excel(\u0026quot;path_to_file.xlsb\u0026quot;, engine=\u0026quot;pyxlsb\u0026quot;)  å‚è€ƒ: https://pandas.pydata.org/docs/user_guide/io.html#io-xlsb\n","date":"2019-10-05","permalink":"https://masatakashiwagi.github.io/portfolio/post/excel_processing_using_python/","tags":["Dev"],"title":"Excel Binary Workbookã‚’Pythonã§å‡¦ç†"}]