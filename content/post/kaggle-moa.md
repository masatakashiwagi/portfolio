+++
author = "Masataka Kashiwagi"
title = "Kaggle-MoA の振り返り"
description = "Kaggle-MoA に参加したので，その振り返りを書きました"
date = 2020-12-11T23:13:30+09:00
draft = false
share = true
showLicense = false
support = true
tags = ["KAGGLE"]
+++

## Kaggle-MoA コンペに Team 90's で初参加

このブログは2020/9/4~12/1まで開催していた [MoA コンペ](https://www.kaggle.com/c/lish-moa)での取り組みを紹介する内容です．
（コンペの詳細な内容については割愛します）

今回のコンペでは，同世代のメンバーでチームを組んで取り組みました！チーム結成の経緯は，Twitter でお互いが90年生まれということを知って，同世代で Kaggle チーム組んで戦いたいねーという感じだったと思います．それが少し前のことで当時取り組める良い感じのコンペがなかったのですが，今回テーブルデータのコンペで取り組めそうということで始まりました．

チームでの取り組みはとにかく学びが多く，終盤までモチベーションを保つことができたのが大きかったです．

また，議論することで理解なども深まっていくので，コンペを通してより成長できたんじゃないかなと思います．

今回の僕たちのチームでの取り組み方を紹介すると，

**1. 情報は Slack で共有**
**2. 分析方針や実験結果は Github の issue で管理**
**3. 毎週末に2時間程度のディスカッション**

といった感じです．

3番目の週末のディスカッションは強制ではなく，参加可能な人が参加する形式で運用してました．
（と言いつつもみんな真面目に毎回参加してました笑）

今回はチームでの取り組み方針の具体的な内容について少しだけ掘り下げます．

### 1. 情報は Slack で共有

Slack をどうゆう感じで活用していたのかというと，コンペの Discussion や Notebook の内容について疑問点などを話し合ったり，それ以外にも進め方の相談や雑談などを基本的に行っていました．
あとは submit する時は一言声をかけるなどの submit 管理もしていました．

こうゆうのがあれば良かったなーというところでは，新着の Discussion や Notebook を Kaggle から連携して通知する仕組みを用意しておければ尚良かったのかなと思いました．

### 2. 分析方針や実験結果は Github の issue で管理

Github をどうゆう感じで活用していたのかというと，分析での実験毎に1つの issue を立てて，そこでどうゆう実験をしたのか submit した結果のスコアがどうだったのかなどを記録として残してました．
また，共通で使える特徴量生成のコードだったり，CV の切り方のコードなどの共有も行ってました．

その他には Discussion の内容を整理したり，情報をまとめるために活用したりしていました．

### 3. 毎週末に2時間程度のディスカッション

週末に Google meet でオンラインディスカッションでしていて，そこで何をしていたかというと，基本的には，今週何をしたのかを各々共有したり，わからない部分を話し合ってどうゆうふうに次進めて行くかなどをチームで考えていました．あとは，次の週でどうゆうことをするかの方向性を決めて終わる感じでした．

もちろん雑談や仕事での苦労を労ったりもしていました笑

## 最終順位

最終順位は4373チーム中**34位の銀メダル**で、金メダルまであともう少しのところまで行ったので，とても悔しい結果となりました．

個人的には Inference の処理がエラーで通らない状況に最後の3日ぐらいでなって泣きそうになりました．チームメンバーには weight0 の状態で非常に申し訳なかったなと思ってます泣

学習時に回していたノートブックでは，スコアがチーム内で作ったモデルの中でも上位5つ以内に入っていたので，アンサンブル時には効いてただろうなと思うと尚更です．

個人的な成長としては，テーブルデータに対して NeuralNet が有効に作用する場面について多少理解が深まったと感じています．

今回の MoA では，マルチラベルの予測だったので，一度に大量のクラスを予測する場合には NN が有効でかつ GBDT 系と比較して計算速度も速いんだなと感じました．

また，特徴量的にも交互作用的な部分はNN内部の中間層の組み方などで実現できるので，GBDT 系みたく大量に特徴量を用意しなくても対処できるのが大きいのかなと思っています．（今回のケースだと GBDT で大量のモデルを作るとなると速度的な部分で特徴量が膨大になるとかなり厳しい感じでした）

あとは，NN の実装を Pytorch で行ったこともあり，Pytorch の扱い方がわかるようになったのは大きいと思っています．（仕事では Tensorflow だったりするので...）

Pytorch での実装に関してはもっと進めて行きたいのとコードの整理も合わせてして行きたいので，次に参加予定のコンペではその辺りも意識して挑めたらなーと思います．
